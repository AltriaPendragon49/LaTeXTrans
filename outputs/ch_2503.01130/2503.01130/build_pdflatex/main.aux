\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{schult2023controlroom3droomgenerationusing}
\citation{sarch2022tideetidyingnovelrooms}
\citation{arandjelovi\unhbox \voidb@x \bgroup \let \unhbox \voidb@x \setbox \@tempboxa \hbox {c\global \mathchardef \accent@spacefactor \spacefactor }\let \begingroup \let \typeout \protect \begingroup \def \MessageBreak {
(Font)              }\let \protect \immediate\write \m@ne {LaTeX Font Info:     on input line 19.}\endgroup \endgroup \relax \let \ignorespaces \relax \accent 19 c\egroup \spacefactor \accent@spacefactor 2016netvladcnnarchitectureweakly,hausler2021patchnetvladmultiscalefusionlocallyglobal,keetha2023anylocuniversalvisualplace}
\citation{xu2023clusvprefficientvisualplace}
\citation{7339473}
\citation{caron2021emergingpropertiesselfsupervisedvision}
\citation{oquab2024dinov2learningrobustvisual}
\citation{cai2022patchnetvladlearnedpatchdescriptor}
\citation{hausler2021patchnetvladmultiscalefusionlocallyglobal}
\citation{aryan2023airlocobjectbasedindoorrelocalization}
\citation{keetha2023anylocuniversalvisualplace}
\citation{sattler2019understandinglimitationscnnbasedabsolute}
\citation{lee2017roomnetendtoendroomlayout}
\citation{Snderhauf2015PlaceRW}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.~引言}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{\texorpdfstring {\hskip -1em.~}{}引言}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces AirRoom 利用多层次、面向对象的特征，包括全局上下文、目标区域、目标分割和关键点，执行由粗到细的房间重新识别。}}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example_image}{{1}{1}{AirRoom 利用多层次、面向对象的特征，包括全局上下文、目标区域、目标分割和关键点，执行由粗到细的房间重新识别。}{figure.caption.1}{}}
\newlabel{fig:example_image@cref}{{[figure][1][]1}{[1][1][]1}{}{}{}}
\citation{Lowe2004DistinctiveIF,BAY2008346}
\citation{cao2020unifyingdeeplocalglobal,radenovi\unhbox \voidb@x \bgroup \let \unhbox \voidb@x \setbox \@tempboxa \hbox {c\global \mathchardef \accent@spacefactor \spacefactor }\let \begingroup \let \typeout \protect \begingroup \def \MessageBreak {
(Font)              }\let \protect \immediate\write \m@ne {LaTeX Font Info:     on input line 8.}\endgroup \endgroup \relax \let \ignorespaces \relax \accent 19 c\egroup \spacefactor \accent@spacefactor 2018finetuningcnnimageretrieval}
\citation{Wan2014DeepLF}
\citation{10.1145/1348246.1348248}
\citation{he2015deepresiduallearningimage}
\citation{oquab2024dinov2learningrobustvisual}
\citation{Lowe2004DistinctiveIF}
\citation{10.1007/11744023_32}
\citation{6126544}
\citation{arandjelovi\unhbox \voidb@x \bgroup \let \unhbox \voidb@x \setbox \@tempboxa \hbox {c\global \mathchardef \accent@spacefactor \spacefactor }\let \begingroup \let \typeout \protect \begingroup \def \MessageBreak {
(Font)              }\let \protect \immediate\write \m@ne {LaTeX Font Info:     on input line 23.}\endgroup \endgroup \relax \let \ignorespaces \relax \accent 19 c\egroup \spacefactor \accent@spacefactor 2016netvladcnnarchitectureweakly,hausler2021patchnetvladmultiscalefusionlocallyglobal}
\citation{keetha2023anylocuniversalvisualplace}
\citation{keetha2023anylocuniversalvisualplace}
\citation{arandjelovi\unhbox \voidb@x \bgroup \let \unhbox \voidb@x \setbox \@tempboxa \hbox {c\global \mathchardef \accent@spacefactor \spacefactor }\let \begingroup \let \typeout \protect \begingroup \def \MessageBreak {
(Font)              }\let \protect \immediate\write \m@ne {LaTeX Font Info:     on input line 11.}\endgroup \endgroup \relax \let \ignorespaces \relax \accent 19 c\egroup \spacefactor \accent@spacefactor 2016netvladcnnarchitectureweakly,hausler2021patchnetvladmultiscalefusionlocallyglobal,alibey2023mixvprfeaturemixingvisual}
\citation{kornblith2019betterimagenetmodelstransfer}
\citation{he2015deepresiduallearningimage}
\citation{oquab2024dinov2learningrobustvisual}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.~相关工作}{2}{section.2}\protected@file@percent }
\newlabel{sec:related_work}{{2}{2}{\texorpdfstring {\hskip -1em.~}{}相关工作}{section.2}{}}
\newlabel{sec:related_work@cref}{{[section][2][]2}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.~图像检索}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.~视觉位置识别}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.~提出的方法}{2}{section.3}\protected@file@percent }
\newlabel{sec:proposed_approach}{{3}{2}{\texorpdfstring {\hskip -1em.~}{}提出的方法}{section.3}{}}
\newlabel{sec:proposed_approach@cref}{{[section][3][]3}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.~全局阶段}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}\hskip -1em.~全局特征提取器}{2}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{sec:section3.1.1}{{3.1.1}{2}{\texorpdfstring {\hskip -1em.~}{}全局特征提取器}{subsubsection.3.1.1}{}}
\newlabel{sec:section3.1.1@cref}{{[subsubsection][1][3,1]3.1.1}{[1][2][]2}{}{}{}}
\citation{he2018maskrcnn}
\citation{li2023semanticsamsegmentrecognizegranularity}
\citation{10.5555/1370949}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {AirRoom 粗到细的处理流程}。该流程首先由 Global Feature Extractor 开始，捕获全局上下文特征以检索前 5 张参考图像。然后通过 Instance segmentation 生成目标掩码，接着 Receptive Field Expander 提取目标图像块。Object Feature Extractor 对目标和图像块特征进行处理。Object-Aware Scoring 模块将候选图像缩小到前 2 张，最后 Fine-Grained Retrieval 识别出最合适的参考图像。}}{3}{figure.caption.2}\protected@file@percent }
\newlabel{fig:pipeline}{{2}{3}{\textbf {AirRoom 粗到细的处理流程}。该流程首先由 Global Feature Extractor 开始，捕获全局上下文特征以检索前 5 张参考图像。然后通过 Instance segmentation 生成目标掩码，接着 Receptive Field Expander 提取目标图像块。Object Feature Extractor 对目标和图像块特征进行处理。Object-Aware Scoring 模块将候选图像缩小到前 2 张，最后 Fine-Grained Retrieval 识别出最合适的参考图像。}{figure.caption.2}{}}
\newlabel{fig:pipeline@cref}{{[figure][2][]2}{[1][2][]3}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}\hskip -1em.~全局检索}{3}{subsubsection.3.1.2}\protected@file@percent }
\newlabel{eq:global feature cosine similarity}{{1}{3}{\texorpdfstring {\hskip -1em.~}{}全局检索}{equation.1}{}}
\newlabel{eq:global feature cosine similarity@cref}{{[equation][1][]1}{[1][3][]3}{}{}{}}
\newlabel{eq:global retrieval}{{2}{3}{\texorpdfstring {\hskip -1em.~}{}全局检索}{equation.2}{}}
\newlabel{eq:global retrieval@cref}{{[equation][2][]2}{[1][3][]3}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.~局部阶段}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}\hskip -1em.~实例分割}{3}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{eq:center point}{{3}{3}{\texorpdfstring {\hskip -1em.~}{}实例分割}{equation.3}{}}
\newlabel{eq:center point@cref}{{[equation][3][]3}{[1][3][]3}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}\hskip -1em.~感受野扩展器}{3}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 感受野扩展器将感受野从单个物体扩展到富含上下文信息的区域。通过利用物体邻接矩阵和每个物体的边界框，它将单个物体如橱柜、窗户玻璃和椅子扩展为物体区域，如模块化厨房、多窗玻璃和餐桌套件，分别。}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:expander_image}{{3}{3}{感受野扩展器将感受野从单个物体扩展到富含上下文信息的区域。通过利用物体邻接矩阵和每个物体的边界框，它将单个物体如橱柜、窗户玻璃和椅子扩展为物体区域，如模块化厨房、多窗玻璃和餐桌套件，分别。}{figure.caption.3}{}}
\newlabel{fig:expander_image@cref}{{[figure][3][]3}{[1][3][]3}{}{}{}}
\citation{zheng2018sift}
\citation{zhong2017reranking}
\citation{1498756}
\citation{sarlin2020supergluelearningfeaturematching}
\citation{lindenberger2023lightgluelocalfeaturematching}
\citation{Lowe2004DistinctiveIF}
\citation{yeshwanth2023scannethighfidelitydataset3d}
\citation{5206537}
\citation{7801503}
\citation{aryan2023airlocobjectbasedindoorrelocalization}
\citation{Matterport3D}
\citation{ramakrishnan2021hm3d}
\citation{xiazamirhe2018gibsonenv}
\citation{replica19arxiv}
\citation{puig2023habitat3,szot2021habitat,habitat19iccv}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}\hskip -1em.~面向对象的细化}{4}{subsubsection.3.2.3}\protected@file@percent }
\newlabel{subsec:refinement}{{3.2.3}{4}{\texorpdfstring {\hskip -1em.~}{}面向对象的细化}{subsubsection.3.2.3}{}}
\newlabel{subsec:refinement@cref}{{[subsubsection][3][3,2]3.2.3}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{对象特征提取器}{4}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{互近邻算法}{4}{section*.6}\protected@file@percent }
\newlabel{eq:mutual nearest neighbors}{{4}{4}{互近邻算法}{equation.4}{}}
\newlabel{eq:mutual nearest neighbors@cref}{{[equation][4][]4}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{面向对象的评分}{4}{section*.7}\protected@file@percent }
\newlabel{eq:object-aware scoring}{{8}{4}{面向对象的评分}{equation.8}{}}
\newlabel{eq:object-aware scoring@cref}{{[equation][8][]8}{[1][4][]4}{}{}{}}
\newlabel{eq:mean}{{9a}{4}{面向对象的评分}{equation.9a}{}}
\newlabel{eq:mean@cref}{{[subequation][1][9]9a}{[1][4][]4}{}{}{}}
\newlabel{eq:max}{{9b}{4}{面向对象的评分}{equation.9b}{}}
\newlabel{eq:max@cref}{{[subequation][2][9]9b}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{面向对象的细化}{4}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.~细粒度阶段}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}\hskip -1em.~细粒度检索}{4}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.~实验结果}{4}{section.4}\protected@file@percent }
\newlabel{sec:experimental_results}{{4}{4}{\texorpdfstring {\hskip -1em.~}{}实验结果}{section.4}{}}
\newlabel{sec:experimental_results@cref}{{[section][4][]4}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.~数据集}{4}{subsection.4.1}\protected@file@percent }
\citation{radford2021learningtransferablevisualmodels}
\citation{tan2005introduction}
\citation{lee2022correlationverificationimageretrieval}
\citation{oquab2024dinov2learningrobustvisual}
\citation{hausler2021patchnetvladmultiscalefusionlocallyglobal}
\citation{keetha2023anylocuniversalvisualplace}
\citation{he2015deepresiduallearningimage}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 四个新构建的房间重新识别数据集示意图：MPReID、HMReID、GibsonReID 和 ReplicaReID。每个房间在数据库中仅提供一张参考图像，而查询图像则从不同视角捕捉每个房间。}}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:dataset_image}{{4}{5}{四个新构建的房间重新识别数据集示意图：MPReID、HMReID、GibsonReID 和 ReplicaReID。每个房间在数据库中仅提供一张参考图像，而查询图像则从不同视角捕捉每个房间。}{figure.caption.4}{}}
\newlabel{fig:dataset_image@cref}{{[figure][4][]4}{[1][4][]5}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces AirRoom 与基线模型在四个新构建的房间重识别数据集上的整体性能对比。}}{5}{table.caption.9}\protected@file@percent }
\newlabel{tab:overall}{{1}{5}{AirRoom 与基线模型在四个新构建的房间重识别数据集上的整体性能对比。}{table.caption.9}{}}
\newlabel{tab:overall@cref}{{[table][1][]1}{[1][4][]5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.~数据库预处理}{5}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.~实验概述}{5}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.~整体性能比较}{5}{subsection.4.4}\protected@file@percent }
\newlabel{sec:section4.4}{{4.4}{5}{\texorpdfstring {\hskip -1em.~}{}整体性能比较}{subsection.4.4}{}}
\newlabel{sec:section4.4@cref}{{[subsection][4][4]4.4}{[1][5][]5}{}{}{}}
\citation{lee2022correlationverificationimageretrieval}
\citation{hausler2021patchnetvladmultiscalefusionlocallyglobal}
\citation{dosovitskiy2021imageworth16x16words}
\citation{caron2021emergingpropertiesselfsupervisedvision}
\citation{oquab2024dinov2learningrobustvisual}
\citation{keetha2023anylocuniversalvisualplace}
\citation{he2018maskrcnn}
\citation{li2023semanticsamsegmentrecognizegranularity}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces 与基准模型的组别性能比较，以评估面向对象机制的有效性。}}{6}{table.caption.10}\protected@file@percent }
\newlabel{tab:grouped}{{2}{6}{与基准模型的组别性能比较，以评估面向对象机制的有效性。}{table.caption.10}{}}
\newlabel{tab:grouped@cref}{{[table][2][]2}{[1][5][]6}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces 全局特征提取器的灵活性。}}{6}{table.caption.11}\protected@file@percent }
\newlabel{tab:global feature extractor flexibility}{{3}{6}{全局特征提取器的灵活性。}{table.caption.11}{}}
\newlabel{tab:global feature extractor flexibility@cref}{{[table][3][]3}{[1][5][]6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 给定一个卧室查询，AirRoom 通过利用物体相关性进行房间重识别，准确地检索目标图像。相比之下，CVNet 检索视觉上相似的图像，但没有保持场景的准确性，DINOv2 捕捉语义内容但忽略了颜色细节，Patch-NetVLAD 使用聚合的局部特征形成全局描述符，检索到的图像语义信息不匹配，而 AnyLoc 考虑了语义和颜色属性，但忽略了房间内物体的重要性。}}{6}{figure.caption.12}\protected@file@percent }
\newlabel{fig:failure}{{5}{6}{给定一个卧室查询，AirRoom 通过利用物体相关性进行房间重识别，准确地检索目标图像。相比之下，CVNet 检索视觉上相似的图像，但没有保持场景的准确性，DINOv2 捕捉语义内容但忽略了颜色细节，Patch-NetVLAD 使用聚合的局部特征形成全局描述符，检索到的图像语义信息不匹配，而 AnyLoc 考虑了语义和颜色属性，但忽略了房间内物体的重要性。}{figure.caption.12}{}}
\newlabel{fig:failure@cref}{{[figure][5][]5}{[1][5][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\hskip -1em.~按组别的性能比较}{6}{subsection.4.5}\protected@file@percent }
\newlabel{sec:section4.5}{{4.5}{6}{\texorpdfstring {\hskip -1em.~}{}按组别的性能比较}{subsection.4.5}{}}
\newlabel{sec:section4.5@cref}{{[subsection][5][4]4.5}{[1][6][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}\hskip -1em.~管道灵活性评估}{6}{subsection.4.6}\protected@file@percent }
\newlabel{sec:section4.6}{{4.6}{6}{\texorpdfstring {\hskip -1em.~}{}管道灵活性评估}{subsection.4.6}{}}
\newlabel{sec:section4.6@cref}{{[subsection][6][4]4.6}{[1][6][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}\hskip -1em.~全局特征提取器}{6}{subsubsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.2}\hskip -1em.~实例分割}{6}{subsubsection.4.6.2}\protected@file@percent }
\citation{he2015deepresiduallearningimage}
\citation{oquab2024dinov2learningrobustvisual}
\citation{zhao2024dynamicsceneunderstandingobjectcentric}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces 实例分割的灵活性。}}{7}{table.caption.13}\protected@file@percent }
\newlabel{tab:is flexibility}{{4}{7}{实例分割的灵活性。}{table.caption.13}{}}
\newlabel{tab:is flexibility@cref}{{[table][4][]4}{[1][7][]7}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.3}\hskip -1em.~目标特征提取器}{7}{subsubsection.4.6.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces 目标特征提取器的灵活性。}}{7}{table.caption.14}\protected@file@percent }
\newlabel{tab:ofe flexibility}{{5}{7}{目标特征提取器的灵活性。}{table.caption.14}{}}
\newlabel{tab:ofe flexibility@cref}{{[table][5][]5}{[1][7][]7}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.4}\hskip -1em.~面向对象评分}{7}{subsubsection.4.6.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces 面向对象的评分灵活性。}}{7}{table.caption.15}\protected@file@percent }
\newlabel{tab:os flexibility}{{6}{7}{面向对象的评分灵活性。}{table.caption.15}{}}
\newlabel{tab:os flexibility@cref}{{[table][6][]6}{[1][7][]7}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}\hskip -1em.~消融研究}{7}{subsection.4.7}\protected@file@percent }
\newlabel{sec:section4.7}{{4.7}{7}{\texorpdfstring {\hskip -1em.~}{}消融研究}{subsection.4.7}{}}
\newlabel{sec:section4.7@cref}{{[subsection][7][4]4.7}{[1][7][]7}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces 消融研究（不包括全局评分实验）。}}{7}{table.caption.16}\protected@file@percent }
\newlabel{tab:ablation w/o global score}{{7}{7}{消融研究（不包括全局评分实验）。}{table.caption.16}{}}
\newlabel{tab:ablation w/o global score@cref}{{[table][7][]7}{[1][7][]7}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces 关于全局得分的消融研究。}}{7}{table.caption.17}\protected@file@percent }
\newlabel{tab:ablation on global score}{{8}{7}{关于全局得分的消融研究。}{table.caption.17}{}}
\newlabel{tab:ablation on global score@cref}{{[table][8][]8}{[1][7][]7}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}\hskip -1em.~局限性}{7}{subsection.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.~结论}{7}{section.5}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{7}{\texorpdfstring {\hskip -1em.~}{}结论}{section.5}{}}
\newlabel{sec:conclusion@cref}{{[section][5][]5}{[1][7][]7}{}{}{}}
\bibstyle{ieeenat_fullname}
\bibdata{main}
\bibcite{alibey2023mixvprfeaturemixingvisual}{{1}{2023}{{Ali-bey et~al.}}{{Ali-bey, Chaib-draa, and Giguère}}}
\bibcite{arandjelović2016netvladcnnarchitectureweakly}{{2}{2016}{{Arandjelović et~al.}}{{Arandjelović, Gronat, Torii, Pajdla, and Sivic}}}
\bibcite{aryan2023airlocobjectbasedindoorrelocalization}{{3}{2023}{{Aryan et~al.}}{{Aryan, Li, Scherer, Lin, and Wang}}}
\bibcite{10.1007/11744023_32}{{4}{2006}{{Bay et~al.}}{{Bay, Tuytelaars, and Van~Gool}}}
\bibcite{BAY2008346}{{5}{2008}{{Bay et~al.}}{{Bay, Ess, Tuytelaars, and {Van Gool}}}}
\bibcite{10.5555/1370949}{{6}{2008}{{Berg et~al.}}{{Berg, Cheong, Kreveld, and Overmars}}}
\bibcite{cai2022patchnetvladlearnedpatchdescriptor}{{7}{2022}{{Cai et~al.}}{{Cai, Zhao, Cui, Zhang, Ye, and Feng}}}
\bibcite{cao2020unifyingdeeplocalglobal}{{8}{2020}{{Cao et~al.}}{{Cao, Araujo, and Sim}}}
\bibcite{caron2021emergingpropertiesselfsupervisedvision}{{9}{2021}{{Caron et~al.}}{{Caron, Touvron, Misra, Jégou, Mairal, Bojanowski, and Joulin}}}
\bibcite{Matterport3D}{{10}{2017}{{Chang et~al.}}{{Chang, Dai, Funkhouser, Halber, Niessner, Savva, Song, Zeng, and Zhang}}}
\bibcite{10.1145/1348246.1348248}{{11}{2008}{{Datta et~al.}}{{Datta, Joshi, Li, and Wang}}}
\bibcite{dosovitskiy2021imageworth16x16words}{{12}{2021}{{Dosovitskiy et~al.}}{{Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby}}}
\bibcite{hausler2021patchnetvladmultiscalefusionlocallyglobal}{{13}{2021}{{Hausler et~al.}}{{Hausler, Garg, Xu, Milford, and Fischer}}}
\bibcite{he2015deepresiduallearningimage}{{14}{2015}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{he2018maskrcnn}{{15}{2018}{{He et~al.}}{{He, Gkioxari, Dollár, and Girshick}}}
\bibcite{keetha2023anylocuniversalvisualplace}{{16}{2023}{{Keetha et~al.}}{{Keetha, Mishra, Karhade, Jatavallabhula, Scherer, Krishna, and Garg}}}
\bibcite{kornblith2019betterimagenetmodelstransfer}{{17}{2019}{{Kornblith et~al.}}{{Kornblith, Shlens, and Le}}}
\bibcite{lee2017roomnetendtoendroomlayout}{{18}{2017}{{Lee et~al.}}{{Lee, Badrinarayanan, Malisiewicz, and Rabinovich}}}
\bibcite{lee2022correlationverificationimageretrieval}{{19}{2022}{{Lee et~al.}}{{Lee, Seong, Lee, and Kim}}}
\bibcite{li2023semanticsamsegmentrecognizegranularity}{{20}{2023}{{Li et~al.}}{{Li, Zhang, Sun, Zou, Liu, Yang, Li, Zhang, and Gao}}}
\bibcite{lindenberger2023lightgluelocalfeaturematching}{{21}{2023}{{Lindenberger et~al.}}{{Lindenberger, Sarlin, and Pollefeys}}}
\bibcite{Lowe2004DistinctiveIF}{{22}{2004}{{Lowe}}{{}}}
\bibcite{7339473}{{23}{2016}{{Lowry et~al.}}{{Lowry, Sünderhauf, Newman, Leonard, Cox, Corke, and Milford}}}
\bibcite{1498756}{{24}{2005}{{Mikolajczyk and Schmid}}{{}}}
\bibcite{oquab2024dinov2learningrobustvisual}{{25}{2024}{{Oquab et~al.}}{{Oquab, Darcet, Moutakanni, Vo, Szafraniec, Khalidov, Fernandez, Haziza, Massa, El-Nouby, Assran, Ballas, Galuba, Howes, Huang, Li, Misra, Rabbat, Sharma, Synnaeve, Xu, Jegou, Mairal, Labatut, Joulin, and Bojanowski}}}
\bibcite{puig2023habitat3}{{26}{2023}{{Puig et~al.}}{{Puig, Undersander, Szot, Cote, Partsey, Yang, Desai, Clegg, Hlav\'{a}c, Min, Gervet, Vondru\v {s}, Berges, Turner, Maksymets, Kira, Kalakrishnan, Malik, Chaplot, Jain, Batra, Rai, and Mottaghi}}}
\bibcite{5206537}{{27}{2009}{{Quattoni and Torralba}}{{}}}
\bibcite{radenović2018finetuningcnnimageretrieval}{{28}{2018}{{Radenović et~al.}}{{Radenović, Tolias, and Chum}}}
\bibcite{radford2021learningtransferablevisualmodels}{{29}{2021}{{Radford et~al.}}{{Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever}}}
\bibcite{ramakrishnan2021hm3d}{{30}{2021}{{Ramakrishnan et~al.}}{{Ramakrishnan, Gokaslan, Wijmans, Maksymets, Clegg, Turner, Undersander, Galuba, Westbury, Chang, Savva, Zhao, and Batra}}}
\bibcite{6126544}{{31}{2011}{{Rublee et~al.}}{{Rublee, Rabaud, Konolige, and Bradski}}}
\bibcite{7801503}{{32}{2016}{{Sahdev and Tsotsos}}{{}}}
\bibcite{sarch2022tideetidyingnovelrooms}{{33}{2022}{{Sarch et~al.}}{{Sarch, Fang, Harley, Schydlo, Tarr, Gupta, and Fragkiadaki}}}
\bibcite{sarlin2020supergluelearningfeaturematching}{{34}{2020}{{Sarlin et~al.}}{{Sarlin, DeTone, Malisiewicz, and Rabinovich}}}
\bibcite{sattler2019understandinglimitationscnnbasedabsolute}{{35}{2019}{{Sattler et~al.}}{{Sattler, Zhou, Pollefeys, and Leal-Taixe}}}
\bibcite{habitat19iccv}{{36}{2019}{{Savva et~al.}}{{Savva, Kadian, Maksymets, Zhao, Wijmans, Jain, Straub, Liu, Koltun, Malik, Parikh, and Batra}}}
\bibcite{schult2023controlroom3droomgenerationusing}{{37}{2023}{{Schult et~al.}}{{Schult, Tsai, Höllein, Wu, Wang, Ma, Li, Wang, Wimbauer, He, Zhang, Leibe, Vajda, and Hou}}}
\bibcite{replica19arxiv}{{38}{2019}{{Straub et~al.}}{{Straub, Whelan, Ma, Chen, Wijmans, Green, Engel, Mur-Artal, Ren, Verma, Clarkson, Yan, Budge, Yan, Pan, Yon, Zou, Leon, Carter, Briales, Gillingham, Mueggler, Pesqueira, Savva, Batra, Strasdat, Nardi, Goesele, Lovegrove, and Newcombe}}}
\bibcite{Snderhauf2015PlaceRW}{{39}{2015}{{S{\"u}nderhauf et~al.}}{{S{\"u}nderhauf, Shirazi, Jacobson, Dayoub, Pepperell, Upcroft, and Milford}}}
\bibcite{szot2021habitat}{{40}{2021}{{Szot et~al.}}{{Szot, Clegg, Undersander, Wijmans, Zhao, Turner, Maestre, Mukadam, Chaplot, Maksymets, Gokaslan, Vondrus, Dharur, Meier, Galuba, Chang, Kira, Koltun, Malik, Savva, and Batra}}}
\bibcite{taira2018inlocindoorvisuallocalization}{{41}{2018}{{Taira et~al.}}{{Taira, Okutomi, Sattler, Cimpoi, Pollefeys, Sivic, Pajdla, and Torii}}}
\bibcite{tan2005introduction}{{42}{2005}{{Tan et~al.}}{{Tan, Steinbach, and Kumar}}}
\bibcite{Wan2014DeepLF}{{43}{2014}{{Wan et~al.}}{{Wan, Wang, Hoi, Wu, Zhu, Zhang, and Li}}}
\bibcite{xiazamirhe2018gibsonenv}{{44}{2018}{{Xia et~al.}}{{Xia, R.~Zamir, He, Sax, Malik, and Savarese}}}
\bibcite{xu2023clusvprefficientvisualplace}{{45}{2023}{{Xu et~al.}}{{Xu, Shamsolmoali, and Yang}}}
\bibcite{yeshwanth2023scannethighfidelitydataset3d}{{46}{2023}{{Yeshwanth et~al.}}{{Yeshwanth, Liu, Nießner, and Dai}}}
\bibcite{zhao2024dynamicsceneunderstandingobjectcentric}{{47}{2024}{{Zhao et~al.}}{{Zhao, Hao, Gao, Wang, and Yang}}}
\bibcite{Structured3D}{{48}{2020}{{Zheng et~al.}}{{Zheng, Zhang, Li, Tang, Gao, and Zhou}}}
\bibcite{zheng2018sift}{{49}{2018}{{Zheng et~al.}}{{Zheng, Zheng, and Yang}}}
\bibcite{zhong2017reranking}{{50}{2017}{{Zhong et~al.}}{{Zhong, Zheng, Cao, and Li}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.~数据集}{1}{section.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces MPReID 的组成。}}{1}{table.caption.19}\protected@file@percent }
\newlabel{tab:MPReID}{{9}{1}{MPReID 的组成。}{table.caption.19}{}}
\newlabel{tab:MPReID@cref}{{[table][9][]9}{[1][1][]1}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces HMReID 的组成。}}{1}{table.caption.20}\protected@file@percent }
\newlabel{tab:HMReID}{{10}{1}{HMReID 的组成。}{table.caption.20}{}}
\newlabel{tab:HMReID@cref}{{[table][10][]10}{[1][1][]1}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces GibsonReID的组成。}}{1}{table.caption.21}\protected@file@percent }
\newlabel{tab:GibsonReID}{{11}{1}{GibsonReID的组成。}{table.caption.21}{}}
\newlabel{tab:GibsonReID@cref}{{[table][11][]11}{[1][1][]1}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces ReplicaReID 的组成。}}{1}{table.caption.22}\protected@file@percent }
\newlabel{tab:ReplicaReID}{{12}{1}{ReplicaReID 的组成。}{table.caption.22}{}}
\newlabel{tab:ReplicaReID@cref}{{[table][12][]12}{[1][1][]1}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces 四个新构建的房间ReID数据集中语义不同房间的统计数据。}}{1}{table.caption.23}\protected@file@percent }
\newlabel{tab:Statistics}{{13}{1}{四个新构建的房间ReID数据集中语义不同房间的统计数据。}{table.caption.23}{}}
\newlabel{tab:Statistics@cref}{{[table][13][]13}{[1][1][]1}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}\hskip -1em.~实验细节}{1}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}\hskip -1em.~整体性能比较}{1}{subsection.7.1}\protected@file@percent }
\newlabel{sec:appendix_overall}{{7.1}{1}{\texorpdfstring {\hskip -1em.~}{}整体性能比较}{subsection.7.1}{}}
\newlabel{sec:appendix_overall@cref}{{[subsection][1][7]7.1}{[1][1][]1}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{基准配置}{1}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基准适配}{1}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{AirRoom配置}{1}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}\hskip -1em.~按组性能比较}{1}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基线配置}{1}{section*.27}\protected@file@percent }
\citation{taira2018inlocindoorvisuallocalization}
\citation{Structured3D}
\citation{taira2018inlocindoorvisuallocalization}
\citation{Structured3D}
\@writefile{toc}{\contentsline {paragraph}{基线适配}{2}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{AirRoom配置}{2}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}\hskip -1em.~管道灵活性评估}{2}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}\hskip -1em.~全局特征提取器}{2}{subsubsection.7.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基准配置}{2}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基准适配}{2}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{AirRoom配置}{2}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}\hskip -1em.~实例分割}{2}{subsubsection.7.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{AirRoom 配置}{2}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}\hskip -1em.~大规模评估}{2}{section.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces 在 UnionReID 上与基线模型的对比，用于评估 AirRoom 在数据扩展下的性能。}}{2}{table.caption.34}\protected@file@percent }
\newlabel{tab:Union}{{14}{2}{在 UnionReID 上与基线模型的对比，用于评估 AirRoom 在数据扩展下的性能。}{table.caption.34}{}}
\newlabel{tab:Union@cref}{{[table][14][]14}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}\hskip -1em.~室内定位数据集评估}{2}{section.9}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces 在现有数据集上与基线模型的对比，以进一步验证我们的方法。}}{2}{table.caption.35}\protected@file@percent }
\newlabel{tab:Indoor}{{15}{2}{在现有数据集上与基线模型的对比，以进一步验证我们的方法。}{table.caption.35}{}}
\newlabel{tab:Indoor@cref}{{[table][15][]15}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}\hskip -1em.~运行时分析}{2}{section.10}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Mask R-CNN \& ResNet 运行时间。}}{3}{table.caption.36}\protected@file@percent }
\newlabel{tab:module_runtime_mr}{{16}{3}{Mask R-CNN \& ResNet 运行时间。}{table.caption.36}{}}
\newlabel{tab:module_runtime_mr@cref}{{[table][16][]16}{[1][2][]3}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {17}{\ignorespaces Mask R-CNN \& DINOv2 运行时间。}}{3}{table.caption.37}\protected@file@percent }
\newlabel{tab:module_runtime_md}{{17}{3}{Mask R-CNN \& DINOv2 运行时间。}{table.caption.37}{}}
\newlabel{tab:module_runtime_md@cref}{{[table][17][]17}{[1][2][]3}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {18}{\ignorespaces Mask R-CNN \& ResNet ／ DINOv2 准确率。}}{3}{table.caption.38}\protected@file@percent }
\newlabel{tab:module_accuracy}{{18}{3}{Mask R-CNN \& ResNet ／ DINOv2 准确率。}{table.caption.38}{}}
\newlabel{tab:module_accuracy@cref}{{[table][18][]18}{[1][2][]3}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces 随着目标掩码评分阈值的提高，AirRoom 的性能略有下降；然而，效率却显著提升。}}{3}{figure.caption.39}\protected@file@percent }
\newlabel{fig:runtime}{{6}{3}{随着目标掩码评分阈值的提高，AirRoom 的性能略有下降；然而，效率却显著提升。}{figure.caption.39}{}}
\newlabel{fig:runtime@cref}{{[figure][6][]6}{[1][2][]3}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {19}{\ignorespaces Semantic-SAM \& ResNet / DINOv2 运行时间。}}{3}{table.caption.40}\protected@file@percent }
\newlabel{tab:module_runtime_ssam}{{19}{3}{Semantic-SAM \& ResNet / DINOv2 运行时间。}{table.caption.40}{}}
\newlabel{tab:module_runtime_ssam@cref}{{[table][19][]19}{[1][2][]3}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {20}{\ignorespaces 与当前最先进方法的运行时间比较。}}{3}{table.caption.41}\protected@file@percent }
\newlabel{tab:runtime_comparison}{{20}{3}{与当前最先进方法的运行时间比较。}{table.caption.41}{}}
\newlabel{tab:runtime_comparison@cref}{{[table][20][]20}{[1][2][]3}{}{}{}}
\gdef \@abspage@last{12}
