[
    {
        "placeholder": "<PLACEHOLDER_CAP_1>",
        "cap_type": "title",
        "content": "\\title{AirRoom: Objects Matter in Room Reidentification}",
        "trans_content": "\\title{AirRoom: 物体在房间重识别中的重要性}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_2>",
        "cap_type": "caption",
        "content": "\\caption{AirRoom leverages multi-level, object-oriented features, including global context, object patches, object segmentation, and keypoints, to perform coarse-to-fine room reidentification.}",
        "trans_content": "\\caption{AirRoom 利用多层次、面向对象的特征，包括全局上下文、目标区域、目标分割和关键点，执行由粗到细的房间重新识别。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_3>",
        "cap_type": "caption",
        "content": "\\caption{\\textbf{The AirRoom coarse-to-fine pipeline}. The pipeline begins with the Global Feature Extractor, which captures global context features to retrieve the top-5 reference images. Instance segmentation then generates object masks, followed by the Receptive Field Expander, which extracts object patches. The Object Feature Extractor processes both object and patch features. The Object-Aware Scoring module narrows the selection to the top-2 candidates, and Fine-Grained Retrieval identifies the most suitable reference image.}",
        "trans_content": "\\caption{\\textbf{AirRoom 粗到细的处理流程}。该流程首先由 Global Feature Extractor 开始，捕获全局上下文特征以检索前 5 张参考图像。然后通过 Instance segmentation 生成目标掩码，接着 Receptive Field Expander 提取目标图像块。Object Feature Extractor 对目标和图像块特征进行处理。Object-Aware Scoring 模块将候选图像缩小到前 2 张，最后 Fine-Grained Retrieval 识别出最合适的参考图像。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_4>",
        "cap_type": "caption",
        "content": "\\caption{The Receptive Field Expander broadens the receptive field from individual objects to patches rich in contextual information. Leveraging the object adjacency matrix and each object's bounding box, it expands single objects such as a cupboard, window pane, and chair into object patches like a modular kitchen, multi-pane window, and dining set, respectively.}",
        "trans_content": "\\caption{感受野扩展器将感受野从单个物体扩展到富含上下文信息的区域。通过利用物体邻接矩阵和每个物体的边界框，它将单个物体如橱柜、窗户玻璃和椅子扩展为物体区域，如模块化厨房、多窗玻璃和餐桌套件，分别。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_5>",
        "cap_type": "caption",
        "content": "\\caption{Illustration of four newly constructed room reidentification datasets: MPReID, HMReID, GibsonReID, and ReplicaReID. Each room provides only one reference image in the database, while query images for each room capture varied viewpoints.}",
        "trans_content": "\\caption{四个新构建的房间重新识别数据集示意图：MPReID、HMReID、GibsonReID 和 ReplicaReID。每个房间在数据库中仅提供一张参考图像，而查询图像则从不同视角捕捉每个房间。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_6>",
        "cap_type": "caption",
        "content": "\\caption{Overall performance comparison between AirRoom and baseline models on four newly constructed room ReID datasets.}",
        "trans_content": "\\caption{AirRoom 与基线模型在四个新构建的房间重识别数据集上的整体性能对比。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_7>",
        "cap_type": "caption",
        "content": "\\caption{Group-wise performance comparison with baseline models to assess the effectiveness of the object-aware mechanism.}",
        "trans_content": "\\caption{与基准模型的组别性能比较，以评估面向对象机制的有效性。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_8>",
        "cap_type": "caption",
        "content": "\\caption{Global Feature Extractor Flexibility.}",
        "trans_content": "\\caption{全局特征提取器的灵活性。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_9>",
        "cap_type": "caption",
        "content": "\\caption{Given a bedroom query, AirRoom accurately retrieves the target image by leveraging object relevance for room reidentification. In contrast, CVNet retrieves visually similar images without preserving scene accuracy, DINOv2 captures semantic content but overlooks color details, Patch-NetVLAD, using aggregated local features to form global descriptors, retrieves images with mismatched semantic information, and AnyLoc considers semantic and color attributes but neglects object importance within rooms.}",
        "trans_content": "\\caption{给定一个卧室查询，AirRoom 通过利用物体相关性进行房间重识别，准确地检索目标图像。相比之下，CVNet 检索视觉上相似的图像，但没有保持场景的准确性，DINOv2 捕捉语义内容但忽略了颜色细节，Patch-NetVLAD 使用聚合的局部特征形成全局描述符，检索到的图像语义信息不匹配，而 AnyLoc 考虑了语义和颜色属性，但忽略了房间内物体的重要性。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_10>",
        "cap_type": "caption",
        "content": "\\caption{Instance Segmentation Flexibility.}",
        "trans_content": "\\caption{实例分割的灵活性。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_11>",
        "cap_type": "caption",
        "content": "\\caption{Object Feature Extractor Flexibility.}",
        "trans_content": "\\caption{目标特征提取器的灵活性。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_12>",
        "cap_type": "caption",
        "content": "\\caption{Object-Aware Scoring Flexibility.}",
        "trans_content": "\\caption{面向对象的评分灵活性。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_13>",
        "cap_type": "caption",
        "content": "\\caption{Ablation Studies (Excluding Global Score Experiments).}",
        "trans_content": "\\caption{消融研究（不包括全局评分实验）。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_14>",
        "cap_type": "caption",
        "content": "\\caption{Ablation Studies on Global Score.}",
        "trans_content": "\\caption{关于全局得分的消融研究。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_15>",
        "cap_type": "caption",
        "content": "\\caption{Composition of MPReID.}",
        "trans_content": "\\caption{MPReID 的组成。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_16>",
        "cap_type": "caption",
        "content": "\\caption{Composition of HMReID.}",
        "trans_content": "\\caption{HMReID 的组成。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_17>",
        "cap_type": "caption",
        "content": "\\caption{Composition of GibsonReID.}",
        "trans_content": "\\caption{GibsonReID的组成。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_18>",
        "cap_type": "caption",
        "content": "\\caption{Composition of ReplicaReID.}",
        "trans_content": "\\caption{ReplicaReID 的组成。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_19>",
        "cap_type": "caption",
        "content": "\\caption{Statistics of semantically different rooms across four newly constructed room ReID datasets.}",
        "trans_content": "\\caption{四个新构建的房间ReID数据集中语义不同房间的统计数据。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_20>",
        "cap_type": "caption",
        "content": "\\caption{Comparison with baseline models on UnionReID to evaluate AirRoom's performance under data scaling.}",
        "trans_content": "\\caption{在 UnionReID 上与基线模型的对比，用于评估 AirRoom 在数据扩展下的性能。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_21>",
        "cap_type": "caption",
        "content": "\\caption{Comparison with baseline models on existing datasets to further validate our method.}",
        "trans_content": "\\caption{在现有数据集上与基线模型的对比，以进一步验证我们的方法。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_22>",
        "cap_type": "caption",
        "content": "\\caption{Mask R-CNN \\& ResNet Runtime.}",
        "trans_content": "\\caption{Mask R-CNN \\& ResNet 运行时间。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_23>",
        "cap_type": "caption",
        "content": "\\caption{Mask R-CNN \\& DINOv2 Runtime.}",
        "trans_content": "\\caption{Mask R-CNN \\& DINOv2 运行时间。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_24>",
        "cap_type": "caption",
        "content": "\\caption{Mask R-CNN \\& ResNet / DINOv2 Accuracy.}",
        "trans_content": "\\caption{Mask R-CNN \\& ResNet ／ DINOv2 准确率。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_25>",
        "cap_type": "caption",
        "content": "\\caption{As the object mask score threshold increases, AirRoom's performance experiences a slight decline; however, the efficiency improves significantly.}",
        "trans_content": "\\caption{随着目标掩码评分阈值的提高，AirRoom 的性能略有下降；然而，效率却显著提升。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_26>",
        "cap_type": "caption",
        "content": "\\caption{Semantic-SAM \\& ResNet / DINOv2 Runtime.}",
        "trans_content": "\\caption{Semantic-SAM \\& ResNet / DINOv2 运行时间。}"
    },
    {
        "placeholder": "<PLACEHOLDER_CAP_27>",
        "cap_type": "caption",
        "content": "\\caption{Runtime Comparison with State-of-the-Art Methods.}",
        "trans_content": "\\caption{与当前最先进方法的运行时间比较。}"
    }
]