\begin{figure}[t!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.48\linewidth}
        \input{graphs/early_late/loss_vs_flops}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\linewidth}
        \input{graphs/early_late/d_n_ratio_vs_flops}
    \end{subfigure}
    \vspace{-3mm}
    \caption{\textbf{原生多模态模型的可扩展性特性。} 基于 \cref{sec:scaling_laws_early} 中的可扩展性规律研究，我们观察到： (1) 在使用相同计算预算 $C$（以 FLOPs 计）进行训练时，早期融合模型和后期融合模型在验证损失 $L$ 上表现相当； (2) 该性能是通过参数量 $N$ 与训练标记数 $D$ 之间的不同权衡实现的，其中早期融合模型所需参数更少； \edit{；(3) 稀疏的早期融合模型在给定的 FLOP 预算下可获得更低的损失，但需要更多的训练标记。} }
    \label{fig:teaser}
\end{figure}
