\section{引言}
\label{sec:intro}

多模态提供了丰富的信号，用于感知和理解世界。
视觉的进展
\citep{radford2021learning,oquab2023dinov2,zhai2023sigmoidsiglip,fini2024multimodalaimv2}，
\edit{音频 \citep{huang2022masked,elizalde2023clap,chen2022wavlm,hsu2021hubert}} 
以及语言模型 \citep{achiam2023gpt4,team2023gemini,dubey2024llama3}
促使了强大多模态模型的开发，这些模型能够理解语言、图像和音频。一种常见的方法是将分别预训练的单模态模型连接起来，
\edit{例如将视觉编码器连接到LLM的输入层~\citep{laurenccon2024mattersidefics2,shukor2023epalm,alayrac2022flamingo,
xue2024xgenblip3,beyer2024paligemma,wang2024qwen2,liu2024improvedllava,zhang2023videollama,kong2024audioflam,defossez2024moshi}。}

尽管这种方法看起来很方便，但是否这种后期融合策略在本质上是最优的 \edit{用于理解多模态信号}，仍然是一个未解的问题。此外，随着大量多模态数据的可用，从单模态预训练初始化可能具有潜在的负面影响，
因为它可能引入偏差，阻止模型 \edit{充分利用跨模态的共同依赖性}。
另一个挑战是扩展这样的系统；每个组件（例如视觉编码器、LLM）都有自己的超参数集，\edit{预训练数据混合物}，以及 \edit{关于数据和计算资源应用的} 扩展特性。更灵活的架构可能允许模型在各模态之间动态分配其能力，从而简化扩展工作。

在这项工作中，我们专注于从头开始训练的原生多模态模型的扩展特性。我们首先研究 \edit{常用的} 后期融合架构是否在本质上具有优势，方法是将它们与早期融合模型进行比较，后者处理原始多模态输入，而无需依赖 \edit{专用的视觉编码器}。
我们对早期和后期融合架构进行了扩展实验，推导出扩展定律以预测它们的性能和计算最优配置。
我们的研究结果表明，后期融合在 \edit{从零开始训练} 时并没有固有的优势。相反，早期融合模型更高效，更易于扩展。此外，我们观察到，原生多模态模型遵循类似于LLMs的扩展定律~\citep{hoffmann2022training}，尽管在跨模态和数据集的扩展系数上略有变化。我们的结果表明，模型参数和训练令牌应该 \edit{大致相等} 地扩展，以获得最佳性能。
此外，我们发现，不同的 \edit{多模态} 训练混合物表现出类似的整体趋势，表明我们的研究结果可能适用于更广泛的设置。

尽管我们的发现倾向于早期融合，但多模态数据本质上是异质的，这表明某种程度的参数专业化可能仍然会带来好处。为 \edit{探讨} 这一点，我们 \edit{尝试利用} 专家混合（Mixture of Experts, MoEs）~\citep{shazeer2017outrageously}，这是一种使模型能够在各模态之间对称并行地动态分配专业化参数的技术，区别于后期融合模型，后者是非对称的，并且顺序地处理数据。使用MoEs训练原生多模态模型显著提高了性能，\edit{因此}，收敛速度也更快。 \edit{我们的MoEs扩展定律表明，训练令牌的数量比活跃参数的数量更为重要。这种不平衡的扩展与密集模型所观察到的不同，因为稀疏模型的总参数数量更高。} \edit{此外，}我们的分析表明，专家通常会在不同的模态中进行专业化，这种专业化在早期和最后几层尤为显著。

\input{figs/teaser}
\subsection{我们的研究发现总结}
我们的研究发现可以总结如下：

\cpar{原生早期和晚期融合效果相当：} \edit{从头训练的早期融合模型}
与其晚期融合的对应模型表现相当，且在低计算预算下，早期融合模型稍微占优
(\cref{fig:early_vs_early_init_scaledata})。此外，我们的扩展法则研究表明，随着计算预算的增加，早期和晚期融合的计算最优模型表现相似~(\cref{fig:teaser} 左图)。

\cpar{原生多模态模型的扩展与大语言模型相似：} 原生多模态模型的扩展法则与仅文本的大语言模型遵循相似的规律，只是根据目标数据类型和训练混合的不同，扩展指数略有不同
(\cref{tab:early_vs_late_coeffs})。

\cpar{晚期融合需要更多的参数：} 与早期融合相比，计算最优的晚期融合模型需要更高的参数与数据比率
(\cref{fig:teaser} 右图)。

\cpar{稀疏性显著提升早期融合原生多模态模型表现：} 在相同推理成本下，稀疏的原生多模态模型相比其密集型对照模型表现显著提升~(\cref{fig:dense_vs_moe_scaledata})。此外，经过稀疏性训练后，它们会隐式地学习到模态特定的权重~(\cref{fig:app_moes_specialization})。 \edit{此外，计算最优模型在计算预算增加时，更依赖于扩展训练令牌的数量，而非活跃参数的数量 (\cref{fig:teaser} 右图)。}

\cpar{对于稀疏的原生多模态模型，无模态感知路由优于有模态感知路由：} 训练稀疏的专家混合模型时，使用无模态感知路由的表现始终优于使用有模态感知路由的模型
(\cref{fig:hard_vs_moe_scaledata})。

\vspace{-5pt}
