\section{实验设置}
\label{app:implementation_details}

在\Cref{tab:scaling_laws_hparams}中，我们展示了用于推导缩放规律的不同模型配置的预训练超参数。参数数量从275M到3.7B不等，随着模型宽度的增加，深度保持在24层不变。学习率根据模型的大小有所变化，随着模型的增大而减少。基于类似于\citep{mckinzie2025mm1}的经验实验和估算，我们发现这些值在我们的设置中是有效的。训练使用完全解耦的AdamW优化器，动量值为$\beta_1=0.9$，$\beta_2=0.95$，权重衰减为$1\text{e}{-4}$。批量大小设置为2k样本，考虑到1k的上下文长度，这相当于2M个token。梯度裁剪设置为1.0，最大预热持续时间为5k次迭代，针对较短的训练运行做了调整：对于在1k–4k和5k–15k步之间训练的模型，分别采用1k和2.5k的预热步数。对于MoEs，我们发现较长的预热显著提高了效果，因此我们为所有低于20k步的训练都采用了2.5k的预热。我们使用常数学习率调度，并在训练的最后20\%进行降温，按反平方根调度逐步减小至零。对于视觉处理，图像输入被划分为$(14,14)$的patch，增强方式包括随机调整大小裁剪（将图像调整为224px，缩放范围为[0.4, 1.0]）和随机水平翻转，概率为0.5。我们在交替混合的图像字幕和文本数据集上训练我们的模型\Cref{tab:pretraining_datasets}。

对于晚期融合模型，我们发现对于视觉编码器使用较小的学习率显著提高了性能\Cref{tab:late_scaler_scratch}，而当编码器和解码器都被初始化时（\Cref{sec:app_init_early_late}），我们发现冻结视觉编码器效果最佳\Cref{tab:late_scaler_init}。

\begin{table}[htb]
    \begin{center}
        \centering
        \setlength{\tabcolsep}{14pt}
        \resizebox{\linewidth}{!}{
        \begin{tabular}{l c c c c c c}
            \toprule
            \textbf{Early-fusion} \\
            \midrule
            Params &  275M & 468M & 932M  & 1.63B & 2.28B & 3.35B \\
            width & 800 & 1088 & 1632 & 2208 & 2624 & 3232\\
            depth & \multicolumn{6}{c}{24} \\
            Learning rate & 1.5e-3 & 1.5e-3 & 5e-4 & 4.2e-4 & 4e-4 & 3.5e-4 \\
            \midrule
            \textbf{Late-fusion} \\
            \midrule
            Params &  289M & 494M & 1B  & 1.75B & 2.43B & 3.7B \\
            vision encoder width & 384 & 512 & 768 & 1024 & 1184 & 1536 \\
            vision encoder depth & \multicolumn{6}{c}{24} \\
            width & 768 & 1024 & 1536 & 2048 & 2464 & 3072\\
            depth & \multicolumn{6}{c}{24} \\
            Learning rate & 1.5e-3 & 1.5e-3 & 5e-4 & 4.2e-4 & 3.8e-4 & 3.3e-4 \\
            \midrule
            \textbf{Early-fusion MoEs} \\
            \midrule
            Active Params &  275M & 468M & 932M  & 1.63B & 2.28B & 3.35B \\
            width & 800 & 1088 & 1632 & 2208 & 2624 & 3232\\
            depth & \multicolumn{6}{c}{24} \\
            Learning rate & 1.5e-3 & 1.5e-3 & 5e-4 & 4.2e-4 & 4e-4 & 3.5e-4 \\
            \midrule
            Training tokens & \multicolumn{6}{c}{2.5B-600B} \\
            Optimizer & \multicolumn{6}{c}{Fully decoupled AdamW~\citep{loshchilov2017decoupled}} \\
            Optimizer Momentum & \multicolumn{6}{c}{$\beta_1=0.9 ,\beta_2=0.95$} \\
            Minimum Learning rate & \multicolumn{6}{c}{0} \\
            Weight decay & \multicolumn{6}{c}{1e-4} \\
            Batch size & \multicolumn{6}{c}{2k} \\
            Patch size & \multicolumn{6}{c}{(14, 14)} \\
            Gradient clipping & \multicolumn{6}{c}{1.0} \\
            MAximum Warmup iterations & \multicolumn{6}{c}{5k} \\
            Augmentations: \\
            \quad {\tt RandomResizedCrop} \\
            \qquad {\tt size} & \multicolumn{6}{c}{224px} \\
            \qquad {\tt scale} & \multicolumn{6}{c}{[0.4, 1.0]} \\
            \quad {\tt RandomHorizontalFlip} & \multicolumn{6}{c}{$p=0.5$} \\
            \bottomrule
        \end{tabular}}
    \end{center}
    \caption{\textbf{预训练超参数} 我们详细说明了用于预训练不同模型配置以推导规模规律的超参数。}
    \label{tab:scaling_laws_hparams}
    \end{table}

\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt}
    \renewcommand{\arraystretch}{1}
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lccccc}
        Vision encoder & Interleaved & Image-Caption & Text  & AVG & AVG (SFT)  \\
        lr scaler & (CE) & (CE) & (CE) & (CE) & (Acc) \\
        \shline
        1 & 2.521 & 2.15 & 2.867 &  2.513 & 43.49 \\
        0.1 & 2.502 & 2.066 & 2.862 &  2.477 & 52.27\\
        0.01 & 2.502 & 2.066 & 2.859 &  2.476 & 53.76\\
        0.001 & 2.513 & 2.066 & 2.857 &  2.479 & -- \\
        0 (frozen) & 2.504 & 2.061 & 2.856 & 2.474 & 54.14 \\
        \bottomrule
    \end{tabular}
    }
    \caption{\textbf{视觉编码器缩放器。} 在使用预训练模型初始化后融合模型时，冻结视觉编码器效果最佳。}
    \label{tab:late_scaler_init}
\end{table}

\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt}
    \renewcommand{\arraystretch}{1}
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lccccc}
        Vision encoder & Interleaved & Image-Caption & Text  & AVG & AVG (SFT)  \\
        lr scaler & (CE) & (CE) & (CE) & (CE) & (Acc) \\
        \shline
        0.1 & 2.674 & 2.219 & 3.072   & 2.655 & 34.84 \\
        0.01 & 2.672 & 2.197 & 3.071  & 2.647 & 38.77 \\
        0.001 & 2.674 & 2.218 & 3.073 & 2.655 & 38.46 \\
        \bottomrule
    \end{tabular}
    }
    \caption{\textbf{视觉编码器缩放器。} 当从头开始训练后融合模型时，降低视觉编码器的学习率效果更佳。}
    \label{tab:late_scaler_scratch}
\end{table}

\input{figs/late_vs_early_equal_tokens}

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_late_datatype_sameflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
         \input{graphs/early_late/early_late_datatype_sameflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
         \input{graphs/early_late/early_vs_late_datatype_sameflops_dclm}
    \end{subfigure}

    \vspace{0.3cm}
    \caption{\textbf{早期与晚期融合：改变训练混合。} 我们变化训练混合并绘制最终训练损失图。随着交织文档比例的增加，早期融合模型表现更好。早期和晚期融合分别具有1.63B和1.75B个参数。}
    \label{fig:early_vs_late_datatype_sameflops}
\end{figure*}
\section{晚期融合与早期融合}
\label{app:late_vs_early}
本节提供了早期融合和晚期融合模型的额外比较。

\subsection{FLOPs的规模} \Cref{fig:early_vs_late_scaledata_main} 比较了在扩大FLOPs时，早期融合与晚期融合模型的表现。具体来说，对于每个模型大小，我们使用不同数量的训练标记训练多个模型。两种方法之间的性能差距主要是由于模型大小的增加，而不是训练标记数量的增加而减小的。尽管差距在减小，但在我们训练的所有模型中，早期融合始终优于晚期融合。
\subsection{改变训练数据混合方式}  
我们分析了随着训练数据混合方式的变化，早期融合模型与晚期融合模型之间的性能差距如何变化。如 \Cref{fig:early_vs_late_textratio} 和 \Cref{fig:early_vs_late_datatype_sameflops} 所示，在固定模型规模的情况下，增加文本与交错数据的比例有利于早期融合。有趣的是，对于其他类型的数据，这种差距基本保持不变。我们还观察到不同数据类型之间存在干扰效应。具体而言，增加交错数据的数量会对图像标题的性能产生负面影响，反之亦然。此外，增加纯文本数据的比例会略微提升交错数据的性能，但会加剧图像标题的损失。总体而言，我们发现纯文本数据与交错数据在不同配置下存在相关性。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_textratio_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_textratio_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_textratio_dclm}
    \end{subfigure}

    \vspace{0.3cm}
    \caption{\textbf{早期融合 vs 晚期融合：改变训练混合数据中仅文本数据的比例（isoFLOPs）。} 我们改变仅文本数据的比例，并绘制最终训练损失。随着文本数据比例的增加，早期融合模型的优势差距也随之扩大。早期融合模型具有 1.63B 参数，而晚期融合模型具有 1.75B 参数。}
    \label{fig:early_vs_late_textratio}
\end{figure*}

\input{figs/early_vs_late_imageres}
\subsection{图像分辨率的缩放有利于早期融合}

我们研究了在不同图像分辨率下两种架构的表现。我们将早期和晚期融合的模型参数分别固定为1.63B和1.75B。所有模型训练了100K步或200B个token。由于补丁大小保持不变，分辨率的增加会导致更多的视觉token。对于所有分辨率，我们保持相同数量的文本token。正如\Cref{fig:early_vs_late_imageres}所示，早期融合模型在所有分辨率下始终优于晚期融合模型，特别是在多模态数据方面，且随着分辨率的提高，性能差距进一步扩大。此外，我们观察到，随着分辨率的增加，文本和交错数据的损失也会增加。

\vspace{1cm}
\subsection{在匹配后融合模型大小时，早融合始终表现更优}
\input{figs/early_vs_late_datatype_isoparams}

本节中，我们将具有不同配置的早融合模型与后融合模型进行比较。具体而言，我们训练了在总参数量（Params）、文本模型大小（Text）和计算量（FLOPs）上与后融合模型相匹配的早融合模型，假设采用 45-45-10 的训练混合比例。如 \Cref{fig:early_vs_late_datatype_isoparams} 所示，当以总参数量归一化时，早融合始终优于后融合，其次是在计算量归一化的情况下。当匹配文本模型大小时，在较高比例的交错数据下，早融合的性能更佳。
\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}\subsection{不同的后期融合配置}
我们研究在不同的后期融合配置下，这种扩展方式如何变化。与主文中同时等比例扩展视觉模型和文本模型不同，我们固定视觉编码器的规模为 300M，仅扩展文本模型。 \Cref{fig:early_vs_late_scalellmdata_dclm} 显示，当模型规模较小时，后期融合模型的表现落后，但随着文本模型的扩展，这一差距显著缩小。这表明，将更多参数分配给共享组件更具优势，进一步支持了选择早期融合模型的理由。

\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=4,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}

\addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合 vs 晚期融合：在固定视觉编码器大小的同时扩展训练 FLOPs。}我们在扩展训练标记数量和模型规模的同时，比较了早期融合模型和晚期融合模型。对于晚期融合模型，我们固定视觉编码器的大小（300M），并扩展文本模型（250M、834M、2B、3B）。随着文本模型规模的扩展，早期融合与晚期融合之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}
\subsection{从 LLM 和 CLIP 初始化}
\label{sec:app_init_early_late}

我们研究了晚期融合和早期融合模型均从预训练模型初始化的情形，具体来说，晚期融合采用了 DCLM-1B \citep{li2024datacomp} 和 CLIP-ViT-L \citep{radford2021learning} 进行初始化。有趣的是，\Cref{fig:early_vs_late_init_scaledata} 表明，对于文本和交错的多模态文档，经过较长时间训练后，早期融合可以达到与晚期融合相当的性能。然而，在图像字幕数据上缩小差距仍然更具挑战性。值得注意的是，在考虑包括预训练模型在内的整体训练成本时，早期融合需要显著更长的训练时间，以补偿视觉编码器的预训练开销。

\input{figs/early_vs_late_init_scaledata}
\section{尺度定律}
\label{app:scaling_laws}

\subsection{拟合 \(L = F(N, D)\)}
根据 \citep{hoffmann2022training}，我们确定最小化以下目标函数的参数，该目标函数在所有运行 \(i\) 上进行最小化：
\begin{equation}
\footnotesize
    \min_{a,b,e,\alpha,\beta} \sum_{i} \text{Huber}_\delta \left( \text{LSE} \left( a - \alpha \log N_i, b - \beta \log D_i, e \right) - \log L_i \right),
\end{equation}
我们在不同的初始化范围内执行此优化，并选择在所有初始化中实现最低损失的参数。具体来说，我们的网格搜索涵盖了 \(\{0, 0.5, 2.5\}\) 的 \(\alpha\) 和 \(\beta\)，\(\{0, 5, 10, ..., 30\}\) 的 \(a\) 和 \(b\)，以及 \(\{-1, -0.5, 1, 0.5\}\) 的 \(e\)。我们使用 L-BFGS 算法，设置 \(\delta=1e-3\)。
\subsection{拟合 \(N \propto C^a\), \(D \propto C^b\) 和 \(D \propto N^d\)}
尽管这些方程对早期融合模型有封闭解 \citep{hoffmann2022training}，该解可以从 \Cref{eq:scaling_laws} 推导出，但对于晚期融合模型，若未指定视觉编码器或文本模型的大小，则无法得到封闭解。为了确保公平比较，我们通过在对数空间中执行线性回归，推导出这两个模型的方程。我们发现回归结果与通过封闭形式推导得到的系数非常接近 \Cref{tab:scaling_laws_closed_form}。例如，为了推导 \(N = K_aC^a\)，给定一个 FLOP 预算 \(C\) 和一组线性间隔的令牌 \(D_i\)，范围从 10B 到 600B，我们为每个 \(D_i\) 计算模型大小 \(N_i = \frac{C}{6D}\) 用于早期融合，而对于晚期融合，计算式为 \(N_i = \frac{C}{6D}+0.483*N_v\)（对于 45-45-10 混合，\(D_v=0.544D\)，因此 \(C=6D(0.544N_v+N_t)\)）。然后我们应用 \Cref{eq:scaling_laws} 来获得每个模型大小的损失，并选择具有最小损失的 \(N\)。我们对所有与我们的实验相关的 FLOP 值重复此过程，得到一组点 \((C, N_{opt})\)，用于回归 \(a\) 和 \(K_a\)。我们采用类似的程序来找到 \(b\) 和 \(d\)。对于晚期融合模型，我们回归一个线性模型来确定给定 \(N\) 的 \(N_v\)。值得注意的是，尽管我们对晚期融合模型保持固定的宽度比，但这种方法更为准确，因为嵌入层防止了文本和视觉模型大小之间严格固定的比率。我们在 \Cref{fig:scaling_laws_closed_form_early_late} 中展示了回归结果。

\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt}
    \renewcommand{\arraystretch}{1}
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lcccccccc}
        Model & $a$ & $b$ & $d$ & $n$ & $dn$  \\
        \midrule
        Closed form  & 0.52649 & 0.47351 & 0.89938 &  1.11188 & -0.05298  \\
        Regression & 0.52391 & 0.47534 & 0.90052 & 1.10224 & -0.04933  \\
        \bottomrule
    \end{tabular}
    }
    \caption{\textbf{早期融合的缩放律参数。} 通过回归推导缩放律系数所得结果与使用闭式解所得到的结果非常接近。}
    \label{tab:scaling_laws_closed_form}
\end{table}
\subsection{拟合 \(L \propto C^c\)}

为了确定最终模型损失与计算预算 \(C\) 之间的关系，我们首先对对应于相同模型规模的点进行插值，并计算包含所有运行在每个 FLOP 下所达到的最小损失的凸包。这产生了一个从 FLOPs 到最低损失的连续映射。我们考虑一系列 FLOPs，排除非常小的值（$\leq 3e^{19}$），并构建一个关于线性间隔的计算量 \(C\) 的 \((C, L)\) 数据集。利用这些数据，我们在对数空间中找到 \(L\) 与 \(C\) 之间的线性关系，并推导出指数 \(c\)。我们在 \Cref{fig:scaling_laws_early_late_moe} 中对结果进行了可视化。

\begin{figure}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{1\linewidth}

\begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/early/early_scalinglaws_params_vs_flops_avg_ap3}
    \end{subfigure}
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/late/late_scalinglaws_params_vs_flops_avg_ap3}
    \end{subfigure}

    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/early/early_scalinglaws_tokens_vs_flops_avg_ap3}
    \end{subfigure}
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/late/late_scalinglaws_tokens_vs_flops_avg_ap3}
    \end{subfigure}

    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/early/early_scalinglaws_tokens_to_params_vs_flops_avg_ap3}
    \end{subfigure}
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/late/late_scalinglaws_tokens_to_params_vs_flops_avg_ap3}
    \end{subfigure}

\end{subfigure}
    \caption{\textbf{尺度定律系数的回归结果。} 我们对尺度系数的估计接近闭式解。}
    \label{fig:scaling_laws_closed_form_early_late}
\end{figure}

\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/pred_loss_vs_loss_early}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/pred_loss_vs_loss_late}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/pred_loss_vs_loss_moe}
    \end{subfigure}
    \caption{\textbf{观察到的损失与预测的损失.} 我们展示了通过我们的尺度定律 (\Cref{eq:scaling_laws}) 预测的损失与每次运行实际达到的损失。}
    \label{fig:observed_vs_predicted_loss}
\end{figure*}
\subsection{不同目标数据类型的缩放规律}
在\Cref{fig:scaling_laws_early_late_moe_getty_obelics_dclm}中，我们推导了不同目标数据类型的缩放规律。通常，我们观察到模型在图像标注任务上的学习速度快于交错数据任务，如通过较高的缩放指数绝对值所示（例如，0.062与0.046），尽管在标注和交错数据上使用了相同的数据比例（各占45\%）。此外，我们发现模型在仅文本数据上的学习速度较慢，这可能是由于仅文本数据量较少（10\%）。在不同的模型配置下，我们发现早期融合在图像标注任务上与后期融合的缩放规律相似，但其乘法常数较低（49.99与47.97）。对于MoE模型，尽管学习速度较快，但呈现出较高的乘法常数。在文本和交错数据上，早期融合和后期融合模型的缩放规律相似，且取得了相似的性能。然而，MoE模型展现了更好的整体性能，尽管学习速度略慢。
\subsection{不同训练混合的缩放规律}

我们研究了在修改训练混合时，缩放规律如何变化。具体来说，我们改变了图像描述、交替混合和仅文本数据的比例，并在\Cref{fig:app_early_scaleflops_data_mixtures}中报告了结果。总体来看，我们观察到相似的缩放趋势，只有缩放系数发生了轻微变化。通过进一步分析，我们发现，当训练混合中某种数据类型的比例增加时，其缩放指数也相应增加。例如，将图像描述的比例从30\%提高到40\%，其指数的绝对值从0.056增加到0.061。然而，对于仅文本数据，当其在训练混合中的比例变化时，我们并未观察到缩放系数的显著变化。

\begin{wrapfigure}{r}{0.4\textwidth}
        \vspace{-4mm}
        \centering
        \captionsetup{type=figure}
        \begin{subfigure}[t]{\linewidth}
            \includegraphics[width=1.0\textwidth]{assets/moes/specialization/model1088/modality_specialization_1088_150_across_layers.pdf}
        \end{subfigure}

        \caption{\textbf{模态特定的专门化。} 我们可视化了专家在文本和图像模态上的专门化情况。模型在 Obelics 上进行评估。}
        \label{fig:app_moes_specialization}
\end{wrapfigure}
\subsection{缩放规律评估与敏感性分析}

对于每个模型大小和训练令牌数，我们根据\Cref{eq:scaling_laws}中估计的函数形式计算损失，并将其与我们实验中实际获得的损失进行比较。我们在\Cref{fig:observed_vs_predicted_loss}中可视化这些点，展示了我们的估计非常准确，特别是在较低损失值下，因此在更大的FLOPs下尤为如此。此外，我们还通过自助法进行了敏感性分析。具体而言，我们进行有放回抽样，抽取\( P \)个点（\( P \)等于训练的模型总数），并重新估计缩放规律系数。这个过程重复进行100次，我们报告每个系数的平均值和标准差。\Cref{tab:scaling_laws_sensitivity}显示，相较于\(\alpha\)，我们对\(\beta\)的估计更为精确，这主要是因为相对于用以推导缩放规律的不同令牌数，模型大小的数量较少。

\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt}
    \renewcommand{\arraystretch}{1}
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lcccccccc}
        Model & E & $\alpha$ & $\beta$ & a & b  & d\\
        \midrule
        Avg  & 1.80922 & 0.29842 & 0.33209 & 0.54302  & 0.48301 &  0.92375 \\
        Std & 0.33811 & 0.10101 & 0.02892 & 0.08813 & 0.05787 & 0.23296 \\
        \bottomrule
    \end{tabular}
    }
    \caption{\textbf{缩放规律的敏感性。} 我们报告了经过 100 次迭代的自助法后的均值和标准差。}
    \label{tab:scaling_laws_sensitivity}
\end{table}
\subsection{\edit{稀疏NMMs的缩放规律。}}
\label{app:scaling_laws_moes}

与密集模型类似，我们拟合了一个参数化的损失函数（\Cref{eq:scaling_laws}），以根据参数数量和训练标记预测稀疏NMMs的损失，将总参数数量替换为活跃参数的数量。在推导MoEs的缩放规律时，通常会纳入稀疏性\citep{wangscalingmoe,krajewski2024scalingmoe,abnar2025parameters}，但我们专注于推导特定于我们MoE设置中使用的稀疏性水平的缩放规律。这产生的系数隐式地依赖于稀疏配置。

我们还实验了\citep{abnar2025parameters}提出的基于稀疏性的缩放规律公式，并观察到一致的趋势（\Cref{tab:moes_coeffs}）。特别是，与训练标记（$\beta$）相关的模型大小（$N$）的指数显著大于训练标记，强调了在稀疏架构中扩大模型规模的重要性。此外，我们还观察到，控制活跃参数缩放的项分解为两个组成部分。

\input{tables/scaling_laws_coeffs_moes}
\section{专家混合模型与模态特定的专门化}
\label{app:moes}

我们研究了MoE架构中的多模态专门化。我们计算了一个专门化得分，该得分为分配给每个专家的文本/图像标记数与均匀分配（$1/E$）之间的平均差异。此外，我们可视化了每个专家在各层之间分配的标准化文本和图像标记数。\Cref{fig:app_moes_specialization} 显示了明显的模态特定专家，尤其是在早期层。进一步地，专门化得分随着层数的增加而减小，但在最后几层再次上升。这表明，与中间层相比，早期和最后几层需要更多的模态专门化。此外，我们观察到几个文本和图像模态共享的专家，这在硬路由或预定义的模态特定专家中并不存在。

\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_avg}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_avg}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_avg_big}
    \end{subfigure}

\makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=6,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]

            \addlegendimage{legend late_0_2b style}
            \addlegendentry{0.289B}
            \addlegendimage{legend late_0_4b style}
            \addlegendentry{0.494B}
            \addlegendimage{legend late_0_9b style}
            \addlegendentry{1B}
            \addlegendimage{legend late style}
            \addlegendentry{1.748B}
            \addlegendimage{legend late_2_2b style}
            \addlegendentry{2.430B}
            \addlegendimage{legend late_3_3b style}
            \addlegendentry{3.714B}

            \addlegendimage{legend early_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend early_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend early_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend early style}
            \addlegendentry{1.627B}
            \addlegendimage{legend early_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend early_3_3b style}
            \addlegendentry{3.354B}

            \addlegendimage{legend moe_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend moe_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend moe_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend moe style}
            \addlegendentry{1.627B}
            \addlegendimage{legend moe_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend moe_3_3b style}
            \addlegendentry{3.354B}

            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4cm}

    \caption{\textbf{原生多模态模型的尺度法则。} 从左到右：后融合（密集型）、早融合（密集型）和早融合 MoEs。所有模型的尺度指数非常接近。然而，MoEs 导致总体较低的损失（较小的乘法常数），并且需要更长的时间才能饱和。}
    \label{fig:scaling_laws_early_late_moe}
\end{figure*}

\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_dclm}
    \end{subfigure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_dclm}
    \end{subfigure}

\begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_dclm}
    \end{subfigure}

\makebox[0.9\linewidth]{
        \begin{tikzpicture}
            \begin{axis}[
                hide axis,
                xmin=0, xmax=0.5, ymin=0, ymax=1,
                legend columns=6,
                legend style={
                    at={(0.5, 1)},
                    anchor=north,
                    /tikz/every even column/.append style={column sep=0.2cm},
                    scale=0.5,
                    cells={align=left}, font=\footnotesize,
                },
            ]

            \addlegendimage{legend late_0_2b style}
            \addlegendentry{0.289B}
            \addlegendimage{legend late_0_4b style}
            \addlegendentry{0.494B}
            \addlegendimage{legend late_0_9b style}
            \addlegendentry{1B}
            \addlegendimage{legend late style}
            \addlegendentry{1.748B}
            \addlegendimage{legend late_2_2b style}
            \addlegendentry{2.430B}
            \addlegendimage{legend late_3_3b style}
            \addlegendentry{3.714B}

            \addlegendimage{legend early_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend early_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend early_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend early style}
            \addlegendentry{1.627B}
            \addlegendimage{legend early_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend early_3_3b style}
            \addlegendentry{3.354B}

            \addlegendimage{legend moe_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend moe_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend moe_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend moe style}
            \addlegendentry{1.627B}
            \addlegendimage{legend moe_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend moe_3_3b style}
            \addlegendentry{3.354B}

            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4cm}
    \caption{\textbf{原生多模态模型的规模法则。} 从上到下：后融合（密集型）、前融合（密集型）和前融合MoEs。 从左到右：图像-标题验证集上的交叉熵、交错数据和仅文本数据。}
    \label{fig:scaling_laws_early_late_moe_getty_obelics_dclm}
\end{figure*}

\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_dclm}
    \end{subfigure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_getty_40_20_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_obelics_40_20_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_dclm_40_20_40}
    \end{subfigure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_getty_30_30_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_obelics_30_30_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_dclm_30_30_40}
    \end{subfigure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_getty_20_40_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_obelics_20_40_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_dclm_20_40_40}
    \end{subfigure}

    \makebox[0.9\linewidth]{
    \begin{tikzpicture}
        \node[anchor=north] (legend) at (0\linewidth, 0) {
            \begin{axis}[
                        hide axis,
                        xmin=0, xmax=0.5, ymin=0, ymax=1,
                        legend columns=6,
                        legend style={
                            at={(-0.12, -0.025)},
                            anchor=north,
                            /tikz/every even column/.append style={column sep=0.2cm},
                            scale=0.5,
                            cells={align=left}, font=\footnotesize,
                            anchor=center,
                        },
                    ]
                \addlegendimage{legend early_0_2b style}
                \addlegendentry{0.275B}
                \addlegendimage{legend early_0_4b style}
                \addlegendentry{0.464B}
                \addlegendimage{legend early_0_9b style}
                \addlegendentry{0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{2.280B}
                \addlegendimage{legend early_3_3b style}
                \addlegendentry{3.354B}
            \end{axis}
        };
    \end{tikzpicture}
    }
    \vspace{0.5cm}

\caption{\textbf{早期融合原生多模态模型的尺度定律。} 我们在不同的训练混合（图像-字幕交错文本）和FLOPs上的实验结果。我们可视化了三种数据类型上的最终验证损失：HQITP（左）、Obelics（中）和DCLM（右）。}
    \label{fig:app_early_scaleflops_data_mixtures}
\end{figure*}
