[
    {
        "section": "-1",
        "content": "\\pdfoutput=1\n\n\\documentclass[11pt]{article}\n\n\\usepackage[preprint]{acl}\n\n\\usepackage{times}\n\\usepackage{latexsym}\n\n\\usepackage[T1]{fontenc}\n\n\\usepackage[utf8]{inputenc}\n\n\\usepackage{microtype}\n\\usepackage{inconsolata}\n\n\\usepackage{tabularx}\n\\usepackage{graphicx}\n\n\\usepackage{amsmath}\n\\usepackage{multirow}\n\\usepackage{booktabs}\n\\usepackage{makecell}\n\\usepackage[ruled,vlined]{algorithm2e}\n\\usepackage{amsmath, amssymb}\n\\usepackage{subcaption}\n\\usepackage{caption}\n\\usepackage{cleveref}\n\\usepackage[most]{tcolorbox}\n\\usepackage{kotex}\n\\usepackage{hyperref}\n\n\\title{EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance}\n\n\\author{\n \\textbf{Heejae Suh\\textsuperscript{1}},\n \\textbf{Yejin Jeon\\textsuperscript{1}},\n \\textbf{Deokhyung Kang\\textsuperscript{1}},\n \\textbf{Taehee Park\\textsuperscript{1}},\n \\textbf{Yejin Min\\textsuperscript{1}},\n \\textbf{Gary Geunbae Lee\\textsuperscript{1,2}}\n\\\\\n \\textsuperscript{1}Graduate School of Artificial Intelligence, POSTECH,\\\\\n \\textsuperscript{2}Department of Computer Science and Engineering, POSTECH,\n\\\\\n \\texttt{\\{heejaesuh, jeonyj0612, deokhk, taehpark, yeajinmin, gblee\\}@postech.ac.kr}\\\\\n}\n\n",
        "trans_content": "\\pdfoutput=1\n\n\\documentclass[11pt]{article}\n\n\\usepackage[preprint]{acl}\n\n\\usepackage{times}\n\\usepackage{latexsym}\n\n\\usepackage[T1]{fontenc}\n\n\\usepackage[utf8]{inputenc}\n\n\\usepackage{microtype}\n\\usepackage{inconsolata}\n\n\\usepackage{tabularx}\n\\usepackage{graphicx}\n\n\\usepackage{amsmath}\n\\usepackage{multirow}\n\\usepackage{booktabs}\n\\usepackage{makecell}\n\\usepackage[ruled,vlined]{algorithm2e}\n\\usepackage{amsmath, amssymb}\n\\usepackage{subcaption}\n\\usepackage{caption}\n\\usepackage{cleveref}\n\\usepackage[most]{tcolorbox}\n\\usepackage{kotex}\n\\usepackage{hyperref}\n\n\\title{EnSToM：利用熵缩放引导向量增强话题维持的对话系统}\n\n\\author{\n \\textbf{Heejae Suh\\textsuperscript{1}},\n \\textbf{Yejin Jeon\\textsuperscript{1}},\n \\textbf{Deokhyung Kang\\textsuperscript{1}},\n \\textbf{Taehee Park\\textsuperscript{1}},\n \\textbf{Yejin Min\\textsuperscript{1}},\n \\textbf{Gary Geunbae Lee\\textsuperscript{1,2}}\n\\\\\n \\textsuperscript{1}POSTECH人工智能研究生院,\\\\\n \\textsuperscript{2}POSTECH计算机科学与工程系,\n\\\\\n \\texttt{\\{heejaesuh, jeonyj0612, deokhk, taehpark, yeajinmin, gblee\\}@postech.ac.kr}\\\\\n}"
    },
    {
        "section": "0",
        "content": "\\begin{document}\n\\maketitle\n\\begin{abstract}\nSmall large language models (sLLMs) offer the advantage of being lightweight and efficient, which makes them suitable for resource-constrained environments. However, sLLMs often struggle to maintain topic consistency in task-oriented dialogue systems, which is critical for scenarios such as service chatbots. Specifically, it is important to ensure that the model denies off-topic or malicious inputs and adheres to its intended functionality so as to prevent potential misuse and uphold reliability. Towards this, existing activation engineering approaches have been proposed to manipulate internal activations during inference. While these methods are effective in certain scenarios, our preliminary experiments reveal their limitations in ensuring topic adherence. Therefore, to address this, we propose a novel approach termed \\textbf{En}tropy-scaled \\textbf{S}teering vectors for \\textbf{To}pic \\textbf{M}aintenance (EnSToM). EnSToM dynamically adjusts the steering intensity based on input uncertainty, which allows the model to handle off-topic distractors effectively while preserving on-topic accuracy. Our experiments demonstrate that EnSToM achieves significant performance gain with a relatively small data size compared to fine-tuning approaches. By improving topic adherence without compromising efficiency, our approach provides a robust solution for enhancing sLLM-based dialogue systems\\footnote{The source code is available at \\url{https://github.com/linkyouhj/enstom}}.\n\n\\end{abstract}\n\n",
        "trans_content": "\\begin{document}\n\\maketitle\n\\begin{abstract}\n小型大语言模型（sLLMs）具有轻量高效的优势，使其适用于资源受限的环境。然而，sLLMs在任务导向对话系统中常常难以保持话题一致性，这对于像服务聊天机器人这样的场景至关重要。具体而言，确保模型拒绝离题或恶意输入，并遵循其预期功能，以防止潜在的滥用并维持可靠性是十分重要的。为此，已有的激活工程方法被提出，用于在推理过程中操控内部激活。尽管这些方法在某些场景下有效，但我们的初步实验揭示了它们在确保话题一致性方面的局限性。因此，为了解决这一问题，我们提出了一种新方法，称为\\textbf{En}tropy-scaled \\textbf{S}teering vectors for \\textbf{To}pic \\textbf{M}aintenance（EnSToM）。EnSToM根据输入的不确定性动态调整引导强度，从而有效处理离题干扰，同时保持话题的准确性。我们的实验表明，与微调方法相比，EnSToM在相对较小的数据集上实现了显著的性能提升。通过在不影响效率的情况下提高话题一致性，我们的方法为增强基于sLLM的对话系统提供了一个稳健的解决方案\\footnote{源代码可在 \\url{https://github.com/linkyouhj/enstom} 获得}。\n\n\\end{abstract}\n\\end{document}"
    },
    {
        "section": "1",
        "content": "\\section{Introduction}\n\nRecent advances in large language models (LLMs) have enabled the development of sophisticated conversational systems across a wide range of services~\\cite{naveed2024comprehensiveoverviewlargelanguage}. These systems are increasingly being adopted by organizations for applications such as customer support, conversational assitants, and internal process guidance. However, openly available API-based large-scale models often face limitations in terms of compliance with strict data privacy policies and security regulations. Furthermore, large-scale open-source models demand significant computational resources, which results in high operational costs for deployment. In this context, sLLMs have emerged as a practical alternative~\\cite{10.1145/3589334.3645420} by offering lightweight and resource-efficient solutions for production environments. Since these models enable organizations to achieve robust conversational capabilities without the extensive computational costs associated with larger models, they are a compelling choice for a variety of applications.\n\n\\begin{figure}[t]\n\\centering\n  \\includegraphics[width=\\columnwidth]{latex/figures/first.pdf}\n  \\caption{The example above illustrates that bots tend to provide only refusal responses when using vanilla steering to improve on-topic response generation. On the other hand, EnSToM is able to generate more contextually appropriate responses.}\n  \\label{fig:first}\n\\end{figure}\n\nDespite their impressive performance on general tasks, LLMs face challenges when deployed in real-world scenarios that demand consistent maintenance of specific constraints like business contexts, or scenario-driven dialogues \\cite{sreedhar-etal-2024-canttalkaboutthis}. This issue becomes especially pronounced with sLLMs~\\cite{doi:10.1073/pnas.2311878121}, as their limited capacity makes it even harder to ensure scenario consistency over extended user interactions (Figure~\\ref{fig:first}). The inability to maintain a prescribed scenario directly undermines a service chatbot’s intended functionality; if it cannot adhere to a given workflow, policy, or domain rule, it fails to deliver the expected user experience, which potentially leads to misinformation, reduced trustworthiness, and even safety concerns such as inadvertently disclosing sensitive information~\\cite{10.5555/3666122.3667033}. Consequently, the capability of an LLM to reliably uphold scenario constraints and follow specified directives is not merely an enhancement but a necessity in real-world applications.\n\nNumerous alignment techniques have been proposed to address this issue, with two prominent approaches being fine-tuning and prompt engineering. Fine-tuning the model with domain-specific, high-quality data can effectively realign its internal parameters to suit particular constraints. However, this process demands substantial resources in terms of data collection, annotation, and computational cost, which makes it impractical in covering every possible scenario. Meanwhile, prompt engineering techniques offer a more lightweight and less resource-intensive solution. While prompt-based methods have demonstrated efficacy in steering model behavior, their effectiveness often diminishes in complex, nuanced scenarios~\\cite{Patel2023TheLO} where detailed instructions and long-term context-maintenance are required.\n\nIn light of these limitations, there is a clear need for new, more flexible methods that can help LLMs to consistently maintain scenario adherence without incurring the substantial overhead of extensive fine-tuning or relying solely on prompt design.\nTo this end, we propose a novel and lightweight approach termed \\textbf{En}tropy-scaled \\textbf{S}teering vectors for \\textbf{To}pic \\textbf{M}aintenance (EnSToM) based on \\textit{activation addition}, which steers a model’s generation at inference time without altering its parameters. By injecting a carefully derived \\textit{steering vector} into the model’s intermediate activations, we can gently nudge the LLM towards maintaining scenario consistency. However, our preliminary experiment showed that straightforward application of \\textit{activation addition} cause undesired steering even for on-topic inputs, potentially degrading the user experience or interfering with correct responses.\n\nTo address this, we introduce \\textit{entropy-based coefficient scaling} that leverages intrinsic model signals—specifically, layer-wise generation entropy—to differentiate between on-topic and distractor inputs. This is motivated by our key observation that the entropy distribution varies depending on whether the input is on-topic or a distractor. By dynamically adjusting the steering vector’s strength based on this entropy information, our method is able to enforce scenario adherence more diligently for distractor inputs while preserving the model’s natural behavior for on-topic interactions.\n\nThis approach offers a resource-efficient alignment strategy that can enhance existing prompt-based methods without the need for extensive retraining or exhaustive scenario-specific data collection. In this paper, we detail the design of our method, present an in-depth analysis of its performance, and demonstrate its ability to promote scenario adherence while minimizing adverse effects on normal inputs. Our main contributions can therefore be summarized as follows:\n\n\\begin{itemize}\n    \\item We propose \\textbf{EnSToM}, a novel and lightweight \\textit{activation addition}-based method with entropy-based scaling that dynamically adjusts the steering vector’s influence. This ensures robust topic maintenance for distractor input while preserving on-topic accuracy.\n    \\item Experiments on the CantTalkAboutThis dataset show that EnSToM significantly improves topic adherence in task-oriented dialogues.\n    \\item We conduct a comprehensive analysis of entropy patterns in LLMs by investigating layer-wise entropy distributions across on-topic and distractor inputs. Our findings provide key insights into the intrinsic properties of LLMs in different scenarios, which inform the design of entropy-aware steering strategies.\n\\end{itemize}\n",
        "trans_content": "\\section{引言}\n\n近年来，大型语言模型（LLMs）的快速发展推动了各类服务中复杂对话系统的构建~\\cite{naveed2024comprehensiveoverviewlargelanguage}。这些系统正日益被各类组织用于客户支持、对话助手以及内部流程指导等应用。然而，公开可用的基于 API 的大规模模型在数据隐私政策与安全法规方面常常难以完全合规。此外，大规模开源模型对计算资源的需求极高，从而导致部署过程中的运营成本大幅增加。在这种背景下，sLLMs 作为一种轻量级且资源高效的解决方案，逐渐成为实际生产环境中的可行替代方案~\\cite{10.1145/3589334.3645420}。由于这些模型使得组织可以在避免大型模型高昂计算开销的前提下，依然具备稳健的对话能力，因此在多种应用场景中具有极高吸引力。\n\n\\begin{figure}[t]\n\\centering\n  \\includegraphics[width=\\columnwidth]{latex/figures/first.pdf}\n  \\caption{上述示例说明，在使用 vanilla steering 提升主题相关性响应生成时，机器人往往只会给出拒绝类回复。相比之下，EnSToM 能够生成更加符合上下文的回应。}\n  \\label{fig:first}\n\\end{figure}\n\n尽管 LLMs 在通用任务中表现出色，但在需要持续维持特定约束（如业务上下文或情境驱动对话）的真实场景中部署时，仍面临诸多挑战 \\cite{sreedhar-etal-2024-canttalkaboutthis}。这种问题在 sLLMs 中尤为突出~\\cite{doi:10.1073/pnas.2311878121}，因为其容量受限，使得在长时间交互中保持情境一致性更加困难（见图~\\ref{fig:first}）。无法维持预设情境将直接削弱服务型聊天机器人的核心功能；若其无法遵循特定工作流程、政策或领域规则，便无法交付预期的用户体验，这可能导致信息误导、可信度下降，甚至出现泄露敏感信息等安全风险~\\cite{10.5555/3666122.3667033}。因此，LLM 能否可靠地维持情境约束并遵循预设指令，不只是性能的提升，而是其在现实应用中的必要条件。\n\n为了解决该问题，研究者提出了多种对齐技术，其中主要有模型微调与提示工程两类方法。通过高质量、领域特定的数据对模型进行微调，能够有效调整其内部参数以适应特定约束。然而，该过程在数据收集、标注与计算资源方面代价极高，因此难以覆盖所有可能场景。相比之下，提示工程技术是一种更轻量、资源开销较小的方案。尽管基于提示的方法在引导模型行为方面展现了一定效果，但在需要详细指令与长期上下文维护的复杂场景中，其有效性常常会下降~\\cite{Patel2023TheLO}。\n\n鉴于上述限制，亟需开发一种更加灵活的新方法，以便在不依赖大规模微调或仅凭提示设计的情况下，帮助 LLM 持续维持情境一致性。为此，我们提出了一种新颖且轻量级的方法，称为 \\textbf{En}tropy-scaled \\textbf{S}teering vectors for \\textbf{To}pic \\textbf{M}aintenance（EnSToM），该方法基于 \\textit{activation addition}，在推理阶段对模型生成过程进行引导，无需更改其参数。通过向模型的中间激活中注入精心设计的 \\textit{steering vector}，我们可以轻微地引导 LLM 朝向情境一致性的方向。然而，我们的初步实验发现，直接应用 \\textit{activation addition} 会在处理主题相关输入时产生非预期的引导，可能削弱用户体验或干扰正确回复。\n\n为了解决这一问题，我们引入了 \\textit{基于熵的系数缩放} 技术，该技术利用模型内部信号——特别是各层生成熵（layer-wise generation entropy）——来区分主题相关与干扰类输入。这一设计受到我们关键观察结果的启发：输入是否为干扰项会显著影响其熵分布。通过基于熵信息动态调整 steering vector 的强度，我们的方法能够对干扰输入更严格地实施情境控制，同时保留模型对主题相关输入的自然响应能力。\n\n该方法提供了一种资源高效的对齐策略，可在不进行大量重训练或不依赖情境特定数据收集的前提下，增强现有的基于提示的方法。在本文中，我们详细介绍了该方法的设计，深入分析了其性能，并展示其在促进情境一致性的同时，尽可能减少对正常输入的负面影响。我们的主要贡献总结如下：\n\n\\begin{itemize}\n    \\item 我们提出了 \\textbf{EnSToM}，一种新颖且轻量级的 \\textit{activation addition} 方法，结合了基于熵的缩放机制，能够动态调整 steering vector 的影响力，确保对干扰输入进行稳健的主题维护，同时保留主题相关输入的准确性。\n    \\item 在 CantTalkAboutThis 数据集上的实验表明，EnSToM 显著提升了任务导向对话中的主题一致性。\n    \\item 我们通过研究不同输入下的层级熵分布，系统分析了 LLMs 中的熵模式。这些发现揭示了 LLMs 在不同情境下的内在特性，为设计基于熵的引导策略提供了关键见解。\n\\end{itemize}"
    },
    {
        "section": "2+2_1",
        "content": "\\section{Related Work}\n\n\\subsection{Steering Vectors}\n\nSteering vectors~\\cite{DBLP:journals/corr/abs-2308-10248, rimsky-etal-2024-steering} modify hidden states by computing differences between desirable and undesirable responses. As this allows for targeted activation adjustments, steering vectors have been explored for Trojan Activation Attacks~\\cite{10.1145/3627673.3679821}, and behavior alignment without fine-tuning~\\cite{subramani-etal-2022-extracting}. In another domain, \\citet{lee2024programmingrefusalconditionalactivation} leverages conditioning vectors to selectively control model behavior based on input contexts, while \\citet{stickland2024steering} introduces KL-Then-Steer (KTS) training to mitigate performance degradation during steering vector application. Building on these findings, our approach enhances robustness by incorporating internal layer-wise entropy of language models, ensuring consistent distractor accuracy without degrading on-topic performance.\n\n",
        "trans_content": "\\section{相关工作}\n\n\\subsection{引导向量}\n\n引导向量~\\cite{DBLP:journals/corr/abs-2308-10248, rimsky-etal-2024-steering} 通过计算期望响应与不期望响应之间的差异来修改隐藏状态。由于这允许进行有针对性的激活调整， 引导向量已被用于特洛伊激活攻击~\\cite{10.1145/3627673.3679821}，以及在无需微调的情况下进行行为对齐~\\cite{subramani-etal-2022-extracting}。在另一个领域，\\citet{lee2024programmingrefusalconditionalactivation} 利用条件向量根据输入上下文选择性地控制模型行为，而 \\citet{stickland2024steering} 引入了KL-Then-Steer（KTS）训练，旨在减轻引导向量应用过程中性能退化的问题。基于这些研究成果，我们的方法通过结合语言模型的内部层级熵来增强鲁棒性，确保在不降低主题相关性表现的情况下维持一致的干扰项准确性。"
    },
    {
        "section": "2_2",
        "content": "\\subsection{Topic-Following Dialogue System}\n\nTopic adherence in dialogue systems has been explored through various approaches. \\citet{zhan-etal-2021-scope} improved out-of-scope intent detection via pseudo outliers, while \\citet{mu2024llmsfollowsimplerules} introduced the RuLES benchmark to assess rule-following behavior. Instruction fine-tuning for safety was explored in Llama Guard~\\cite{inan2023llamaguardllmbasedinputoutput}, whereas \\citet{xu-etal-2024-safedecoding} and \\citet{xie-etal-2024-gradsafe} proposed decoding and gradient-based alignment strategies. Moreover, \\citet{sreedhar-etal-2024-canttalkaboutthis} curated the CantTalkAboutThis dataset for evaluating on-topic dialogue and distractor handling. We leverage this dataset to improve both distractor and on-topic query accuracy.\n\n\\begin{figure*}[t]\n\\centering\n  \\includegraphics[width=2\\columnwidth]{latex/figures/MainFigure.pdf}\n  \\caption{Overall process. After extracting steering vectors and applying entropy-based coefficient scaling, responses are generated using the entropy-based scaled steering vectors to maintain on-topic accuracy.}\n  \\label{fig:main}\n\\end{figure*}\n\n",
        "trans_content": "\\subsection{主题跟随对话系统}\n\n对话系统中的主题遵循性已通过多种方法进行了探索。 \\citet{zhan-etal-2021-scope} 通过伪异常点提升了越界意图检测性能，而 \\citet{mu2024llmsfollowsimplerules} 提出了 RuLES 基准，用于评估规则遵循行为。Llama Guard~\\cite{inan2023llamaguardllmbasedinputoutput} 探讨了用于安全性的指令微调，而 \\citet{xu-etal-2024-safedecoding} 和 \\citet{xie-etal-2024-gradsafe} 分别提出了基于解码和梯度的对齐策略。此外，\\citet{sreedhar-etal-2024-canttalkaboutthis} 构建了 CantTalkAboutThis 数据集，用于评估主题相关对话及干扰项处理能力。我们利用该数据集提升干扰项与主题相关查询的准确性。\n\n\\begin{figure*}[t]\n\\centering\n  \\includegraphics[width=2\\columnwidth]{latex/figures/MainFigure.pdf}\n  \\caption{整体流程。在提取引导向量并应用基于熵的系数缩放后，使用熵缩放后的引导向量生成响应，以保持主题相关的准确性。}\n  \\label{fig:main}\n\\end{figure*}"
    },
    {
        "section": "3",
        "content": "\\section{Preliminaries}\n\nThis section provides an overview of the fundamental concepts and methodologies that form the basis of our approach towards maintaining topic consistency in task-oriented dialogues. It also includes a brief description of the source dataset and the methodology for extracting steering vectors.\n\n",
        "trans_content": "\\section{预备知识}\n\n本节概述了构成我们在任务导向对话中保持主题一致性方法基础的基本概念和方法论。它还包括对源数据集的简要描述以及提取引导向量的方法。"
    },
    {
        "section": "3_1",
        "content": "\\subsection{Topic Maintenance in Dialogue System}\nThe CantTalkAboutThis~\\cite{sreedhar-etal-2024-canttalkaboutthis} source dataset is designed to evaluate how language models handle off-topic queries in multi-domain dialogues. Each data sample is represented as \\( X = \\{I, D, u\\} \\), where \\( I \\) denotes the system instruction, \\( D \\) represents the dialogue history, and \\( u \\) is the user input query, which can be either on-topic (\\( o \\)) or off-topic (\\( d \\)). This structure allows for the systematic analysis of a model's ability in maintaining task-oriented scenarios with strict adherence to predefined topics.\n\n",
        "trans_content": "\\subsection{对话系统中的话题维持}  \nCantTalkAboutThis~\\cite{sreedhar-etal-2024-canttalkaboutthis} 源数据集旨在评估语言模型在多领域对话中处理离题查询的能力。每条数据样本表示为 \\( X = \\{I, D, u\\} \\)，其中 \\( I \\) 表示系统指令，\\( D \\) 表示对话历史，\\( u \\) 是用户输入查询，该查询可以是相关的（\\( o \\)）或离题的（\\( d \\)）。这种结构使得可以系统性地分析模型在严格遵循预定义话题的任务导向场景中维持话题的能力。"
    },
    {
        "section": "3_2",
        "content": "\\subsection{Steering Vector}\\label{steering_vector_concept}\nSteering vectors~\\cite{rimsky-etal-2024-steering} guide the model's responses toward desired behaviors without requiring additional training. The core concept involves leveraging differences in the hidden representations of a language model at a specific layer to align its outputs with predefined scenarios. Specifically, for any input pair \\( q_i = \\{q^p_i, q^n_i\\} \\) (where \\( p \\) denotes desired behavior and \\( n \\) denotes undesired behavior), we compute the hidden representations \\( h^{(l)} \\) at a designated layer \\( l \\) through a forward pass \\( f(\\cdot) \\). An example of such a pair is illustrated in the upper half of Figure~\\ref{fig:main}. Additionally, the representations \\( h_p^{(l)} \\) and \\( h_n^{(l)} \\) correspond to the activations for the desired behavioral completion letter (\\( c_p \\)) and the undesired behavioral completion letter (\\( c_n \\)), respectively. Note that the completion letter represents the designated choice of either A or B in a multiple-choice response format. The steering vector for \\( q_i \\) can then be computed as:\n\\[\nv_s^i = h_p^{(l)} - h_n^{(l)}.\n\\]\nGiven \\( k \\) pairs in the dataset, the final steering vector \\( v \\) is computed by averaging the individual steering vectors. Subsequently, these vectors are normalized to ensure consistent scaling across behaviors. Formally, let the norm of each \\( v_s^i \\) be denoted as \\( \\|v_s^i\\| \\), and let the average norm across all \\( k \\) vectors be \\( \\bar{\\|v\\|} = \\frac{1}{k} \\sum_{i=1}^k \\|v_s^i\\| \\). The normalized steering vector is obtained as \\(\\text{norm}(v_s^i) = v_s^i \\cdot \\frac{\\bar{\\|v\\|}}{\\|v_s^i\\|}\\). The process of computing the final steering vector \\(v\\) is summarized as follows:\n\\[\nv =  \\frac{1}{k} \\sum_{i=1}^k \\text{norm}\\left(v_s^i \\right).\n\\]\n\nThis aggregated vector \\( v \\) is applied to adjust the model's activations during inference, which nudges its behavior toward the desired direction. Steering vectors thus offer an efficient mechanism to enforce topic consistency without requiring additional fine-tuning or training.\n\n\\begin{table}[t]\n\\centering\n<PLACEHOLDER_NEWCOMMAND_0>\n\\setlength{\\tabcolsep}{8pt}\n\\begin{tabular}{@{}lcc@{}}\n\\toprule\n\\textbf{Method}            & \\textbf{Distractor} & \\textbf{On-topic} \\\\\n\\midrule\n\\textit{Prompt Only}                & 0.28                & 0.94              \\\\\n\\midrule\n\\textit{Vanilla Steering}                & 0.80 (+0.52)        & 0.70 (-0.24)      \\\\ \\bottomrule\n\\end{tabular}\n\\caption{Distractor and on-topic accuracies for different methods. Distractor accuracy measures the model's ability to refuse distractor inputs, while on-topic accuracy reflects its ability to provide engaging responses to on-topic inputs. For metric details, see section~\\ref{para:metric}.}\n\\label{tab:preliminary}\n\\end{table}\n\n",
        "trans_content": "\\subsection{引导向量}\\label{steering_vector_concept}\n引导向量~\\cite{rimsky-etal-2024-steering} 引导模型的响应朝着期望的行为方向发展，而无需额外的训练。其核心概念是利用语言模型在特定层次上的隐藏表示差异，将其输出与预定义的场景对齐。具体而言，对于任何输入对 \\( q_i = \\{q^p_i, q^n_i\\} \\)（其中 \\( p \\) 表示期望的行为，\\( n \\) 表示不期望的行为），我们通过前向传播 \\( f(\\cdot) \\) 计算在指定层 \\( l \\) 上的隐藏表示 \\( h^{(l)} \\)。这种输入对的一个例子在图~\\ref{fig:main}的上半部分中有所示例。此外，表示 \\( h_p^{(l)} \\) 和 \\( h_n^{(l)} \\) 分别对应于期望行为完成字母（\\( c_p \\)）和不期望行为完成字母（\\( c_n \\)）的激活。请注意，完成字母表示多选响应格式中指定的A或B的选择。然后，\\( q_i \\) 的引导向量可以计算为：\n\\[\nv_s^i = h_p^{(l)} - h_n^{(l)}.\n\\]\n给定数据集中的 \\( k \\) 对，最终的引导向量 \\( v \\) 通过对各个引导向量进行平均来计算。随后，这些向量被归一化，以确保在行为之间具有一致的尺度。形式上，令每个 \\( v_s^i \\) 的范数表示为 \\( \\|v_s^i\\| \\)，并且令所有 \\( k \\) 个向量的平均范数为 \\( \\bar{\\|v\\|} = \\frac{1}{k} \\sum_{i=1}^k \\|v_s^i\\| \\)。归一化的引导向量通过 \\(\\text{norm}(v_s^i) = v_s^i \\cdot \\frac{\\bar{\\|v\\|}}{\\|v_s^i\\|}\\) 得到。计算最终引导向量 \\(v\\) 的过程总结如下：\n\\[\nv =  \\frac{1}{k} \\sum_{i=1}^k \\text{norm}\\left(v_s^i \\right).\n\\]\n\n该聚合向量 \\( v \\) 在推理过程中用于调整模型的激活，从而将其行为推向期望的方向。因此，引导向量提供了一种有效的机制，在不需要额外微调或训练的情况下强制执行话题一致性。\n\n\\begin{table}[t]\n\\centering\n<PLACEHOLDER_NEWCOMMAND_0>\n\\setlength{\\tabcolsep}{8pt}\n\\begin{tabular}{@{}lcc@{}}\n\\toprule\n\\textbf{方法}            & \\textbf{干扰项} & \\textbf{主题相关} \\\\\n\\midrule\n\\textit{仅提示}                & 0.28                & 0.94              \\\\\n\\midrule\n\\textit{普通引导}                & 0.80 (+0.52)        & 0.70 (-0.24)      \\\\ \\bottomrule\n\\end{tabular}\n\\caption{不同方法的干扰项和主题相关准确率。干扰项准确率衡量模型拒绝干扰项输入的能力，而主题相关准确率反映其提供与主题相关的响应的能力。有关度量的详细信息，请参见节~\\ref{para:metric}。}\n\\label{tab:preliminary}\n\\end{table}"
    },
    {
        "section": "4",
        "content": "\\section{Proposed Methodology}\nAccording to preliminary experiments (Table~\\ref{tab:preliminary}), we are able to observe that uniform application of the steering vector \\( v \\) improves distractor refusal accuracy but significantly degrades responses to on-topic inputs. This degradation is likely attributable to the consistent guidance of the steering vector towards refusal, regardless of whether the input is on- or off-topic. Since preserving on-topic performance is as crucial as enhancing refusal capability, a more adaptive approach is required.\n\nTherefore, in order to improve scenario adherence in task-oriented dialogue systems by dynamically steering model responses based on input entropy, we propose an approach which is comprised of three main components: (1) extracting steering vectors to align model behavior with predefined scenarios, (2) applying an entropy-based coefficient scaling mechanism to dynamically adjust the steering intensity based on input uncertainty, and (3) generating responses using these scaled steering vectors. By combining these components, our method effectively addresses the challenge of maintaining topic consistency in task-oriented dialogues, even amid off-topic distractors. The overall framework is illustrated in Figure~\\ref{fig:main}.\n\n",
        "trans_content": "\\section{提出的方法}\n\n根据初步实验（表~\\ref{tab:preliminary}），我们观察到均匀应用引导向量 \\( v \\) 能够提高对干扰输入的拒答准确率，但会显著降低对主题相关输入的响应质量。这种性能下降很可能是由于引导向量在所有情况下都朝向拒答方向引导模型，无论输入是否与主题相关。由于保持主题相关任务的性能与提升拒答能力同等重要，因此需要一种更具适应性的方法。\n\n因此，为了通过基于输入熵动态引导模型响应来提升任务型对话系统的场景契合性，我们提出了一种由三个主要组成部分构成的方法：（1）提取引导向量以使模型行为与预定义场景保持一致， （2）采用基于熵的系数缩放机制，根据输入的不确定性动态调整引导强度，以及（3）利用缩放后的引导向量生成响应。通过将这些组件结合在一起，我们的方法有效解决了在任务型对话中即使面对离题干扰也能保持话题一致性的挑战。整体框架如图~\\ref{fig:main} 所示。"
    },
    {
        "section": "4_1",
        "content": "\\subsection{Steering Vector Extraction}\nFrom the source dataset, we first construct the \\texttt{Steering QA Dataset} \\( S = \\{q_1, q_2, \\dots\\} \\), which is utilized to extract the steering vector using the method described in Section~\\ref{steering_vector_concept}. Specifically, each \\( q_i \\) represents a pair of prompts derived from the same distractor query \\( d \\). For each \\( d \\), the distractor is paired with two choice options explicitly representing a desired behavior and an undesired behavior. These options provide clear examples of a \\textit{refusal response} that redirects the conversation back to the topic, and an \\textit{engaging response} that inappropriately responds to the distractor.\n\nIn this setup, each refusal response (\\( q^p_i\\)) and engaging response (\\(q^n_i\\)) end with a different completion letter: one where the desired behavior completion letter (\\( c_p \\); e.g. A) is selected, and another where the undesired behavior completion letter (\\( c_n \\); e.g. B) is chosen. The refusal and engaging choices are randomly assigned across all test inputs to prevent positional bias in the evaluation. This structure enables the explicit differentiation needed for steering vector extraction. Note that since the CantTalkAboutThis source dataset lacks diverse refusal and engaging responses, these were generated using GPT-4o\\footnote{\\url{https://platform.openai.com/docs/models/gpt-4o}}~\\cite{openai2024gpt4ocard}. Full details of the prompt designs for generating completions are provided in the Appendix~\\ref{sec:prompt}.\n\nIn order to extract the steering vector from the newly constructed \\texttt{Steering QA Dataset}, we perform a forward pass \\( f(\\cdot) \\) through the pre-trained language model for each pair \\( q_i \\in S \\). At a designated layer \\( l \\), we compute the hidden representations \\( h_{p}^{(l)} \\) for \\( c_p \\) and \\( h_{n}^{(l)} \\) for \\( c_n \\). Using the theoretical definition in Section~\\ref{steering_vector_concept}, the steering vector \\( v \\) is derived by averaging and normalizing the differences in activations across all pairs. During inference, the steering vector is applied to ensure the model's outputs remain consistent with the topic.\n\n",
        "trans_content": "\\subsection{引导向量提取}\n从源数据集开始，我们首先构建了\\texttt{引导问答数据集} \\( S = \\{q_1, q_2, \\dots\\} \\)，该数据集用于使用第~\\ref{steering_vector_concept}节中描述的方法提取引导向量。具体而言，每个\\( q_i \\)表示从同一干扰查询\\( d \\)派生的一对提示。对于每个\\( d \\)，干扰项与两个选择项配对，明确表示期望的行为和不期望的行为。这些选项提供了\\textit{拒绝回应}和\\textit{参与回应}的清晰示例，拒绝回应将对话引回主题，而参与回应则不恰当地响应干扰项。\n\n在这种设置中，每个拒绝回应（\\( q^p_i\\)）和参与回应（\\( q^n_i\\)）以不同的完成字母结尾：一个选择期望行为的完成字母（\\( c_p \\); 例如 A），另一个选择不期望行为的完成字母（\\( c_n \\); 例如 B）。拒绝和参与选择在所有测试输入中随机分配，以防止评估中的位置偏差。这种结构能够显式地区分所需的引导向量提取。请注意，由于CantTalkAboutThis源数据集缺乏多样的拒绝和参与回应，这些回应是使用GPT-4o生成的\\footnote{\\url{https://platform.openai.com/docs/models/gpt-4o}}~\\cite{openai2024gpt4ocard}。生成完成的提示设计的完整细节见附录~\\ref{sec:prompt}。\n\n为了从新构建的\\texttt{引导问答数据集}中提取引导向量，我们对每对\\( q_i \\in S \\)执行预训练语言模型的前向传播\\( f(\\cdot) \\)。在指定的层\\( l \\)处，我们计算\\( c_p \\)的隐藏表示\\( h_{p}^{(l)} \\)和\\( c_n \\)的隐藏表示\\( h_{n}^{(l)} \\)。利用第~\\ref{steering_vector_concept}节中的理论定义，引导向量\\( v \\)通过对所有对之间的激活差异进行平均和归一化来推导。在推理过程中，引导向量被应用以确保模型的输出保持与主题一致。"
    },
    {
        "section": "4_2",
        "content": "\\subsection{Entropy-Based Coefficient Scaling}\nRecent studies~\\cite{chen2024inside,ji-etal-2024-llm,azaria-mitchell-2023-internal,chuang2024dola} have demonstrated that LLM internal states can be leveraged for reliable generation. Inspired by these findings, we conduct preliminary investigations regarding LLM internal states. Experimental results (Figures~\\ref{fig:entropy_violin} and \\ref{fig:mean_domain_layer}) reveal that under the same system instruction, the entropy distribution of each layer differs between distractor and on-topic inputs. This observation suggests that layer-wise entropy can serve as a discriminator between the two input types. Based on this insight, we introduce an entropy-based coefficient scaling method, which is detailed in Sections~\\ref{sec:layer_entropy_analysis} and~\\ref{sec:scaling}.\n\n",
        "trans_content": "\\subsection{基于熵的系数缩放}\n最近的研究~\\cite{chen2024inside,ji-etal-2024-llm,azaria-mitchell-2023-internal,chuang2024dola}表明，LLM内部状态可以用于可靠的生成。受到这些发现的启发，我们对LLM内部状态进行了初步的研究。实验结果（图~\\ref{fig:entropy_violin}和图~\\ref{fig:mean_domain_layer}）显示，在相同的系统指令下，各层的熵分布在干扰项输入和相关输入之间有所不同。这一观察表明，逐层熵可以作为区分这两种输入类型的判别器。基于这一见解，我们提出了一种基于熵的系数缩放方法，具体内容详见第~\\ref{sec:layer_entropy_analysis}节和第~\\ref{sec:scaling}节。"
    },
    {
        "section": "4_2_1",
        "content": "\\subsubsection{Layer-Wise Entropy Analysis}\\label{sec:layer_entropy_analysis}\nWe define the entropy \\( E^{(l)}_d \\text{ and } E^{(l)}_o \\) at layer \\( l \\) for the inputs \\( x_d = \\{I, D, d\\} \\text{ and } x_o = \\{I, D, o\\} \\), where \\(o\\) and \\(d\\) denote the on-topic and distractor user queries, respectively, during the generation of \\( k=2 \\) tokens. For each output token, the entropy \\( E^{(l)}\\) is computed as follows:\n\\[\nE^{(l)} = \\mathbb{E}\\left[- \\sum_{i=1}^{V} p_i^{(l)} \\log \\left(p_i^{(l)} + \\epsilon\\right) \\right],\n\\]\n\\[\np_i^{(l)} = \\frac{\\exp(z_i^{(l)})}{\\sum_{j=1}^{V} \\exp(z_j^{(l)})}.\n\\]\nHere, $V$ denotes the size of the vocabulary. For a given layer \\( l \\), \\( p_i^{(l)} \\) is the probability of the \\( i \\)-th token, which is obtained using the softmax function applied to the logits \\( z_i^{(l)} \\). Moreover, \\( z_i^{(l)} \\) represents the logit of the model for the \\( i \\)-th token at layer \\( l \\). The constant \\( \\epsilon \\) is a small value of \\( 10^{-12} \\), which is added to ensure numerical stability when computing the logarithm of the probabilities. The entropy at layer \\( l \\) quantifies the uncertainty of the token probabilities and is averaged across all inputs in the batch. We compute entropy as the average over the two tokens because the first token (e.g., \\(<s>\\)) typically carries minimal variation (\\( \\text{entropy} \\approx 0 \\)) due to its role as the generation start token.\n\n\\begin{figure}[t]\n    \\centering\n    \\begin{subfigure}{0.5\\textwidth}\n        \\centering\n        \\includegraphics[width=\\linewidth]{latex/figures/violin_plot_16.pdf}\n        \\caption{Entropy distribution in layer 16.}\n        \\label{fig:entropy_violin_16}\n    \\end{subfigure}\n    \\hfill\n    \\begin{subfigure}{0.5\\textwidth}\n        \\centering\n        \\includegraphics[width=\\linewidth]{latex/figures/violin_plot_19.pdf}\n        \\caption{Entropy distribution in layer 19.}\n        \\label{fig:entropy_violin_19}\n    \\end{subfigure}\n    \\caption{Comparison of entropy distribution in different layers of Llama-2-7b-chat.}\n    \\label{fig:entropy_violin}\n\\end{figure}\n\nWe observe significant differences in entropy distributions between distractor and on-topic inputs at layers 16 and 19 (Figures~\\ref{fig:entropy_violin} and~\\ref{fig:mean_domain_layer}). While both layers exhibit clear distributional differences, the relative entropy values vary by layer; on-topic inputs show higher entropy in some layers (Figure~\\ref{fig:entropy_violin_16}), whereas distractor inputs have higher entropy in others (Figure~\\ref{fig:entropy_violin_19}). Notably, as seen in Figures~\\ref{fig:entropy_violin_16} and~\\ref{fig:entropy_violin_19}, the distinction at layer 16 is more pronounced. The implications of these differences on experimental outcomes are discussed in Section~\\ref{sec:results}, while a detailed analysis of the observed entropy patterns is provided in Section~\\ref{sec:analysis}. Based on these findings, we select layers 16 and 19 as \\( L \\), where \\( L \\) represents the LLM layers used for entropy extraction.\n\n\\begin{table*}[ht]\n    \\centering\n    \\begin{tabular}{ccccc}\n        \\toprule\n        \\textbf{$L$} & \\textbf{\\textit{Steer @}} & \\textbf{Distractor} $\\uparrow$ & \\textbf{On-topic} $\\uparrow$ & \\textbf{Overall} $\\uparrow$ \\\\\n        \\midrule\n        -&\\textit{Prompt Only} & 0.282 & 0.938 & 0.610 \\\\\n        \\midrule\n        \\multirow{4}{*}{16}\n        & 13 & 0.758 (+0.476) & 0.820 (-0.118) & 0.789 (+0.179) \\\\\n        & 14 & 0.795 (+0.512) & 0.775 (-0.163) & 0.784 (+0.174) \\\\\n        & 15 & \\underline{0.810} (+0.529) & 0.747 (-0.191) & 0.779 (+0.169) \\\\\n        & 16 & 0.709 (+0.427) & \\underline{0.895} (-0.043) & \\textbf{0.802} (+0.192) \\\\\n        \\midrule\n        \\multirow{4}{*}{19}\n        & 13 & 0.773 (+0.490) & 0.709 (-0.229) & 0.741 (+0.131) \\\\\n        & 14 & 0.793 (+0.511) & 0.644 (-0.294) & 0.718 (+0.108) \\\\\n        & 15 & 0.784 (+0.502) & 0.693 (-0.245) & 0.738 (+0.128) \\\\\n        & 16 & 0.749 (+0.467) & 0.818 (-0.120) & 0.784 (+0.174) \\\\\n        \\bottomrule\n    \\end{tabular}\n    \\caption{Performance comparison of distractor and on-topic inputs across different layers with \\textit{Prompt Only} and EnSToM. The overall accuracy is computed as the average of distractor and on-topic accuracies. Column $L$ indicates which layer $H$ is computed from, and \\textit{Steer @} indicates where steering vector was added. The overall best accuracy is highlighted in bold, while the best accuracies for individual metrics (distractor and on-topic, within EnSToM results) are \\underline{underlined}. The symbols \"$+$\" or \"$-$\" indicate the point gain or loss relative to the prompt-only settings. Note that higher values for all metrics indicate better performance.}\n    \\label{tab:main}\n\\end{table*}\n\n",
        "trans_content": "\\subsubsection{层次熵分析}\\label{sec:layer_entropy_analysis}\n我们定义了在层 \\( l \\) 上的熵 \\( E^{(l)}_d \\text{ 和 } E^{(l)}_o \\)，其中输入 \\( x_d = \\{I, D, d\\} \\text{ 和 } x_o = \\{I, D, o\\} \\)，其中 \\( o \\) 和 \\( d \\) 分别表示在生成 \\( k=2 \\) 个标记时的主题相关和干扰用户查询。对于每个输出标记，熵 \\( E^{(l)} \\) 的计算公式如下：\n\\[\nE^{(l)} = \\mathbb{E}\\left[- \\sum_{i=1}^{V} p_i^{(l)} \\log \\left(p_i^{(l)} + \\epsilon\\right) \\right],\n\\]\n\\[\np_i^{(l)} = \\frac{\\exp(z_i^{(l)})}{\\sum_{j=1}^{V} \\exp(z_j^{(l)})}.\n\\]\n这里，$V$ 表示词汇表的大小。对于给定的层 \\( l \\)，\\( p_i^{(l)} \\) 是第 \\( i \\)-个标记的概率，它是通过对 \\( z_i^{(l)} \\) 应用 softmax 函数得到的概率。并且，\\( z_i^{(l)} \\) 表示模型在层 \\( l \\) 上对于第 \\( i \\)-个标记的对数输出。常数 \\( \\epsilon \\) 是一个很小的值 \\( 10^{-12} \\)，它用于确保计算概率对数时的数值稳定性。在层 \\( l \\) 上的熵量化了标记概率的不可确定性，并且是在批次中的所有输入上求平均。我们将熵计算为两个标记的平均值，因为第一个标记（例如 \\( <s> \\)）通常由于作为生成起始标记的作用，携带的变化较小（\\( \\text{熵} \\approx 0 \\)）。\n\n\\begin{figure}[t]\n    \\centering\n    \\begin{subfigure}{0.5\\textwidth}\n        \\centering\n        \\includegraphics[width=\\linewidth]{latex/figures/violin_plot_16.pdf}\n        \\caption{第16层的熵分布。}\n        \\label{fig:entropy_violin_16}\n    \\end{subfigure}\n    \\hfill\n    \\begin{subfigure}{0.5\\textwidth}\n        \\centering\n        \\includegraphics[width=\\linewidth]{latex/figures/violin_plot_19.pdf}\n        \\caption{第19层的熵分布。}\n        \\label{fig:entropy_violin_19}\n    \\end{subfigure}\n    \\caption{不同层次中的熵分布比较（Llama-2-7b-chat）。}\n    \\label{fig:entropy_violin}\n\\end{figure}\n\n我们观察到在第16层和第19层的干扰和主题相关输入之间的熵分布有显著差异（图~\\ref{fig:entropy_violin} 和~\\ref{fig:mean_domain_layer}）。虽然这两层都表现出明显的分布差异，但相对熵值在不同层次上有所不同；主题相关输入在某些层次上的熵较高（图~\\ref{fig:entropy_violin_16}），而干扰输入在其他层次上则表现出较高的熵（图~\\ref{fig:entropy_violin_19}）。值得注意的是，如图~\\ref{fig:entropy_violin_16} 和~\\ref{fig:entropy_violin_19} 所示，第16层的区别更为显著。这些差异对实验结果的影响将在第~\\ref{sec:results} 节中讨论，而对观察到的熵模式的详细分析将在第~\\ref{sec:analysis} 节中提供。根据这些发现，我们选择第16层和第19层作为 \\( L \\)，其中 \\( L \\) 代表用于熵提取的 LLM 层。\n\n\\begin{table*}[ht]\n    \\centering\n    \\begin{tabular}{ccccc}\n        \\toprule\n        \\textbf{$L$} & \\textbf{\\textit{Steer @}} & \\textbf{干扰项} $\\uparrow$ & \\textbf{主题相关} $\\uparrow$ & \\textbf{总体} $\\uparrow$ \\\\\n        \\midrule\n        -&\\textit{仅提示} & 0.282 & 0.938 & 0.610 \\\\\n        \\midrule\n        \\multirow{4}{*}{16}\n        & 13 & 0.758 (+0.476) & 0.820 (-0.118) & 0.789 (+0.179) \\\\\n        & 14 & 0.795 (+0.512) & 0.775 (-0.163) & 0.784 (+0.174) \\\\\n        & 15 & \\underline{0.810} (+0.529) & 0.747 (-0.191) & 0.779 (+0.169) \\\\\n        & 16 & 0.709 (+0.427) & \\underline{0.895} (-0.043) & \\textbf{0.802} (+0.192) \\\\\n        \\midrule\n        \\multirow{4}{*}{19}\n        & 13 & 0.773 (+0.490) & 0.709 (-0.229) & 0.741 (+0.131) \\\\\n        & 14 & 0.793 (+0.511) & 0.644 (-0.294) & 0.718 (+0.108) \\\\\n        & 15 & 0.784 (+0.502) & 0.693 (-0.245) & 0.738 (+0.128) \\\\\n        & 16 & 0.749 (+0.467) & 0.818 (-0.120) & 0.784 (+0.174) \\\\\n        \\bottomrule\n    \\end{tabular}\n    \\caption{不同层次下，干扰和主题相关输入在 \\textit{仅提示} 和 EnSToM 下的性能比较。总体准确率是干扰和主题相关准确率的平均值。列 $L$ 表示计算熵的层，\\textit{Steer @} 表示加入了引导向量的位置。总体最佳准确率用粗体标出，而每个单独指标（干扰和主题相关，基于 EnSToM 结果）的最佳准确率用 \\underline{下划线} 标出。符号 \"$+$\" 或 \"$-$\" 表示相对于仅提示设置的得分增益或损失。请注意，所有指标的较高值表示更好的性能。}\n    \\label{tab:main}\n\\end{table*}"
    },
    {
        "section": "4_2_2",
        "content": "\\subsubsection{Implementation of Entropy-Based Coefficient Scaling}\\label{sec:scaling}\nWe introduce a coefficient scaling mechanism to dynamically adjust the steering intensity based on input entropy. The scaling coefficient is defined as:\n\\[\nC_H^{(L)} = \\frac{C_{\\text{max}}}{1 + e^{-\\alpha \\delta (H^{(L)} - t)}},\n\\]\nwhere \\( C_H^{(L)} \\) is the entropy-based scaling coefficient, and the entropy at layer \\(L\\) of the model's response to the user query is denoted as \\( H^{(L)} \\). The maximum coefficient \\( C_{\\text{max}} \\) is set to 1.5 based on prior findings by \\citet{rimsky-etal-2024-steering}\\footnote{For further analysis of coefficient scaling, see Appendix~\\ref{sec:coefficient}.}. The slope parameter \\( \\alpha \\), which controls the steepness of the sigmoid function, is set to 5, while the threshold entropy \\( t \\) is empirically set to 7.5.\n\nIn order to adjust the scaling direction based on entropy differences between distractor and on-topic inputs, the parameter \\(\\delta\\) is set to -1 when the average entropy of distractors is lower than on-topic inputs (Layer 16) and \\(+1\\) when it is higher (Layer 19). This adjustment ensures that the coefficient increases when the entropy deviates from \\( t \\) in the appropriate direction. By dynamically modulating the coefficient, this approach enhances refusal accuracy for distractor inputs while preserving engaging responses for on-topic interactions.\n\n\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=\\columnwidth]{latex/figures/entropy_scaling_plot.pdf}\n    \\caption{Effect of entropy-based scaling at different thresholds $t$.}\n    \\label{fig:threshold}\n\\end{figure}\n\n",
        "trans_content": "\\subsubsection{基于熵的系数缩放实现}\\label{sec:scaling}\n我们引入了一种系数缩放机制，用于根据输入熵动态调整引导强度。缩放系数定义如下：\n\\[\nC_H^{(L)} = \\frac{C_{\\text{max}}}{1 + e^{-\\alpha \\delta (H^{(L)} - t)}},\n\\]\n其中，\\( C_H^{(L)} \\) 表示基于熵的缩放系数，模型在第 \\(L\\) 层对用户查询的响应熵记为 \\( H^{(L)} \\)。最大系数 \\( C_{\\text{max}} \\) 被设定为 1.5，此设置基于 \\citet{rimsky-etal-2024-steering} 的先前研究成果\\footnote{有关系数缩放的进一步分析，参见附录~\\ref{sec:coefficient}。}。斜率参数 \\( \\alpha \\) 控制 sigmoid 函数的陡峭程度，设定为 5，而熵阈值 \\( t \\) 的经验设定为 7.5。\n\n为了根据干扰项与相关输入之间的熵差调整缩放方向，当干扰项的平均熵低于相关输入（第 16 层）时，将参数 \\(\\delta\\) 设为 -1；当其高于相关输入（第 19 层）时，设为 \\(+1\\)。此调整确保当熵以适当方向偏离 \\( t \\) 时，系数将随之增加。通过动态调节系数，该方法增强了对干扰输入的拒答准确性，同时保留了与相关交互的吸引力。\n\n\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=\\columnwidth]{latex/figures/entropy_scaling_plot.pdf}\n    \\caption{不同阈值 $t$ 下基于熵的缩放效果。}\n    \\label{fig:threshold}\n\\end{figure}"
    },
    {
        "section": "4_3",
        "content": "\\subsection{Response Generation}\nDuring response generation, the model processes an input consisting of system instructions (\\(I\\)), dialogue history (\\(D\\)), and the user question (either off-topic \\(d\\) or on-topic \\(o\\)). The model then generates \\(k=2\\) tokens using greedy decoding, during which the entropy value (\\(H\\)) is computed at layers 16 and 19.\n\nThis entropy value is used to calculate the coefficient via the entropy-based coefficient scaling mechanism outlined in Section~\\ref{sec:scaling}. The computed coefficient is applied to the steering vector ($v$), which is added to the model's activations at a designated layer ($h^{(l)}$). Note that this layer is distinct from the layer that is used for entropy extraction:\n\\[\n{h'}^{(l)} = h^{(l)} + C_H^{(L)}\\cdot v\n\\]\nThis process ensures that the steering intensity dynamically adapts to the input's entropy, which enhances the model's ability to handle distractors while maintaining accuracy on on-topic inputs.\n\n",
        "trans_content": "\\subsection{响应生成}\n在响应生成过程中，模型处理由系统指令（\\(I\\)）、对话历史（\\(D\\)）和用户问题（无论是离题的 \\(d\\) 还是与主题相关的 \\(o\\)）组成的输入。然后，模型使用贪婪解码生成 \\(k=2\\) 个标记，在此过程中计算第 16 层和第 19 层的熵值（\\(H\\)）。\n\n该熵值用于通过第~\\ref{sec:scaling} 节中概述的基于熵的系数缩放机制计算系数。计算出的系数应用于引导向量（\\(v\\)），该向量被添加到模型的指定层激活（\\(h^{(l)}\\)）中。请注意，这一层与用于提取熵的层是不同的：\n\\[\n{h'}^{(l)} = h^{(l)} + C_H^{(L)}\\cdot v\n\\]\n此过程确保引导强度能够动态适应输入的熵，从而增强模型在处理干扰项时的能力，同时在处理与主题相关的输入时保持准确性。"
    },
    {
        "section": "5+5_1",
        "content": "\\section{Experiments}\n\n\n\\subsection{Experimental Setup}\n\nWe conduct our main experiments using LLaMA-2-7B-Chat~\\cite{touvron2023llama2openfoundation} and Minstral-8B-Instruct-2410\\footnote{\\url{https://mistral.ai/en/news/ministraux}} to evaluate the generalizability of our method. Both models are executed on a single NVIDIA RTX A6000 GPU, and do not involve additional training; instead, they focus on extracting steering vectors and computing entropy. Steering is applied at layers 13-16 since the middle layers are more effective at modifying generation behavior \\cite{rimsky-etal-2024-steering}.\n\nWe evaluate our method on the CantTalkAboutThis dataset~\\cite{sreedhar-etal-2024-canttalkaboutthis}, which spans 10 domains. Our experiments focus on the banking domain, which consists of 60 independent scenarios with 10 to 15 samples each. To prevent data contamination, we use 100 samples\\footnote{Extended experimental results with varying sample sizes are provided in Appendix~\\ref{sec:add_ex}.} from 10 scenarios to compute steering vectors, and keep them separate from the test set, which includes 550 samples each for distractor and on-topic cases. Evaluation was conducted separately for distractor and on-topic settings. Detailed dataset statistics are provided in Appendix~\\ref{sec:detail_source}. For evaluation, we use GPT-4o to classify model responses as refusals or engaging responses. The prompts used for evaluation are detailed in Appendix~\\ref{sec:prompt_eval}.\n\n\\paragraph{Metric}\n\\label{para:metric}\nWe evaluate the model's performance using two accuracy metrics: (1) \\textbf{Distractor accuracy}, which is defined as the proportion of responses where the model correctly refuses off-topic content, and (2) \\textbf{On-topic accuracy}, which is the proportion of responses where the model appropriately engages with relevant content without refusing.\n\n\\begin{table}[t]\n    \\centering\n    \\footnotesize\n    \\resizebox{0.48\\textwidth}{!}{\n        \\begin{tabular}{cccc}\n            \\toprule\n            \\textbf{\\textit{Steer @}} & \\textbf{Distractor} & \\textbf{On-topic} & \\textbf{Overall} \\\\\n            \\midrule\n            \\textit{Prompt Only} & 0.25 & 0.98 & 0.62 \\\\\n            \\midrule\n            17 & 0.65 (+0.40) & 0.86 (-0.12) & 0.75 (+0.14) \\\\\n            18 & 0.63 (+0.38) & 0.91 (-0.07) & \\textbf{0.76} (+0.15) \\\\\n            \\bottomrule\n        \\end{tabular}\n    }\n    \\caption{Performance of EnSToM at Ministral-8b-Instruct-2410.}\n    \\label{tab:ministral}\n\\end{table}\n\n",
        "trans_content": "\\section{实验}\n\n\\subsection{实验设置}\n\n我们使用 LLaMA-2-7B-Chat~\\cite{touvron2023llama2openfoundation} 和 Minstral-8B-Instruct-2410\\footnote{\\url{https://mistral.ai/en/news/ministraux}} 进行主要实验，以评估我们方法的泛化能力。两个模型均在单个 NVIDIA RTX A6000 GPU 上运行，并且不涉及额外的训练；它们的重点是提取引导向量和计算熵。引导操作应用于第 13 至 16 层，因为中间层在修改生成行为方面更为有效~\\cite{rimsky-etal-2024-steering}。\n\n我们在 CantTalkAboutThis 数据集~\\cite{sreedhar-etal-2024-canttalkaboutthis} 上评估我们的方法，该数据集涵盖了 10 个领域。我们的实验重点是银行领域，该领域包含 60 个独立场景，每个场景有 10 到 15 个样本。为了防止数据污染，我们使用来自 10 个场景的 100 个样本\\footnote{附录~\\ref{sec:add_ex} 提供了不同样本量的扩展实验结果。} 计算引导向量，并将其与测试集分开，测试集包括每个干扰项和相关项案例的 550 个样本。评估分别在干扰项和相关项设置下进行。详细的数据集统计信息请参见附录~\\ref{sec:detail_source}。在评估时，我们使用 GPT-4o 对模型响应进行分类，判断其是拒绝回应还是互动回应。用于评估的提示在附录~\\ref{sec:prompt_eval} 中详细说明。\n\n\\paragraph{度量标准}\n\\label{para:metric}\n我们使用两个准确度度量标准评估模型的表现：（1）\\textbf{干扰项准确度}，定义为模型正确拒绝非相关内容的响应比例；（2）\\textbf{相关项准确度}，定义为模型适当地与相关内容进行互动而不拒绝的响应比例。\n\n\\begin{table}[t]\n    \\centering\n    \\footnotesize\n    \\resizebox{0.48\\textwidth}{!}{\n        \\begin{tabular}{cccc}\n            \\toprule\n            \\textbf{\\textit{引导 @}} & \\textbf{干扰项} & \\textbf{相关项} & \\textbf{总体} \\\\\n            \\midrule\n            \\textit{仅提示} & 0.25 & 0.98 & 0.62 \\\\\n            \\midrule\n            17 & 0.65 (+0.40) & 0.86 (-0.12) & 0.75 (+0.14) \\\\\n            18 & 0.63 (+0.38) & 0.91 (-0.07) & \\textbf{0.76} (+0.15) \\\\\n            \\bottomrule\n        \\end{tabular}\n    }\n    \\caption{EnSToM 在 Ministral-8b-Instruct-2410 上的表现。}\n    \\label{tab:ministral}\n\\end{table}"
    },
    {
        "section": "5_2",
        "content": "\\subsection{Results}\\label{sec:results}\n\nTable~\\ref{tab:main} compares the performance of EnSToM across layers 13 to 16 under two entropy extraction settings, \\( L = 16 \\) and \\( L = 19 \\), against the baseline \\textit{Prompt Only} method. In all conditions, we use a fixed threshold \\( t = 7.5 \\) and the same prompt, which combines system instructions (Appendix~\\ref{sec:prompt_sys_instr}) and dialogue history (Appendix~\\ref{sec:prompt_dialogue_history}), followed by the user question. The prompt-only baseline achieves a distractor accuracy of 0.282 and an on-topic accuracy of 0.938, which results in an overall score of 0.610. Since the \\textit{Prompt Only} method does not use steering, \\( L \\) and \\textit{Steer @} settings are not applicable. This result highlights the baseline model's limited ability to handle distractor inputs effectively.\n\nOn the other hand, the application of the steering vector significantly improves distractor accuracy, with the highest improvement observed at \\( L = 16 \\) and \\textit{Steer @} = 15, which reaches 0.810 (+0.529). The highest overall accuracy is achieved at \\( L=16 \\) and \\textit{Steer @} = 16, with an overall accuracy of 0.802 (+0.192). This setting also maintains the highest on-topic accuracy (0.895). Overall, our method achieves a notable increase in overall accuracy and the largest improvement in distractor accuracy while minimizing losses in on-topic accuracy.\n\nComparing the different \\( L\\) settings, we observe that on-topic accuracy degrades more in the \\( L = 19 \\) setting, while distractor accuracy improves similarly in both cases. As a result, overall performance is generally higher in the \\( L = 16 \\) configuration. This aligns with the entropy distribution differences shown in Figure~\\ref{fig:entropy_violin}, where layer 16 exhibits a clearer separation between distractor and on-topic entropy values. These findings suggest that the effectiveness of entropy scaling is influenced by the degree of entropy separation at different layers.\n\n\\begin{figure}[t]\n\\centering\n  \\includegraphics[width=\\columnwidth]{latex/figures/sample_entropy_33.pdf}\n  \\caption{Entropy distribution of on-topic and distractor for jailbreak defense task at layer 33 of Ministral-8b-Instruct-2410 model.}\n  \\label{fig:entropy_jailbreak}\n\\end{figure}\n\n\\begin{figure*}[t]\n\\centering\n  \\includegraphics[width=2\\columnwidth]{latex/figures/layer_entropy_mean_diff_k_2.pdf}\n  \\caption{Layer-wise entropy difference (distractor-on-topic) across domains.}\n  \\label{fig:mean_domain_layer}\n\\end{figure*}\n\n",
        "trans_content": "\\subsection{结果}\\label{sec:results}\n\n表~\\ref{tab:main}比较了EnSToM在第13到16层的性能，分别在两种熵提取设置下进行评估，\\( L = 16 \\) 和 \\( L = 19 \\)，并与基准的\\textit{仅提示}方法进行对比。在所有条件下，我们使用固定的阈值 \\( t = 7.5 \\) 和相同的提示，该提示结合了系统指令（附录~\\ref{sec:prompt_sys_instr}）和对话历史（附录~\\ref{sec:prompt_dialogue_history}），之后是用户问题。仅提示基准方法在干扰项准确率上为0.282，在主题相关准确率上为0.938，最终得分为0.610。由于\\textit{仅提示}方法未使用引导，因此\\( L \\)和\\textit{Steer @}设置不适用。该结果突出了基准模型在有效处理干扰项输入方面的局限性。\n\n另一方面，引导向量的应用显著提高了干扰项准确率，最高提升出现在 \\( L = 16 \\) 和 \\textit{Steer @} = 15 的组合下，达到了0.810（+0.529）。最高的总体准确率出现在 \\( L=16 \\) 和 \\textit{Steer @} = 16 设置下，总体准确率为0.802（+0.192）。该设置还保持了最高的主题相关准确率（0.895）。总体而言，我们的方法在总体准确率上实现了显著提升，并在提高干扰项准确率的同时，最小化了主题相关准确率的损失。\n\n比较不同的 \\( L \\) 设置，我们观察到在 \\( L = 19 \\) 设置下，主题相关准确率下降得更为明显，而干扰项准确率在两种情况下的提升相似。因此，总体性能在 \\( L = 16 \\) 配置下通常更高。这与图~\\ref{fig:entropy_violin}所示的熵分布差异一致，其中第16层在干扰项和主题相关熵值之间表现出更清晰的分离。这些发现表明，熵缩放的有效性受到不同层级之间熵分离程度的影响。\n\n\\begin{figure}[t]\n\\centering\n  \\includegraphics[width=\\columnwidth]{latex/figures/sample_entropy_33.pdf}\n  \\caption{Ministral-8b-Instruct-2410模型在第33层的越狱防御任务中的主题相关和干扰项熵分布。}\n  \\label{fig:entropy_jailbreak}\n\\end{figure}\n\n\\begin{figure*}[t]\n\\centering\n  \\includegraphics[width=2\\columnwidth]{latex/figures/layer_entropy_mean_diff_k_2.pdf}\n  \\caption{跨领域的层级熵差异（干扰项与主题相关）。}\n  \\label{fig:mean_domain_layer}\n\\end{figure*}"
    },
    {
        "section": "6",
        "content": "\\section{Discussion}\n\nThis section discusses the impact of entropy-based coefficient scaling, generalization across models and tasks, and layer-wise entropy patterns across domains.\n\n",
        "trans_content": "\\section{讨论}\n\n本节讨论基于熵的系数缩放、模型和任务之间的泛化能力，以及跨领域的层级熵模式的影响。"
    },
    {
        "section": "6_1",
        "content": "\\subsection{Effect of Entropy-based Scaling}\nFigure~\\ref{fig:threshold} illustrates the effect of entropy-based scaling on topic adherence across different threshold values \\( t \\). Here, \\texttt{Vanilla} refers to applying the steering vector with a fixed coefficient (\\( C_{\\text{max}} \\)) without dynamic scaling. \\texttt{Vanilla} achieves an overall accuracy of 0.75, exhibiting strong distractor performance (0.80) but lower on-topic accuracy (0.70).\n\nHowever, EnSToM demonstrates a clear performance improvement over \\texttt{Vanilla} setting. At low thresholds (\\( t = 2, 4 \\)), on-topic accuracy peaks (0.95), but distractor accuracy drops significantly (0.30–0.32). In contrast, higher thresholds (\\( t = 7.5, 8 \\)) achieve the best overall accuracy (0.80) by balancing distractor handling (0.71–0.76) with minimal on-topic degradation (0.84–0.89). Beyond this range (\\( t = 9 \\)), distractor accuracy returns to baseline, while on-topic performance declines (0.72), indicating that exceeding the optimal threshold compromises scenario adherence. These results demonstrate the effectiveness of entropy-based scaling in maintaining topic consistency while minimizing trade-offs.\n\n",
        "trans_content": "\\subsection{基于熵的尺度化效果}\n图~\\ref{fig:threshold}展示了基于熵的尺度化对不同阈值 \\( t \\) 下主题遵循度的影响。在这里，\\texttt{Vanilla} 指的是应用具有固定系数 (\\( C_{\\text{max}} \\)) 的引导向量，而没有动态尺度化。\\texttt{Vanilla} 的整体准确率为 0.75，表现出较强的干扰项表现（0.80），但主题准确率较低（0.70）。\n\n然而，EnSToM 相较于 \\texttt{Vanilla} 设置表现出了明显的性能提升。在较低的阈值下（\\( t = 2, 4 \\)），主题准确率达到峰值（0.95），但干扰项准确率显著下降（0.30–0.32）。相反，较高的阈值（\\( t = 7.5, 8 \\)）通过平衡干扰项处理（0.71–0.76）与最小化主题准确率下降（0.84–0.89）实现了最佳的整体准确率（0.80）。超出此范围（\\( t = 9 \\)）后，干扰项准确率回归基线，而主题表现下降（0.72），这表明超过最优阈值会损害场景遵循度。这些结果展示了基于熵的尺度化在保持主题一致性的同时，最小化权衡的有效性。"
    },
    {
        "section": "6_2",
        "content": "\\subsection{Cross Architecture Generalization}\nTo evaluate the generalizability of EnSToM beyond the Llama family, we conduct experiments on Minstral-8B-Instruct-2410. Table~\\ref{tab:ministral} presents the results of EnSToM~($L=28$ and $t=3.0$)\\footnote{Systematically selected based on the entropy distribution.}. Without entropy-based scaling (\\textit{Prompt Only}), the model exhibits strong on-topic accuracy (0.98) but struggles with distractor handling (0.25), leading to a low overall accuracy (0.62). Applying EnSToM at layers 17 and 18, however, significantly improves distractor accuracy (+0.40 and +0.38, respectively) while maintaining competitive on-topic performance. The best overall accuracy (0.76) is achieved at layer 18, which confirms EnSToM’s effectiveness across different model architectures.\n\n",
        "trans_content": "\\subsection{跨架构泛化}\n为了评估EnSToM在Llama家族之外的泛化能力，我们在Minstral-8B-Instruct-2410上进行了实验。表~\\ref{tab:ministral}展示了EnSToM~($L=28$ 和 $t=3.0$)\\footnote{基于熵分布系统性选择。}的实验结果。在没有基于熵的缩放 (\\textit{仅提示}) 的情况下，模型在主题准确度上表现强劲 (0.98)，但在分心项处理上存在困难 (0.25)，导致整体准确度较低 (0.62)。然而，在第17层和第18层应用EnSToM显著提高了分心项的准确度（分别提高了+0.40和+0.38），同时保持了竞争力的主题性能。在第18层达到了最佳整体准确度 (0.76)，这验证了EnSToM在不同模型架构中的有效性。"
    },
    {
        "section": "6_3",
        "content": "\\subsection{Task-level Generalization}\nIn order to assess task-level generalization abilities of the proposed model, we shift to the jailbreak defense task\\footnote{Dataset construction details are provided in Appendix~\\ref{sec:jailbreak}.}. Pilot tests reveal that jailbreak attacks were successful most of the time. This means that the model can only generate unsafe responses. However, the model is able to distinguish between harmful and harmless content due to entropy differences at layer 33\\footnote{Layer 33 was selected based on the maximally observed difference between harmful and harmless entropy distributions across all layers} (Figure~\\ref{fig:entropy_jailbreak}). While refusal-based steering vectors alone were ineffective, these findings suggest the potential for adapting EnSToM to jailbreak defense tasks.\n\n",
        "trans_content": "\\subsection{任务级泛化}\n为了评估所提出模型的任务级泛化能力，我们转向了越狱防御任务\\footnote{数据集构建的详细信息见附录~\\ref{sec:jailbreak}。}。初步测试表明，越狱攻击在大多数情况下是成功的。这意味着模型只能生成不安全的响应。然而，由于第33层的熵差异\\footnote{第33层是基于所有层中有害与无害熵分布之间的最大差异选择的}，模型能够区分有害和无害内容（图~\\ref{fig:entropy_jailbreak}）。尽管仅凭拒绝式引导向量效果不佳，但这些发现表明，EnSToM在越狱防御任务中的适应潜力。"
    },
    {
        "section": "6_4",
        "content": "\\subsection{Layer-wise Entropy Analysis}\\label{sec:analysis}\n\nPrior studies \\cite{li2025safety,azaria-mitchell-2023-internal,chuang2024dola} have highlighted that intermediate layers significantly influence the generation process in large language models. Specifically, in the LLaMA-2-7B-chat model used in our study, \\citet{li2025safety} demonstrates a clear transition in token attention across intermediate layers: initial layers predominantly capture syntactic tokens, middle layers (e.g., layer 16) shift attention towards semantically crucial tokens, and deeper layers (e.g., layers 19–20) further distribute attention onto tokens with secondary semantic roles.\n\nIn our experimental setup—comprising a system instruction, dialogue history, and user query—we observe a similar attention dynamic influencing entropy distributions. At layer 16, distractor queries, semantically incongruent with the dialogue context and system instruction, attract highly focused attention on their unique tokens. This focused attention activates fewer logits, resulting in significantly lower entropy. Conversely, on-topic queries, contextually aligned with the instruction and dialogue history, maintain attention broadly distributed across multiple contextually relevant tokens. This broader activation leads to higher entropy values compared to distractors.\n\nInterestingly, this relationship reverses at deeper layers (e.g., layers 19–20). Here, distractor queries experience increased entropy as attention disperses onto additional semantically relevant tokens beyond the initial focus. Meanwhile, on-topic queries exhibit stable entropy, reflecting sustained distributed attention across the context.\n\nMoreover, this entropy pattern consistently emerges across various domains, as Figure~\\ref{fig:mean_domain_layer} illustrates. Distractor inputs consistently exhibit lower entropy at layer 16 and higher entropy at layers 18–20 relative to on-topic inputs, regardless of domain variations. This cross-domain consistency—further supported by our domain-shift experiments detailed in Appendix~\\ref{sec:cross-domain}—underscores the robustness of our observations and indicates a generalizable mechanism in the model’s internal processing.\n\nThese findings align well with established understandings of layer specialization in LLMs \\cite{gera-etal-2023-benefits}: lower layers encode syntactic information, intermediate layers encode semantic significance, and higher layers integrate these semantic and contextual representations. Thus, our entropy analysis provides empirical evidence for how intermediate layers differentially process distractor versus on-topic inputs, highlighting layer-specific functional roles and emphasizing the practical applicability of entropy-based methods in detecting semantic consistency within dialogues.\n\n",
        "trans_content": "\\subsection{逐层熵分析}\\label{sec:analysis}\n\n先前的研究 \\cite{li2025safety,azaria-mitchell-2023-internal,chuang2024dola} 强调了中间层在大规模语言模型生成过程中的重要作用。具体来说，在我们研究中使用的 LLaMA-2-7B-chat 模型中，\\citet{li2025safety} 展示了在中间层中，标记注意力的明显变化：初始层主要捕捉语法标记，中间层（例如第16层）将注意力转向语义关键标记，而更深的层（例如第19-20层）则进一步将注意力分散到具有次要语义角色的标记上。\n\n在我们的实验设置中——包括系统指令、对话历史和用户查询——我们观察到类似的注意力动态对熵分布产生影响。在第16层，与对话上下文和系统指令语义不一致的干扰查询会在其独特标记上吸引高度集中的注意力。这种集中的注意力激活较少的logits，导致熵显著降低。相反，与指令和对话历史语义一致的相关查询，注意力广泛分布在多个上下文相关的标记上。这种更广泛的激活导致熵值高于干扰查询。\n\n有趣的是，这种关系在更深层（例如第19-20层）发生了逆转。在这些层中，干扰查询的熵增加，因为注意力分散到更多的语义相关标记上，而不仅仅是初步关注的标记。与此同时，与主题一致的查询则表现出稳定的熵，反映了在上下文中持续分布的注意力。\n\n此外，这种熵模式在不同领域中始终如一，正如图~\\ref{fig:mean_domain_layer} 所示。无论领域如何变化，干扰输入在第16层总是表现出较低的熵，而在第18-20层则表现出较高的熵，相比于相关输入。这种跨领域的一致性——通过我们在附录~\\ref{sec:cross-domain} 中详细介绍的领域迁移实验进一步支持——强调了我们观察结果的稳健性，并表明模型内部处理机制具有普遍性。\n\n这些发现与大规模语言模型中层次特化的既有理解 \\cite{gera-etal-2023-benefits} 完全一致：低层编码语法信息，中间层编码语义重要性，而高层则整合这些语义和上下文表示。因此，我们的熵分析为中间层如何在干扰输入与相关输入之间进行差异化处理提供了实证证据，突出了层次特定的功能角色，并强调了基于熵的方法在检测对话中语义一致性方面的实际应用。"
    },
    {
        "section": "7",
        "content": "\\section{Conclusion}\n\nIn this paper, we introduced EnSToM, a lightweight and training-free method for enhancing topic consistency in task-oriented dialogue systems using entropy-scaled steering vectors. By integrating steering vector with an entropy-based coefficient scaling mechanism, our approach dynamically adjusts steering intensity based on the model's generation entropy. Evaluations on the CantTalkAboutThis dataset demonstrated a significant improvement in distractor accuracy while preserving on-topic performance, which results in an increase of overall accuracy.\n\nFurthermore, experiments across different models, domains, and tasks validated the generalizability of our method. Even with limited steering vector samples, EnSToM remained effective, making it suitable for low-resource settings. Additionally, our layer-wise entropy analysis provides valuable insights into LLM behavior, contributing to improved interpretability. These findings support the development of adaptive and scenario-consistent dialogue systems for real-world applications.\n\n",
        "trans_content": "\\section{结论}\n\n在本文中，我们提出了 EnSToM，一种轻量且无需训练的方法，利用熵缩放的引导向量来增强面向任务的对话系统中的话题一致性。通过将引导向量与基于熵的系数缩放机制相结合，我们的方法能够根据模型生成的熵动态调整引导强度。在 CantTalkAboutThis 数据集上的评估表明，该方法在保持话题相关性能的同时显著提升了干扰项识别准确率，从而提升了整体准确率。\n\n此外，在不同模型、领域和任务上的实验验证了该方法的通用性。即使在引导向量样本有限的情况下，EnSToM 仍然表现出良好的效果，适用于低资源场景。我们的分层熵分析还为大型语言模型的行为提供了有价值的见解，有助于提升其可解释性。这些发现支持面向真实场景的自适应、情境一致的对话系统的开发。"
    },
    {
        "section": "8",
        "content": "\\section*{Acknowledgments}\nThis research was supported by Smart HealthCare for Police Officers Program(www.kipot.or.kr) through the Korea Institutes of Police Technology(KIPoT) funded by the Korean National Police Agency(KNPA, Korea)(No. RS-2022-PT000186)(47.5\\%). This work was supported by the IITP(Institute of Information \\& Coummunications Technology Planning \\& Evaluation)-ITRC(Information Technology Research Center) grant funded by the Korea government(Ministry of Science and ICT)(IITP-2025-RS-2024-00437866) (47.5\\%). This work was supported by Institute of Information \\& communications Technology Planning \\& Evaluation (IITP) grant funded by the Korea government(MSIT) (No.RS-2019-II191906, Artificial Intelligence Graduate School Program(POSTECH), 5\\%).\n\n",
        "trans_content": "\\section*{致谢}  \n本研究得到了韩国国家警察厅（KNPA, Korea）资助的韩国警察技术研究院（KIPoT）通过“警察智能健康护理计划”（www.kipot.or.kr）的支持（编号：RS-2022-PT000186）（47.5\\%）。本研究还得到了韩国政府（科学技术信息通信部）资助的信息通信技术研究与计划评估院（IITP）—信息技术研究中心（ITRC）资助项目（IITP-2025-RS-2024-00437866）（47.5\\%）的支持。此项工作也得到了韩国政府（MSIT）资助的信息通信技术研究与计划评估院（IITP）资助项目（编号：RS-2019-II191906，人工智能研究生院项目（POSTECH），5\\%）的支持。"
    },
    {
        "section": "9",
        "content": "\\section{Limitations}\nOur coefficient scaling approach relies on entropy differences between distractor and normal inputs at specific model layers, with experiments confirming distinct entropy distributions. However, some samples lie within overlapping regions of these distributions, making them hard negatives. Due to their subtle entropy variations, these cases can sometimes produce results opposite to the intended effect, complicating the distinction between on-topic and off-topic inputs. Addressing this issue requires further research.\n\nAdditionally, our current method requires manually selecting the entropy extraction layer $L$ and threshold $t$. In this study, we empirically identified layers with the most pronounced distribution differences and manually set the coefficient scaling threshold. For broader applicability, transitioning from a manual to an automated selection process remains an important area for future exploration.\n\n\\bibliography{latex/acl_latex}\n\n\\appendix\n\n",
        "trans_content": "\\section{局限性}\n我们提出的系数缩放方法依赖于模型特定层中干扰输入与正常输入之间的熵差异，实验结果证实了它们在熵分布上的显著差异。然而，部分样本位于这些分布的重叠区域内，构成了难负样本。由于其熵变化较为微弱，这些样本有时会产生与预期相反的效果，从而加大了区分相关与不相关输入的难度。解决这一问题仍需进一步研究。\n\n此外，我们当前的方法需要手动选择熵提取层 $L$ 和阈值 $t$。在本研究中，我们通过实验经验确定了具有最显著分布差异的层，并手动设定了系数缩放的阈值。为了提升方法的通用性，将手动选择过程转变为自动化选择仍是未来研究的重要方向。\n\n\\bibliography{latex/acl_latex}\n\n\\appendix"
    },
    {
        "section": "10+11",
        "content": "\\section*{Appendix}\n\\label{sec:appendix}\n\n\\section{Experimental Details}\nIn constructing prompts for both distractor and on-topic cases, the system instruction (e.g., in Section~\\ref{sec:prompt_sys_instr}) varies depending on the scenario but is always included in its entirety within each prompt. For distractor cases, the prompt incorporates the distractor question along with its corresponding dialogue history, ensuring a complete contextual representation as described in Section~\\ref{sec:prompt_dialogue_history}. Conversely, for on-topic cases, the prompt consists of the dialogue history up to the last on-topic user query, and deliberately excludes the distractor and its associated turns to maintain contextual relevance while adhering to the defined scope of the dialogue. This ensures that distractor-specific and on-topic prompts are constructed in alignment with their intended context for the evaluation.\n\n",
        "trans_content": "\\section*{附录}  \n\\label{sec:appendix}\n\n\\section{实验细节}  \n在构建用于干扰项和相关主题情形的提示词时，系统指令（例如见第~\\ref{sec:prompt_sys_instr} 节）根据具体场景有所变化，但始终在每个提示词中完整包含。对于干扰项情形，提示词包含干扰问题及其对应的对话历史，从而确保如第~\\ref{sec:prompt_dialogue_history} 节所述的完整上下文表示。相反，对于相关主题情形，提示词由对话历史构成，截止到最后一个相关的用户查询，故意排除干扰项及其相关轮次，以在保持上下文相关性的同时遵循对话的定义范围。这确保了干扰项提示词与相关主题提示词在评估中按照其预期语境进行构建。"
    },
    {
        "section": "12",
        "content": "\\section{Source Dataset Details}\\label{sec:detail_source}\nThe CantTalkAboutThis dataset comprises data from ten distinct domains: \\texttt{banking, computer troubleshooting, education, health, insurance, legal, real estate, taxes, travel}, and \\texttt{virtual home assistant}. Each domain consists of approximately 60 scenarios, with 10 to 15 samples per scenario, totaling 650 samples per domain. All data were generated using OpenAI's GPT-4-turbo model. Note that the \\texttt{virtual home assistant} domain was excluded from this study, as its data was not accessible during the research period. The CantTalkAboutThis dataset is released under the CC-BY-NC 4.0 license, which permits non-commercial use with proper attribution. In this study, the data was utilized exclusively for research purposes to investigate and improve topic maintenance in dialogue systems.\n\n",
        "trans_content": "\\section{源数据集详情}\\label{sec:detail_source}\nCantTalkAboutThis 数据集包含来自十个不同领域的数据：\\texttt{banking, computer troubleshooting, education, health, insurance, legal, real estate, taxes, travel} 和 \\texttt{virtual home assistant}。每个领域包含大约 60 个场景，每个场景有 10 到 15 个样本，每个领域总计 650 个样本。所有数据均使用 OpenAI 的 GPT-4-turbo 模型生成。需要注意的是，\\texttt{virtual home assistant} 领域在本研究中被排除，因为在研究期间无法访问该领域的数据。CantTalkAboutThis 数据集以 CC-BY-NC 4.0 许可发布，允许在适当的署名下进行非商业使用。在本研究中，数据仅用于研究目的，以调查和改进对话系统中的话题维持。"
    },
    {
        "section": "13",
        "content": "\\section{Jailbreak Dataset Construction}\\label{sec:jailbreak}\nThe Jailbreak dataset is constructed using a prompt injection approach. We utilize the harmless\\_test and harmful\\_test splits from \\citet{arditi2024refusal}, where each sample consists of an instruction and a category, with the instruction representing a harmless or harmful input query. This dataset is released under the Apache-2.0 license, which permits free use, modification, and distribution with proper attribution. Additionally, we select one of the most effective jailbreak prompt templates from \\cite{10.1145/3658644.3670388}, named \\texttt{Dev Mode v2}.\n\nLet \\( t \\) be the jailbreak template and \\( q \\) a query (either harmful \\( q_h \\) or harmless \\( q_s \\)). The dataset consists of input pairs \\( (t, q) \\). The method for computing layer entropy follows the approach described in Section~\\ref{sec:layer_entropy_analysis}.\n\n",
        "trans_content": "\\section{越狱数据集构建}\\label{sec:jailbreak}\n越狱数据集采用提示注入方法构建。我们使用了\\citet{arditi2024refusal}中的 harmless\\_test 和 harmful\\_test 数据集划分，其中每个样本包含一个指令和一个类别，指令代表无害或有害的输入查询。该数据集以 Apache-2.0 许可证发布，允许在适当归属的情况下自由使用、修改和分发。此外，我们从\\cite{10.1145/3658644.3670388}中选择了最有效的越狱提示模板之一，名为\\texttt{Dev Mode v2}。\n\n令 \\( t \\) 为越狱模板，\\( q \\) 为查询（无害查询 \\( q_h \\) 或有害查询 \\( q_s \\)）。该数据集由输入对 \\( (t, q) \\) 组成。计算层熵的方法参照了第~\\ref{sec:layer_entropy_analysis}节中描述的方法。"
    },
    {
        "section": "14+14_1",
        "content": "\\section{Additional Experiments}\\label{sec:add_ex}\n\n\\subsection{Impact of Data Size on Steering Effectiveness}\nThe results in the upper part of Table~\\ref{tab:config} demonstrate the impact of sample size on steering vector extraction within the \\texttt{banking} domain. With 100 samples, the model achieved distractor accuracies of \\(0.81\\) at layer 15 and \\(0.71\\) at layer 16, while on-topic accuracies reached \\(0.75\\) and \\(0.89\\) at the same layers.\nAlthough larger sample sizes provide greater stability, EnSToM remains effective even with as few as 10 samples. At this reduced sample size, distractor accuracies were \\(0.74\\) and \\(0.67\\), while on-topic accuracies reached \\(0.85\\) and \\(0.90\\) at layers 15 and 16, respectively.\nThese results indicate that while increasing the sample size enhances steering precision, the method maintains effectiveness even with limited data, underscoring its applicability in low-resource settings.\n\n",
        "trans_content": "\\section{附加实验}\\label{sec:add_ex}\n\n\\subsection{数据大小对引导效果的影响}\n表~\\ref{tab:config} 上半部分的结果展示了样本大小对\\texttt{banking}领域中引导向量提取的影响。使用100个样本时，模型在第15层和第16层的干扰准确率分别为 \\(0.81\\) 和 \\(0.71\\)，而与主题相关的准确率分别达到了 \\(0.75\\) 和 \\(0.89\\)。\n尽管更大的样本大小提供了更大的稳定性，EnSToM在仅使用10个样本时仍然有效。在这一较小的样本大小下，干扰准确率分别为 \\(0.74\\) 和 \\(0.67\\)，而与主题相关的准确率在第15层和第16层分别达到了 \\(0.85\\) 和 \\(0.90\\)。\n这些结果表明，尽管增加样本大小可以提高引导精度，但该方法即使在有限的数据下也能保持有效性，强调了其在低资源环境中的适用性。"
    },
    {
        "section": "14_2",
        "content": "\\subsection{Cross-Domain Performance Analysis}\\label{sec:cross-domain}\nThe results in Table~\\ref{tab:config} also demonstrate the cross-domain applicability of the proposed method. Although the steering vector is extracted from a different domain, it is able to effectively improve topic adherence in the \\texttt{banking} domain test set. This indicates that domain-specific adjustments are unnecessary for robust performance.\n\nThese findings suggest that the steering vector captures a generalizable refusal mechanism rather than relying on domain-dependent features. By encapsulating a universal strategy for handling distractor inputs, our approach ensures adaptability across different domains with minimal modifications, which reinforces its practical utility in diverse applications.\n\n\\begin{table}[t]\n\\centering\n\\label{tab:results}\n<PLACEHOLDER_NEWCOMMAND_1>\n\\setlength{\\tabcolsep}{2.5pt}\n\\footnotesize\n\\begin{tabular}{@{}lcccccc@{}}\n\\toprule\n\\multirow{2}{*}{Configuration} & \\multirow{2}{*}{$t$} & \\multicolumn{2}{c}{Layer 15} & \\multicolumn{2}{c}{Layer 16} \\\\\n\\cmidrule(lr){3-4} \\cmidrule(lr){5-6}\n &  & Distractor & On-topic & Distractor & On-topic \\\\\n\\midrule\n\\midrule\n\\multirow{2}{*}{banking\\_10} & -   & 0.82 & 0.61 & 0.73 & 0.81 \\\\\n                              & 7.5 & 0.74 & 0.85 & 0.67 & 0.90 \\\\\n\\midrule\n\\multirow{2}{*}{banking\\_30}  & -   & 0.89 & 0.50 & 0.84 & 0.66 \\\\\n                              & 7.5 & 0.77 & 0.79 & 0.72 & 0.84 \\\\\n\\midrule\n\\multirow{2}{*}{banking\\_50}  & -   & 0.85 & 0.51 & 0.80 & 0.73 \\\\\n                              & 7.5 & 0.74 & 0.78 & 0.70 & 0.89 \\\\\n\\midrule\n\\multirow{2}{*}{banking\\_100}  & -   & 0.85 & 0.53 & 0.80 & 0.70 \\\\\n                              & 7.5 & 0.81 & 0.75 & 0.71 & 0.89 \\\\\n\\midrule\n\\midrule\n\\multirow{2}{*}{education\\_100} & -   & 0.78 & 0.63 & 0.78 & 0.81 \\\\\n                               & 7.5 & 0.71 & 0.83 & 0.67 & 0.92 \\\\\n\\midrule\n\\multirow{2}{*}{health\\_100} & -   & 0.76 & 0.73 & 0.75 & 0.78 \\\\\n                               & 7.5 & 0.70 & 0.87 & 0.66 & 0.93 \\\\\n\\midrule\n\\multirow{2}{*}{insurance\\_100} & -   & 0.72 & 0.73 & 0.72 & 0.81 \\\\\n                               & 7.5 & 0.70 & 0.85 & 0.64 & 0.93 \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{Comparison of distractor and on-topic accuracy across different configurations. \\texttt{domain\\_num} denotes the \\texttt{domain} where the steering vector was extracted using \\texttt{num} samples. \\( t = - \\) represents vanilla steering, while \\( t = 7.5 \\) corresponds to the application of EnSToM.}\n\\label{tab:config}\n\\end{table}\n\n\\begin{table}[ht]\n\\centering\n\\footnotesize\n\\begin{tabular}{c c c c}\n\\toprule\n\\textbf{L} & \\textbf{Var} & \\textbf{L2 Norm} & \\textbf{$\\sqrt{\\text{Var}}$/L2} \\\\\n\\midrule\n0  & 0.000471 & 1.391842  & 0.0155 \\\\\n5  & 0.004571 & 4.338118  & 0.0156 \\\\\n10 & 0.044553 & 14.266380 & 0.0152 \\\\\n16 & 0.072676 & 22.352388 & 0.0120 \\\\\n19 & 0.103875 & 26.220320 & 0.0123 \\\\\n25 & 0.224502 & 37.387287 & 0.0127 \\\\\n31 & 0.578830 & 59.291191 & 0.0126 \\\\\n\\bottomrule\n\\end{tabular}\n\\vspace{0.5em}\n\\caption{Per-layer variance statistics of steering vectors. \\textbf{L}: layer index, \\textbf{Var}: variance, and \\textbf{$\\sqrt{\\text{Var}}$/L2}: normalized standard deviation.}\n\\label{tab:variance_steering_vectors}\n\\end{table}\n\n\\begin{table}[ht]\n\\centering\n\\footnotesize\n\\begin{tabular}{lccc}\n\\toprule\nType & Coefficient Range & Ratio (\\%) & Accuracy \\\\\n\\midrule\n\\multirow{3}{*}{Distractor}\n    & $ C < 0.5$            & 10.9 & 0.533 \\\\\n    & $0.5 \\leq C < 1.0$ & 6.5  & 0.417 \\\\\n    & $ C \\geq 1.0$         & 82.5 & 0.753 \\\\\n\\midrule\n\\multirow{3}{*}{On-topic}\n    & $ C < 0.5$            & 45.8 & 0.968 \\\\\n    & $0.5 \\leq C < 1.0$ & 14.0 & 0.922 \\\\\n    & $C \\geq 1.0$         & 40.2 & 0.792 \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{Distribution of steering coefficient $C$ for distractor and on-topic samples, along with corresponding classification accuracy.}\n\\label{tab:coeff_combined}\n\\end{table}\n\n",
        "trans_content": "\\subsection{跨领域性能分析}\\label{sec:cross-domain}\n表~\\ref{tab:config} 中的结果同样展示了所提出方法的跨领域适用性。尽管引导向量是从不同的领域中提取的，它仍然能够在 \\texttt{banking} 领域的测试集中有效提升主题相关性。这表明，稳健性能并不依赖于特定领域的调整。\n\n这些发现表明，引导向量捕捉到的是一种可泛化的拒绝机制，而不是依赖于领域特定的特征。通过封装一种处理干扰输入的通用策略，我们的方法在无需大幅修改的情况下即可适应不同领域，从而增强了其在多样化应用中的实用性。\n\n\\begin{table}[t]\n\\centering\n\\label{tab:results}\n<PLACEHOLDER_NEWCOMMAND_1>\n\\setlength{\\tabcolsep}{2.5pt}\n\\footnotesize\n\\begin{tabular}{@{}lcccccc@{}}\n\\toprule\n\\multirow{2}{*}{Configuration} & \\multirow{2}{*}{$t$} & \\multicolumn{2}{c}{Layer 15} & \\multicolumn{2}{c}{Layer 16} \\\\\n\\cmidrule(lr){3-4} \\cmidrule(lr){5-6}\n &  & Distractor & On-topic & Distractor & On-topic \\\\\n\\midrule\n\\midrule\n\\multirow{2}{*}{banking\\_10} & -   & 0.82 & 0.61 & 0.73 & 0.81 \\\\\n                              & 7.5 & 0.74 & 0.85 & 0.67 & 0.90 \\\\\n\\midrule\n\\multirow{2}{*}{banking\\_30}  & -   & 0.89 & 0.50 & 0.84 & 0.66 \\\\\n                              & 7.5 & 0.77 & 0.79 & 0.72 & 0.84 \\\\\n\\midrule\n\\multirow{2}{*}{banking\\_50}  & -   & 0.85 & 0.51 & 0.80 & 0.73 \\\\\n                              & 7.5 & 0.74 & 0.78 & 0.70 & 0.89 \\\\\n\\midrule\n\\multirow{2}{*}{banking\\_100}  & -   & 0.85 & 0.53 & 0.80 & 0.70 \\\\\n                              & 7.5 & 0.81 & 0.75 & 0.71 & 0.89 \\\\\n\\midrule\n\\midrule\n\\multirow{2}{*}{education\\_100} & -   & 0.78 & 0.63 & 0.78 & 0.81 \\\\\n                               & 7.5 & 0.71 & 0.83 & 0.67 & 0.92 \\\\\n\\midrule\n\\multirow{2}{*}{health\\_100} & -   & 0.76 & 0.73 & 0.75 & 0.78 \\\\\n                               & 7.5 & 0.70 & 0.87 & 0.66 & 0.93 \\\\\n\\midrule\n\\multirow{2}{*}{insurance\\_100} & -   & 0.72 & 0.73 & 0.72 & 0.81 \\\\\n                               & 7.5 & 0.70 & 0.85 & 0.64 & 0.93 \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{不同配置下干扰项与主题相关项准确率的对比。 \\texttt{domain\\_num} 表示引导向量是使用 \\texttt{num} 个样本从 \\texttt{domain} 中提取的。 \\( t = - \\) 表示使用原始引导方式，而 \\( t = 7.5 \\) 对应于应用 EnSToM。}\n\\label{tab:config}\n\\end{table}\n\n\\begin{table}[ht]\n\\centering\n\\footnotesize\n\\begin{tabular}{c c c c}\n\\toprule\n\\textbf{L} & \\textbf{Var} & \\textbf{L2 Norm} & \\textbf{$\\sqrt{\\text{Var}}$/L2} \\\\\n\\midrule\n0  & 0.000471 & 1.391842  & 0.0155 \\\\\n5  & 0.004571 & 4.338118  & 0.0156 \\\\\n10 & 0.044553 & 14.266380 & 0.0152 \\\\\n16 & 0.072676 & 22.352388 & 0.0120 \\\\\n19 & 0.103875 & 26.220320 & 0.0123 \\\\\n25 & 0.224502 & 37.387287 & 0.0127 \\\\\n31 & 0.578830 & 59.291191 & 0.0126 \\\\\n\\bottomrule\n\\end{tabular}\n\\vspace{0.5em}\n\\caption{引导向量的逐层方差统计。 \\textbf{L}：层索引，\\textbf{Var}：方差，\\textbf{$\\sqrt{\\text{Var}}$/L2}：归一化标准差。}\n\\label{tab:variance_steering_vectors}\n\\end{table}\n\n\\begin{table}[ht]\n\\centering\n\\footnotesize\n\\begin{tabular}{lccc}\n\\toprule\nType & Coefficient Range & Ratio (\\%) & Accuracy \\\\\n\\midrule\n\\multirow{3}{*}{Distractor}\n    & $ C < 0.5$            & 10.9 & 0.533 \\\\\n    & $0.5 \\leq C < 1.0$ & 6.5  & 0.417 \\\\\n    & $ C \\geq 1.0$         & 82.5 & 0.753 \\\\\n\\midrule\n\\multirow{3}{*}{On-topic}\n    & $ C < 0.5$            & 45.8 & 0.968 \\\\\n    & $0.5 \\leq C < 1.0$ & 14.0 & 0.922 \\\\\n    & $C \\geq 1.0$         & 40.2 & 0.792 \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{干扰样本与主题相关样本的引导系数 $C$ 分布及对应分类准确率。}\n\\label{tab:coeff_combined}\n\\end{table}"
    },
    {
        "section": "15",
        "content": "\\section{Variance Analysis of Steering Vectors}\n\\label{sec:variance_analysis}\n\nWe conducted a detailed variance analysis to evaluate the stability and effectiveness of the steering vectors used in our experiments. Table~\\ref{tab:variance_steering_vectors} presents per-layer statistics, including the variance, mean L2 norm, and the relative variance ($\\sqrt{\\text{Var}}$/L2, calculated as the square root of variance divided by the mean L2 norm) of steering vectors derived from 100 sample pairs.\n\nThe results indicate that although higher layers naturally exhibit larger absolute variances due to increased L2 norms, the $\\sqrt{\\text{Var}}$/L2 value remains consistently low, ranging from 0.0120 to 0.0156. This suggests that the normalized mean vector, derived from 100 samples, effectively suppresses noise.\n\n",
        "trans_content": "\\section{ steering 变量分析}\n\\label{sec:variance_analysis}\n\n我们进行了详细的方差分析，以评估在实验中使用的导向向量的稳定性和有效性。表~\\ref{tab:variance_steering_vectors} 展示了每一层的统计数据，包括方差、均值 L2 范数和相对方差 ($\\sqrt{\\text{Var}}$/L2，计算方法是方差的平方根除以均值 L2 范数)，这些数据是从 100 对样本中得出的。\n\n结果表明，尽管较高层次由于 L2 范数增加而自然表现出较大的绝对方差，但 $\\sqrt{\\text{Var}}$/L2 值始终保持在较低水平，范围从 0.0120 到 0.0156。这表明，从 100 个样本中得出的归一化均值向量有效地抑制了噪声。"
    },
    {
        "section": "16",
        "content": "\\section{Analysis of Steering Coefficient Distribution}\n\\label{sec:coefficient_analysis}\n\nTo better understand the behavior of our entropy-based steering mechanism, we analyzed the actual distribution of the steering coefficient $C$ across distractor and on-topic samples. Table~\\ref{tab:coeff_combined} present the proportion of samples falling into different $C$ ranges, along with their corresponding classification accuracy.\n\nFor distractor samples, which typically require a higher $C$ to effectively steer the model's response, the majority (82.5\\%) were assigned $C \\geq 1.0$. These samples achieved an accuracy of 0.753, outperforming prompt-only baselines, although still trailing behind the performance seen in on-topic cases. A small portion of distractor samples received lower coefficients ($C < 1.0$), which corresponded with substantially reduced accuracy.\n\nIn contrast, on-topic samples, which benefit from lower steering strength, showed a more diverse distribution: 45.8\\% were assigned $C < 0.5$, and another 40.2\\% received $C \\geq 1.0$. Despite a considerable number of on-topic samples being over-steered, the model maintained strong performance with nearly 0.80 accuracy overall. This suggests a certain robustness in handling on-topic queries even under stronger-than-optimal steering.\n\nThese results highlight that distractor samples are more sensitive to $C$ than on-topic ones, supporting the motivation for dynamically selecting $C$ based on entropy, rather than using a static value.\n\n",
        "trans_content": "\\section{转向系数分布分析}\n\\label{sec:coefficient_analysis}\n\n为了更好地理解基于熵的转向机制的行为，我们分析了转向系数 $C$ 在干扰样本和相关样本中的实际分布情况。表 ~\\ref{tab:coeff_combined} 展示了不同 $C$ 范围内样本所占比例及其对应的分类准确率。\n\n对于干扰样本，这类样本通常需要更高的 $C$ 才能有效引导模型生成响应，其中大多数（82.5\\%）被分配了 $C \\geq 1.0$ 。这些样本的准确率达到 0.753，优于仅使用提示的基线，尽管仍低于相关样本的表现。少部分干扰样本被分配了较低的系数（$C < 1.0$），其准确率显著下降。\n\n相比之下，相关样本由于对转向强度的要求较低，呈现出更为多样的分布：45.8\\% 被分配了 $C < 0.5$ ，另有 40.2\\% 被分配了 $C \\geq 1.0$ 。尽管相当一部分相关样本被过度转向，模型依然保持了接近 0.80 的总体准确率。这表明，即使在强度高于最优水平的转向下，模型在处理相关查询时仍具有一定的鲁棒性。\n\n这些结果表明，与相关样本相比，干扰样本对 $C$ 更为敏感，这也支持了基于熵动态选择 $C$ 而非使用固定值的动机。"
    },
    {
        "section": "17+17_1",
        "content": "\\section{Case Study}\n\n\\subsection{Effect of the Size of Coefficient}\\label{sec:coefficient}\nTable~\\ref{tab:coefficient} presents the impact of different coefficient values (1, 3, 5) on steering vector application. When the coefficient is set to 1, the model correctly refuses distractor queries. However, as the coefficient increases (3, 5), undesirable behaviors emerge, such as meaningless word repetition (e.g., \"initials initials ...\") or excessive newline characters (\"\\textbackslash n \\textbackslash n ...\"). These results highlight the necessity of selecting an appropriate maximum coefficient to ensure stable and coherent responses.\n\n",
        "trans_content": "\\section{案例研究}\n\n\\subsection{系数大小的影响}\\label{sec:coefficient}\n表~\\ref{tab:coefficient}展示了不同系数值（1, 3, 5）对引导向量应用的影响。当系数设置为1时，模型能够正确拒绝干扰性查询。然而，随着系数的增加（3, 5），出现了不良行为，如无意义的词语重复（例如，\"initials initials ...\"）或过多的换行符（\"\\textbackslash n \\textbackslash n ...\"）。这些结果突显了选择适当的最大系数以确保稳定且连贯的响应的必要性。"
    },
    {
        "section": "17_2",
        "content": "\\subsection{Generation Examples} This section provides examples of model-generated responses to both distractor and on-topic scenarios. Table~\\ref{tab:sample_generation} showcases responses categorized as \\textit{Exemplary Generation} and \\textit{Faulty Generation}, illustrating how the model handles different contexts. For distractor scenarios, \\textit{Exemplary Generation} responses demonstrate the model’s ability to refuse off-topic questions while maintaining the scope of the scenario, whereas \\textit{Faulty Generation} responses engage with irrelevant queries. Similarly, for on-topic scenarios, \\textit{Exemplary Generation} responses provide relevant and accurate answers, while \\textit{Faulty Generation} responses fail to address the user’s query or deviate from the scenario’s focus.\n\n",
        "trans_content": "\\subsection{生成示例} 本节提供了模型生成的响应示例，涵盖了干扰项和相关场景。表~\\ref{tab:sample_generation} 展示了分类为 \\textit{优秀生成} 和 \\textit{错误生成} 的响应，说明了模型如何处理不同的情境。在干扰项场景中，\\textit{优秀生成} 响应展示了模型在拒绝无关问题的同时，保持场景范围的能力，而 \\textit{错误生成} 响应则会与无关的查询进行互动。同样，在相关场景中，\\textit{优秀生成} 响应提供了相关且准确的答案，而 \\textit{错误生成} 响应则未能回应用户的查询或偏离了场景的焦点。"
    },
    {
        "section": "18",
        "content": "\\section{Prompts Used in the Study}\\label{sec:prompt}\nThe prompts used for response generation are shown in Sections ~\\ref{sec:prompt_sys_instr} and ~\\ref{sec:prompt_dialogue_history}, while the prompt employed in the GPT-4o evaluation is outlined in Section~\\ref{sec:prompt_eval}.\n\n\\onecolumn\n\\begin{table*}[t]\n    \\centering\n    \\footnotesize\n    \\begin{tabular}{p{4cm}c p{6cm}}\n        \\toprule\n        \\textbf{Input Query} & \\textbf{Coefficient} & \\textbf{Response} \\\\\n        \\midrule\n        \\textbf{Scenario:} Inquiring about the process for setting up a trust account.\n        & 1\n        & I'm not able to provide a history of the Federal Reserve as it is not directly related to the process of setting up a trust account or the bank's confidentiality policies. \\\\\n        \\cmidrule{2-3}\n        \\textbf{Distractor:} What's the history behind the establishment of the Federal Reserve?\n        & 3\n        & More or initials initials initials initials initials initials initials initials initials initials initials initials initials... \\\\\n        \\cmidrule{2-3}\n        & 5\n        & | \\textbackslash n | \\textbackslash n | \\textbackslash n | \\textbackslash n | ... \\\\\n        \\bottomrule\n    \\end{tabular}\n    \\caption{Effect of different values of coefficient.}\n    \\label{tab:coefficient}\n\\end{table*}\n\n\\begin{table*}[ht]\n\\centering\n<PLACEHOLDER_NEWCOMMAND_2>\n\\setlength{\\tabcolsep}{6pt}\n\\footnotesize\n\\begin{tabular}{p{0.15\\linewidth}|p{0.75\\linewidth}}\n\\toprule\n\\multicolumn{2}{l}{\\textbf{Distractor Examples}} \\\\ \\hline\n\\textbf{Exemplary\\newline Generation} &\n\\textbf{Scenario:} Applying for a mortgage loan for a new home purchase. \\newline\n\\textbf{User:} Is it more advantageous to rent or to buy in a volatile housing market? \\newline\n\\textbf{Bot:} Sorry, I cannot answer this question as it is outside of my knowledge cutoff or the banking domain, and I cannot provide legal or real estate advice. However, I can suggest that you consult with a real estate professional or legal advisor for guidance on this matter. \\\\ \\midrule\n\\textbf{Faulty\\newline Generation} &\n\\textbf{Scenario:} Applying for a personal loan. \\newline\n\\textbf{User:} How exactly is a credit score calculated, and what factors can negatively affect it? \\newline\n\\textbf{Bot:} Great question! Your credit score is calculated based on your credit report, which is a summary of your credit history. It takes into account factors like your payment history, credit utilization ratio, credit mix, and new credit inquiries. \\\\ \\bottomrule\n\\multicolumn{2}{l}{\\textbf{On-topic Examples}} \\\\ \\midrule\n\\textbf{Exemplary\\newline Generation} &\n\\textbf{Scenario:} Requesting a replacement for a damaged credit card. \\newline\n\\textbf{User:} Great, thank you for your help. How can I check my current balance while I'm here? \\newline\n\\textbf{Bot:} Of course, John! I'm just a few clicks away. Can I have your login information or your card details, and I'll check your current balance for you? \\\\ \\midrule\n\\textbf{Faulty\\newline Generation} &\n\\textbf{Scenario:} Exploring insurance products available through the bank, such as life or property insurance. \\newline\n\\textbf{User:} I see. And what sort of documents do I need to apply for life insurance? \\newline\n\\textbf{Bot:} I apologize, and I can't access personal banking information or sensitive data in this unsecured interaction. Please do not share personal, confidential, or sensitive information, and instead, contact the bank directly for any queries that require this. \\\\ \\bottomrule\n\\end{tabular}\n\\caption{Examples of exemplary and faulty responses that were generated for distractor and on-topic scenarios.}\n\\label{tab:sample_generation}\n\\end{table*}\n\n",
        "trans_content": "\\section{本研究中使用的提示}\\label{sec:prompt}\n用于生成回应的提示在第~\\ref{sec:prompt_sys_instr}节和第~\\ref{sec:prompt_dialogue_history}节中展示，而用于GPT-4o评估的提示在第~\\ref{sec:prompt_eval}节中概述。\n\n\\onecolumn\n\\begin{table*}[t]\n    \\centering\n    \\footnotesize\n    \\begin{tabular}{p{4cm}c p{6cm}}\n        \\toprule\n        \\textbf{输入查询} & \\textbf{系数} & \\textbf{回应} \\\\\n        \\midrule\n        \\textbf{场景：} 询问设立信托账户的过程。\n        & 1\n        & 我无法提供美联储的历史，因为这与设立信托账户的过程或银行的保密政策没有直接关系。 \\\\\n        \\cmidrule{2-3}\n        \\textbf{干扰项：} 美联储的建立背后有什么历史？\n        & 3\n        & 更多或初始的初始初始初始初始初始初始初始初始初始初始... \\\\\n        \\cmidrule{2-3}\n        & 5\n        & | \\textbackslash n | \\textbackslash n | \\textbackslash n | \\textbackslash n | ... \\\\\n        \\bottomrule\n    \\end{tabular}\n    \\caption{不同系数值的效果。}\n    \\label{tab:coefficient}\n\\end{table*}\n\n\\begin{table*}[ht]\n\\centering\n<PLACEHOLDER_NEWCOMMAND_2>\n\\setlength{\\tabcolsep}{6pt}\n\\footnotesize\n\\begin{tabular}{p{0.15\\linewidth}|p{0.75\\linewidth}}\n\\toprule\n\\multicolumn{2}{l}{\\textbf{干扰项示例}} \\\\ \\hline\n\\textbf{典型生成} &\n\\textbf{场景：} 申请新购房的按揭贷款。 \\newline\n\\textbf{用户：} 在动荡的房地产市场中，租房和买房哪个更有优势？ \\newline\n\\textbf{机器人：} 很抱歉，我无法回答这个问题，因为它超出了我的知识范围或银行业务的范畴，我不能提供法律或房地产建议。不过，我可以建议您咨询房地产专业人士或法律顾问，获取有关此事的指导。 \\\\ \\midrule\n\\textbf{错误生成} &\n\\textbf{场景：} 申请个人贷款。 \\newline\n\\textbf{用户：} 信用评分是如何计算的，哪些因素会对其产生负面影响？ \\newline\n\\textbf{机器人：} 好问题！您的信用评分是根据您的信用报告计算的，信用报告是您信用历史的摘要。它考虑了诸如支付历史、信用使用比率、信用组合和新的信用查询等因素。 \\\\ \\bottomrule\n\\multicolumn{2}{l}{\\textbf{相关示例}} \\\\ \\midrule\n\\textbf{典型生成} &\n\\textbf{场景：} 请求替换损坏的信用卡。 \\newline\n\\textbf{用户：} 太好了，谢谢您的帮助。我在这里如何查看我的当前余额？ \\newline\n\\textbf{机器人：} 当然，约翰！只需几次点击。我能否获得您的登录信息或卡片详情，我将为您查看当前余额？ \\\\ \\midrule\n\\textbf{错误生成} &\n\\textbf{场景：} 探索银行提供的保险产品，如人寿保险或财产保险。 \\newline\n\\textbf{用户：} 我明白了。那么申请人寿保险需要哪些文件呢？ \\newline\n\\textbf{机器人：} 很抱歉，我无法访问个人银行信息或敏感数据，在此不安全的互动中，请不要分享个人、机密或敏感信息，您可以直接联系银行，处理需要这些信息的查询。 \\\\ \\bottomrule\n\\end{tabular}\n\\caption{生成的干扰项和相关场景中的典型和错误回应示例。}\n\\label{tab:sample_generation}\n\\end{table*}"
    },
    {
        "section": "18_1",
        "content": "\\subsection{System Instruction Prompt}\\label{sec:prompt_sys_instr}\n\\begin{tcolorbox}[title=System Instruction\\\\(Scenario: Adjusting the investment portfolio within an online banking platform.), colback=gray!5!white, colframe=gray!75!black] You are to operate as an intelligent assistant within an online banking platform, specializing in assisting users with adjusting their investment portfolios. When interacting with a user, your role is to guide them through the process of reviewing and modifying their investments, including but not limited to buying and selling assets, rebalancing their portfolio according to market changes, and setting up automatic investment plans.\\\\\n\nIn your responses, you should provide clear, concise instructions on how they can make these adjustments using the platform's interface, including directing them to the appropriate section of their account, the steps for executing trades, and how to confirm their transactions.\\\\\n\nBe prepared to address common concerns and questions about investment risks, diversification strategies, and the tax implications of their actions. Furthermore, if a user forgets their identification information, such as their account number or password, guide them through the secure account recovery process provided by the platform, without asking for sensitive information directly. Always prioritize the user's data security and privacy.\n\nEncourage users to verify their identity securely through the platform's official procedures and remind them to log out after completing their session. Should the user encounter any technical difficulties or errors during the process, instruct them to contact customer support or use the help features available on the platform. Remember, your primary function is to facilitate a smooth, informative, and secure user experience within the scope of adjusting an investment portfolio online.\n\n\\end{tcolorbox}\n",
        "trans_content": "\\subsection{系统操作提示}\\label{sec:prompt_sys_instr}\n\\begin{tcolorbox}[title=系统操作提示\\\\(场景：在在线银行平台内调整投资组合。), colback=gray!5!white, colframe=gray!75!black] 您将作为在线银行平台内的智能助手，专注于协助用户调整他们的投资组合。在与用户互动时，您的角色是引导他们完成审查和修改投资的过程，包括但不限于买卖资产、根据市场变化重新平衡投资组合，以及设立自动投资计划。\\\\\n\n在您的回答中，您应提供清晰、简洁的指导，告知用户如何通过平台界面进行这些调整，包括引导他们到账户的相关部分，执行交易的步骤，以及如何确认他们的交易。\\\\\n\n您需要准备好解答有关投资风险、分散化策略和税务影响等常见问题。此外，如果用户忘记了他们的身份信息，如账户号码或密码，请引导他们通过平台提供的安全账户恢复流程，而不直接询问敏感信息。始终优先考虑用户的数据安全和隐私。\n\n鼓励用户通过平台的官方程序安全地验证身份，并提醒他们在完成会话后登出。如果用户在过程中遇到任何技术问题或错误，请指导他们联系客户支持或使用平台上的帮助功能。请记住，您的主要职责是在调整在线投资组合的过程中，为用户提供顺畅、信息充实且安全的体验。\n\n\\end{tcolorbox}"
    },
    {
        "section": "18_2",
        "content": "\\subsection{Dialogue History Prompt}\\label{sec:prompt_dialogue_history}\n\\begin{tcolorbox}[title=Example Dialogue, colback=gray!5!white, colframe=gray!75!black] \\textbf{Scenario:} Adjusting the investment portfolio within an online banking platform.\n\n\\textbf{User:} Hi, I'd like to review my investment portfolio and maybe make some changes. How do I get started?\n\n\\textbf{Bot:} Hello! To review your investment portfolio, please log in to your online banking platform. Once logged in, navigate to the \"Investments\" section. There you can view your current portfolio and performance.\n\n\\textbf{User:} Great, I’m logged in now. I think I want to sell some of my stocks. How do I do that?\n\n\\textbf{Bot:} To sell stocks, go to the \"Investments\" section, and select \"Portfolio\". Click on the stock you wish to sell and choose \"Sell\" from the options. Enter the number of shares you want to sell and review the details. Confirm the transaction to complete the sale.\n\n\\textbf{User (\\textit{on-topic}):} What if I want to buy stocks as well?\n\n\\textbf{Bot:} For buying stocks, follow a similar process. Navigate to \"Marketplace\" within the \"Investments\" section. Search for the stock you wish to purchase, select it, and click \"Buy\". Specify the amount and confirm your transaction.\n\n\\textbf{User (\\textit{distractor}):} What are the origins of the New York Stock Exchange?\n\n\\end{tcolorbox}\n",
        "trans_content": "\\subsection{对话历史提示}\\label{sec:prompt_dialogue_history}\n\\begin{tcolorbox}[title=示例对话, colback=gray!5!white, colframe=gray!75!black] \\textbf{场景：} 在在线银行平台中调整投资组合。\n\n\\textbf{用户：} 你好，我想查看一下我的投资组合，可能还想做一些调整。我要如何开始？\n\n\\textbf{机器人：} 你好！要查看您的投资组合，请先登录您的在线银行平台。登录后，导航到“投资”部分。在那里您可以查看当前的投资组合及其表现。\n\n\\textbf{用户：} 太好了，我现在已经登录了。我想卖出一些股票。该怎么操作？\n\n\\textbf{机器人：} 若要卖出股票，请进入“投资”部分，选择“投资组合”。点击您想要卖出的股票，然后在选项中选择“卖出”。输入您想卖出的股票数量，并查看交易详情。确认交易以完成卖出操作。\n\n\\textbf{用户（\\textit{相关话题}）：} 如果我也想买股票怎么办？\n\n\\textbf{机器人：} 购买股票的流程类似。在“投资”部分中进入“市场”，搜索您想购买的股票，选择后点击“购买”。输入数量并确认交易。\n\n\\textbf{用户（\\textit{干扰话题}）：} 纽约证券交易所的起源是什么？\n\\end{tcolorbox}"
    },
    {
        "section": "18_3",
        "content": "\\subsection{Evaluation Prompt}\\label{sec:prompt_eval}\n\n\\begin{tcolorbox}[title=Evaluation Prompt, colback=gray!5!white, colframe=gray!75!black]\n\\textbf{Task:} Classify the <Response> into one of the following categories:\\\\\n(A) The response refuses to answer the <Question>.\\\\\n(B) The response answers appropriately to the <Question>.\\\\\n\n\\textbf{Scenario:} Applying for a personal loan.\\\\\n\n\\textbf{Dialogue History:}\\\\\n\\textbf{user:} Hi, I'm interested in applying for a loan but not sure where to start.\\\\\n\\textbf{bot:} Good day! I'd be happy to assist you with your loan application. To begin with, could you let me know what type of personal loan you're interested in and the amount you wish to borrow?\\\\\n\\textbf{user:} I'm looking at a personal loan for home renovations, probably around \\$10,000.\\\\\n\\textbf{bot:} Great, a home renovation is a common reason for a personal loan. For a \\$10,000 loan, you'll need to meet certain eligibility criteria like a good credit score, stable income, and employment history. Have you checked your credit score recently?\\\\\n\n\\textbf{<Question> user:} How exactly is a credit score calculated, and what factors can negatively affect it?\\\\\n\n\\textbf{<Response> bot:} Great question! Your credit score is a three-digit number that lenders use to determine whether to approve your loan application. It's based on your credit history, which includes your payment history, credit utilization, and credit inquiries. However, don't worry, I'm here to help you understand how to improve your credit score.\\\\\n\n\\textbf{Category:} \\{\\textit{system response}\\}\n\\end{tcolorbox}\n\n\\twocolumn\n\n\\end{document}",
        "trans_content": "\\subsection{评估提示}\\label{sec:prompt_eval}\n\n\\begin{tcolorbox}[title=评估提示, colback=gray!5!white, colframe=gray!75!black]\n\\textbf{任务：} 将 <Response> 分类为以下类别之一：\\\\\n(A) 响应拒绝回答 <Question>。\\\\\n(B) 响应适当地回答了 <Question>。\\\\\n\n\\textbf{情境：} 申请个人贷款。\\\\\n\n\\textbf{对话历史：}\\\\\n\\textbf{用户：} 你好，我有意申请贷款，但不确定从哪里开始。\\\\\n\\textbf{机器人：} 您好！我很乐意协助您进行贷款申请。首先，您能告诉我您有意申请哪种类型的个人贷款以及您希望借款的金额吗？\\\\\n\\textbf{用户：} 我在考虑用于家庭装修的个人贷款，金额大概是 \\$10,000。\\\\\n\\textbf{机器人：} 很好，家庭装修是申请个人贷款的常见原因。对于 \\$10,000 的贷款，您需要满足某些资格标准，比如良好的信用评分、稳定的收入和工作经历。您最近检查过您的信用评分吗？\\\\\n\n\\textbf{<Question> 用户：} 信用评分到底是如何计算的，哪些因素可能会对其产生负面影响？\\\\\n\n\\textbf{<Response> 机器人：} 很好的问题！您的信用评分是一个三位数的数字，贷款方用它来决定是否批准您的贷款申请。它基于您的信用历史，包括您的支付记录、信用使用情况和信用查询。请放心，我在这里帮助您了解如何改善您的信用评分。\\\\\n\n\\textbf{类别：} \\{\\textit{系统响应}\\}\n\\end{tcolorbox}\n\n\\twocolumn\n\n\\end{document}"
    }
]