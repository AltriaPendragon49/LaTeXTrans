\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{anyt/global//global/global/global}
\providecommand \oddpage@label [2]{}
\abx@aux@cite{0}{dacey2000center}
\abx@aux@segm{0}{0}{dacey2000center}
\abx@aux@cite{0}{doi2012efficient}
\abx@aux@segm{0}{0}{doi2012efficient}
\abx@aux@cite{0}{knudsen1978space}
\abx@aux@segm{0}{0}{knudsen1978space}
\abx@aux@cite{0}{hubel1959receptive}
\abx@aux@segm{0}{0}{hubel1959receptive}
\abx@aux@cite{0}{hubel1968receptive}
\abx@aux@segm{0}{0}{hubel1968receptive}
\abx@aux@cite{0}{rolls1995sparseness}
\abx@aux@segm{0}{0}{rolls1995sparseness}
\abx@aux@cite{0}{niell2008highly}
\abx@aux@segm{0}{0}{niell2008highly}
\abx@aux@cite{0}{willmore2011sparse}
\abx@aux@segm{0}{0}{willmore2011sparse}
\abx@aux@cite{0}{ringach2002orientation}
\abx@aux@segm{0}{0}{ringach2002orientation}
\abx@aux@cite{0}{ringach2002spatial}
\abx@aux@segm{0}{0}{ringach2002spatial}
\abx@aux@cite{0}{crochet2011synaptic}
\abx@aux@segm{0}{0}{crochet2011synaptic}
\abx@aux@cite{0}{deweese2003binary}
\abx@aux@segm{0}{0}{deweese2003binary}
\abx@aux@cite{0}{hromadka2008sparse}
\abx@aux@segm{0}{0}{hromadka2008sparse}
\abx@aux@cite{0}{saxe2011unsupervised}
\abx@aux@segm{0}{0}{saxe2011unsupervised}
\abx@aux@cite{0}{olshausen1996emergence}
\abx@aux@segm{0}{0}{olshausen1996emergence}
\abx@aux@cite{0}{olshausen1997sparse}
\abx@aux@segm{0}{0}{olshausen1997sparse}
\abx@aux@cite{0}{bell1997independent}
\abx@aux@segm{0}{0}{bell1997independent}
\abx@aux@cite{0}{vanhateren1998independent}
\abx@aux@segm{0}{0}{vanhateren1998independent}
\abx@aux@cite{0}{field1999wavelets}
\abx@aux@segm{0}{0}{field1999wavelets}
\abx@aux@cite{0}{saxe2011unsupervised}
\abx@aux@segm{0}{0}{saxe2011unsupervised}
\abx@aux@cite{0}{krizhevsky2012imagenet}
\abx@aux@segm{0}{0}{krizhevsky2012imagenet}
\abx@aux@cite{0}{zeiler2013visualizing}
\abx@aux@segm{0}{0}{zeiler2013visualizing}
\abx@aux@cite{0}{yosinski2015understanding}
\abx@aux@segm{0}{0}{yosinski2015understanding}
\abx@aux@cite{0}{sengupta2018manifoldtiling}
\abx@aux@segm{0}{0}{sengupta2018manifoldtiling}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{goldt2020modelling}
\abx@aux@segm{0}{0}{goldt2020modelling}
\abx@aux@cite{0}{ringach2002spatial}
\abx@aux@segm{0}{0}{ringach2002spatial}
\abx@aux@cite{0}{decharms1998optimizing}
\abx@aux@segm{0}{0}{decharms1998optimizing}
\abx@aux@cite{0}{singer2018sensory}
\abx@aux@segm{0}{0}{singer2018sensory}
\abx@aux@cite{0}{krizhevsky2012imagenet}
\abx@aux@segm{0}{0}{krizhevsky2012imagenet}
\abx@aux@cite{0}{hyvarinen2000independent}
\abx@aux@segm{0}{0}{hyvarinen2000independent}
\abx@aux@cite{0}{ringach2002spatial}
\abx@aux@segm{0}{0}{ringach2002spatial}
\abx@aux@cite{0}{decharms1998optimizing}
\abx@aux@segm{0}{0}{decharms1998optimizing}
\abx@aux@cite{0}{singer2018sensory}
\abx@aux@segm{0}{0}{singer2018sensory}
\abx@aux@cite{0}{krizhevsky2012imagenet}
\abx@aux@segm{0}{0}{krizhevsky2012imagenet}
\abx@aux@cite{0}{hyvarinen2000independent}
\abx@aux@segm{0}{0}{hyvarinen2000independent}
\abx@aux@cite{0}{ringach2002spatial}
\abx@aux@segm{0}{0}{ringach2002spatial}
\abx@aux@cite{0}{decharms1998optimizing}
\abx@aux@segm{0}{0}{decharms1998optimizing}
\abx@aux@cite{0}{singer2018sensory}
\abx@aux@segm{0}{0}{singer2018sensory}
\abx@aux@cite{0}{krizhevsky2012imagenet}
\abx@aux@segm{0}{0}{krizhevsky2012imagenet}
\abx@aux@cite{0}{hyvarinen2000independent}
\abx@aux@segm{0}{0}{hyvarinen2000independent}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\@writefile{toc}{\contentsline {section}{\numberline {1}引言}{5}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{5}{引言}{section.1}{}}
\newlabel{sec:introduction@cref}{{[section][1][]1}{[1][5][]5}{}{}{}}
\abx@aux@cite{0}{barron1993universal}
\abx@aux@segm{0}{0}{barron1993universal}
\abx@aux@cite{0}{pinkus1999approximation}
\abx@aux@segm{0}{0}{pinkus1999approximation}
\abx@aux@cite{0}{woodworth2020kernel}
\abx@aux@segm{0}{0}{woodworth2020kernel}
\abx@aux@cite{0}{mei2018mean}
\abx@aux@segm{0}{0}{mei2018mean}
\abx@aux@cite{0}{goldt2019dynamics}
\abx@aux@segm{0}{0}{goldt2019dynamics}
\abx@aux@cite{0}{veiga2022phase}
\abx@aux@segm{0}{0}{veiga2022phase}
\abx@aux@cite{0}{saad1995line}
\abx@aux@segm{0}{0}{saad1995line}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{hyvarinen2009natural}
\abx@aux@segm{0}{0}{hyvarinen2009natural}
\abx@aux@cite{0}{rosenblatt1956central}
\abx@aux@segm{0}{0}{rosenblatt1956central}
\abx@aux@cite{0}{bardet2008dependent}
\abx@aux@segm{0}{0}{bardet2008dependent}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \textbf  {(左)} 来自非人灵长类动物（NHP）初级视觉皮层的空间感受野（RFs）局部化~\blx@tocontentsinit {0}\parencite [][图~2]{ringach2002spatial} 以及来自NHP~\blx@tocontentsinit {0}\parencite [][图~2]{decharms1998optimizing}和雪貂~\blx@tocontentsinit {0}\parencite [][图~2]{singer2018sensory}初级听觉皮层的时空感受野（RFs）局部化。 \textbf  {(中)} 用于ImageNet分类训练的AlexNet的局部化第一层卷积核半切片~\blx@tocontentsinit {0}\parencite {krizhevsky2012imagenet}。 \textbf  {(右)} 从任务\cref  {sec:task}中学习到的局部化感受野，在二维空间中使用独立成分分析（ICA）~\blx@tocontentsinit {0}\parencite {hyvarinen2000independent} 和软委员会机器（SCM；\labelcref  {item:many-neuron-model}，固定第二层权重） 来自\cref  {sec:model}。 \emph  {局部化——空间和/或时间选择性——在不同的设置中都有出现， 无论是通过生物系统中的响应最大化（左），还是通过检查人工系统中的线性滤波器（中、右）。} }}{6}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sim-real-gabors}{{1}{6}{\textbf {(左)} 来自非人灵长类动物（NHP）初级视觉皮层的空间感受野（RFs）局部化~\parencite [][图~2]{ringach2002spatial} 以及来自NHP~\parencite [][图~2]{decharms1998optimizing}和雪貂~\parencite [][图~2]{singer2018sensory}初级听觉皮层的时空感受野（RFs）局部化。 \textbf {(中)} 用于ImageNet分类训练的AlexNet的局部化第一层卷积核半切片~\parencite {krizhevsky2012imagenet}。 \textbf {(右)} 从任务\cref {sec:task}中学习到的局部化感受野，在二维空间中使用独立成分分析（ICA）~\parencite {hyvarinen2000independent} 和软委员会机器（SCM；\labelcref {item:many-neuron-model}，固定第二层权重） 来自\cref {sec:model}。 \emph {局部化——空间和/或时间选择性——在不同的设置中都有出现， 无论是通过生物系统中的响应最大化（左），还是通过检查人工系统中的线性滤波器（中、右）。}}{figure.caption.2}{}}
\newlabel{fig:sim-real-gabors@cref}{{[figure][1][]1}{[1][5][]6}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}建模方法}{6}{section.2}\protected@file@percent }
\newlabel{sec:prelims}{{2}{6}{建模方法}{section.2}{}}
\newlabel{sec:prelims@cref}{{[section][2][]2}{[1][5][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}神经网络架构与学习算法}{6}{subsection.2.1}\protected@file@percent }
\newlabel{sec:model}{{2.1}{6}{神经网络架构与学习算法}{subsection.2.1}{}}
\newlabel{sec:model@cref}{{[subsection][1][2]2.1}{[1][6][]6}{}{}{}}
\newlabel{item:many-neuron-model}{{{M1}}{6}{\textbf {模型 1} (\emph {多神经元架构})}{Item.1}{}}
\newlabel{item:many-neuron-model@cref}{{[enumi][1][]{M1}}{[1][6][]6}{}{}{}}
\newlabel{item:single-neuron-model}{{{M2}}{6}{\textbf {Model 2} (\emph {single-neuron architecture})}{Item.2}{}}
\newlabel{item:single-neuron-model@cref}{{[enumi][2][]{M2}}{[1][6][]6}{}{}{}}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{kolesnikov2019revisiting}
\abx@aux@segm{0}{0}{kolesnikov2019revisiting}
\abx@aux@cite{0}{chen2020simple}
\abx@aux@segm{0}{0}{chen2020simple}
\abx@aux@cite{0}{olshausen1996emergence}
\abx@aux@segm{0}{0}{olshausen1996emergence}
\abx@aux@cite{0}{bell1997independent}
\abx@aux@segm{0}{0}{bell1997independent}
\abx@aux@cite{0}{geman1984stochastic}
\abx@aux@segm{0}{0}{geman1984stochastic}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}刺激特性}{7}{subsection.2.2}\protected@file@percent }
\newlabel{sec:input}{{2.2}{7}{刺激特性}{subsection.2.2}{}}
\newlabel{sec:input@cref}{{[subsection][2][2]2.2}{[1][6][]7}{}{}{}}
\newlabel{item:weak-dependence}{{{S1}}{7}{\textbf {刺激属性 1--3} (\emph {自然图像的理想化})}{Item.3}{}}
\newlabel{item:weak-dependence@cref}{{[enumi][1][]{S1}}{[1][6][]7}{}{}{}}
\newlabel{item:translation-invariance}{{{S2}}{7}{\textbf {刺激属性 1--3} (\emph {自然图像的理想化})}{Item.4}{}}
\newlabel{item:translation-invariance@cref}{{[enumi][2][]{S2}}{[1][6][]7}{}{}{}}
\newlabel{item:sign-symmetry}{{{S3}}{7}{\textbf {刺激属性 1--3} (\emph {自然图像的理想化})}{Item.5}{}}
\newlabel{item:sign-symmetry@cref}{{[enumi][3][]{S3}}{[1][6][]7}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}长度尺度判别任务}{7}{subsection.2.3}\protected@file@percent }
\newlabel{sec:task}{{2.3}{7}{长度尺度判别任务}{subsection.2.3}{}}
\newlabel{sec:task@cref}{{[subsection][3][2]2.3}{[1][7][]7}{}{}{}}
\newlabel{eq:task}{{1}{7}{长度尺度判别任务}{equation.1}{}}
\newlabel{eq:task@cref}{{[equation][1][]1}{[1][7][]7}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{\texttt  {Ising}.}{7}{section*.3}\protected@file@percent }
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{hyvarinen2000independent}
\abx@aux@segm{0}{0}{hyvarinen2000independent}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{goldt2020modelling}
\abx@aux@segm{0}{0}{goldt2020modelling}
\abx@aux@cite{0}{gerace2020generalisation}
\abx@aux@segm{0}{0}{gerace2020generalisation}
\abx@aux@cite{0}{goldt2022gaussian}
\abx@aux@segm{0}{0}{goldt2022gaussian}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  从左到右： 长尺度和短尺度样本 $\mathbf  {x}$， 单一尺度的协方差 $\Sigma $， 以及数据模型的边缘分布 $p(X_i)$，如 \cref  {sec:task} 所述： Ising 模型（左、右样本分别为 $J=1.2, 0.3$）， 非线性高斯过程~\blx@tocontentsinit {0}\parencite [NLGP;~][]{ingrosso2022data}， 以及可控峰度模型 \texttt  {Kur} （左、右样本分别为 $\xi =5, 1$）。 \emph  { 每个模型生成的样本以零为中心，且其协方差可以被约束为相似， 但具有不同的高阶统计量，从维度方向的边缘分布中可以看出这一点。 } }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:task}{{2}{8}{从左到右： 长尺度和短尺度样本 $\mathbf {x}$， 单一尺度的协方差 $\Sigma $， 以及数据模型的边缘分布 $p(X_i)$，如 \cref {sec:task} 所述： Ising 模型（左、右样本分别为 $J=1.2, 0.3$）， 非线性高斯过程~\parencite [NLGP;~][]{ingrosso2022data}， 以及可控峰度模型 \texttt {Kur} （左、右样本分别为 $\xi =5, 1$）。 \emph { 每个模型生成的样本以零为中心，且其协方差可以被约束为相似， 但具有不同的高阶统计量，从维度方向的边缘分布中可以看出这一点。 }}{figure.caption.4}{}}
\newlabel{fig:task@cref}{{[figure][2][]2}{[1][7][]8}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{\texttt  {NLGP}$(g)$.}{8}{section*.5}\protected@file@percent }
\newlabel{eq:nlgp}{{3}{8}{\texttt {NLGP}$(g)$}{equation.3}{}}
\newlabel{eq:nlgp@cref}{{[equation][3][]3}{[1][7][]8}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{\texttt  {Kur}$(k)$.}{8}{section*.6}\protected@file@percent }
\newlabel{eq:alg}{{4}{8}{\texttt {Kur}$(k)$}{equation.4}{}}
\newlabel{eq:alg@cref}{{[equation][4][]4}{[1][8][]8}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}理论结果}{8}{section.3}\protected@file@percent }
\newlabel{sec:theory}{{3}{8}{理论结果}{section.3}{}}
\newlabel{sec:theory@cref}{{[section][3][]3}{[1][8][]8}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}单神经元中定位动力学的分析模型}{8}{subsection.3.1}\protected@file@percent }
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\newlabel{item:mean-assumption}{{{A1}}{9}{\textbf {解析简化 1--3} (\emph {早期时间，极限动态})}{Item.6}{}}
\newlabel{item:mean-assumption@cref}{{[enumi][1][]{A1}}{[1][9][]9}{}{}{}}
\newlabel{item:covariance-assumption}{{{A2}}{9}{\textbf {解析简化 1--3} (\emph {早期时间，极限动态})}{Item.7}{}}
\newlabel{item:covariance-assumption@cref}{{[enumi][2][]{A2}}{[1][9][]9}{}{}{}}
\newlabel{item:lindeberg-condition}{{{A3}}{9}{\textbf {解析简化 1--3} (\emph {早期时间，极限动态})}{Item.8}{}}
\newlabel{item:lindeberg-condition@cref}{{[enumi][3][]{A3}}{[1][9][]9}{}{}{}}
\newlabel{lem:gradient_flow}{{3.1}{9}{}{theorem.3.1}{}}
\newlabel{lem:gradient_flow@cref}{{[theorem][1][3]3.1}{[1][9][]9}{}{}{}}
\newlabel{eq:gradient_flow_early}{{5}{9}{}{equation.5}{}}
\newlabel{eq:gradient_flow_early@cref}{{[equation][5][]5}{[1][9][]9}{}{}{}}
\newlabel{eq:varphi}{{6}{9}{}{equation.6}{}}
\newlabel{eq:varphi@cref}{{[equation][6][]6}{[1][9][]9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}涌现局部化的必要和充分条件}{9}{subsection.3.2}\protected@file@percent }
\newlabel{subsec:localization_conditions}{{3.2}{9}{涌现局部化的必要和充分条件}{subsection.3.2}{}}
\newlabel{subsec:localization_conditions@cref}{{[subsection][2][3]3.2}{[1][9][]9}{}{}{}}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{harsh2020placecell}
\abx@aux@segm{0}{0}{harsh2020placecell}
\abx@aux@cite{0}{frahm2004generalized}
\abx@aux@segm{0}{0}{frahm2004generalized}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  从左侧开始，对于与 \cref  {fig:task} 中相同的 \texttt  {Ising}、\texttt  {NLGP} 和 \texttt  {Kur} 数据模型： 边缘分布 $p(X_i)$， 放大器 $\varphi $（定义见 \cref  {lem:gradient_flow}）与峰度 $\kappa $， 以及在其对应数据上训练的单神经元模型（\labelcref  {item:single-neuron-model}）的模拟感受野演化， 最后是通过数值积分 \cref  {eq:gradient_flow_early} 并将 $\varphi $ 展开为三阶泰勒近似后得到的感受野； 训练或演化时间由线条颜色表示（蓝色表示早期，红色表示晚期）。 \emph  {详见 \cref  {sec:theory-validation} 的阐述。} }}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:theory}{{3}{10}{从左侧开始，对于与 \cref {fig:task} 中相同的 \texttt {Ising}、\texttt {NLGP} 和 \texttt {Kur} 数据模型： 边缘分布 $p(X_i)$， 放大器 $\varphi $（定义见 \cref {lem:gradient_flow}）与峰度 $\kappa $， 以及在其对应数据上训练的单神经元模型（\labelcref {item:single-neuron-model}）的模拟感受野演化， 最后是通过数值积分 \cref {eq:gradient_flow_early} 并将 $\varphi $ 展开为三阶泰勒近似后得到的感受野； 训练或演化时间由线条颜色表示（蓝色表示早期，红色表示晚期）。 \emph {详见 \cref {sec:theory-validation} 的阐述。}}{figure.caption.7}{}}
\newlabel{fig:theory@cref}{{[figure][3][]3}{[1][9][]10}{}{}{}}
\newlabel{thm:localization}{{3.2}{10}{}{theorem.3.2}{}}
\newlabel{thm:localization@cref}{{[theorem][2][3]3.2}{[1][10][]10}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}案例研究：椭圆分布未能产生局部化}{10}{subsection.3.3}\protected@file@percent }
\newlabel{sub:elliptical}{{3.3}{10}{案例研究：椭圆分布未能产生局部化}{subsection.3.3}{}}
\newlabel{sub:elliptical@cref}{{[subsection][3][3]3.3}{[1][10][]10}{}{}{}}
\newlabel{def:elliptical}{{1}{10}{}{definition.1}{}}
\newlabel{def:elliptical@cref}{{[definition][1][]1}{[1][10][]10}{}{}{}}
\abx@aux@cite{0}{godfrey2023symmetries}
\abx@aux@segm{0}{0}{godfrey2023symmetries}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  单神经元模型 (\labelcref  {item:single-neuron-model}) 学习的感受野的演化，以及当在三种椭圆分布的数据上训练时，拟合到最终状态的正弦波（红色虚线）：$t_{40}(\nu =3)$ (\textbf  {左图})，椭圆表面 (\textbf  {中图})，以及一个自定义的椭圆分布，其质量位于椭圆的外侧 (\textbf  {右图})。 在所有情况下，学习到的感受野都是振荡的（正弦波），正如命题 \ref {thm:elliptical} 所预测的。 拟合的振荡权重与经验感受野之间的 $\ell _2$ 距离，作为经验感受野的 $\ell _2$ 范数的比率分别为（左图）9.77\%，（中图）3.75\%，（右图）4.14\%。 \emph  {参见 \cref  {sec:elliptical-experiments} 以获取详细说明。} }}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:elliptical}{{4}{11}{单神经元模型 (\labelcref {item:single-neuron-model}) 学习的感受野的演化，以及当在三种椭圆分布的数据上训练时，拟合到最终状态的正弦波（红色虚线）：$t_{40}(\nu =3)$ (\textbf {左图})，椭圆表面 (\textbf {中图})，以及一个自定义的椭圆分布，其质量位于椭圆的外侧 (\textbf {右图})。 在所有情况下，学习到的感受野都是振荡的（正弦波），正如命题 \ref {thm:elliptical} 所预测的。 拟合的振荡权重与经验感受野之间的 $\ell _2$ 距离，作为经验感受野的 $\ell _2$ 范数的比率分别为（左图）9.77\%，（中图）3.75\%，（右图）4.14\%。 \emph {参见 \cref {sec:elliptical-experiments} 以获取详细说明。}}{figure.caption.8}{}}
\newlabel{fig:elliptical@cref}{{[figure][4][]4}{[1][11][]11}{}{}{}}
\newlabel{thm:elliptical}{{3.3}{11}{}{theorem.3.3}{}}
\newlabel{thm:elliptical@cref}{{[theorem][3][3]3.3}{[1][10][]11}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}实验结果}{11}{section.4}\protected@file@percent }
\newlabel{sec:experiments}{{4}{11}{实验结果}{section.4}{}}
\newlabel{sec:experiments@cref}{{[section][4][]4}{[1][11][]11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}通过正负预测验证 Claim~\labelcref  {thm:localization}}{11}{subsection.4.1}\protected@file@percent }
\newlabel{sec:theory-validation}{{4.1}{11}{通过正负预测验证 Claim~\labelcref {thm:localization}}{subsection.4.1}{}}
\newlabel{sec:theory-validation@cref}{{[subsection][1][4]4.1}{[1][11][]11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  IPR \textit  {vs.}~超额峰度对于 $\texttt  {NLGP}$ 和 $\texttt  {Kur}$ 数据模型，基于30次重新初始化的单神经元模型的均值和标准差（\labelcref  {item:single-neuron-model}）； 误差条较小，可能不可见。 }}{11}{figure.caption.9}\protected@file@percent }
\newlabel{fig:replications}{{5}{11}{IPR \vs 超额峰度对于 $\texttt {NLGP}$ 和 $\texttt {Kur}$ 数据模型，基于30次重新初始化的单神经元模型的均值和标准差（\labelcref {item:single-neuron-model}）； 误差条较小，可能不可见。}{figure.caption.9}{}}
\newlabel{fig:replications@cref}{{[figure][5][]5}{[1][11][]11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  (\textbf  {左}, \textbf  {中}) 由多神经元（\labelcref  {item:many-neuron-model}）软委员会机器（第二层权重固定为 $\frac  {1}{K}$）学习到的感受野，分别在 $\texttt  {Kur}(10)$ 和 $\texttt  {Kur}(4)$ 数据集上训练得到。 模型具有 $N=40$ 个输入单元，$K=10$ 个隐藏单元，初始化方差为 $0.1$。 (\textbf  {右}) 从 scikit-learn 的 FastICA 算法中学习到的 40 个分量的随机子集，其中包含 10 个分量，使用的 $\texttt  {Kur}(3)$ 数据集，其长度尺度相关值为 $\xi _0 = 1$ 和 $\xi _1 = 3$。 \emph  {参见 \cref  {sec:extensions} 以了解详细说明。} }}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig:extensions}{{6}{12}{(\textbf {左}, \textbf {中}) 由多神经元（\labelcref {item:many-neuron-model}）软委员会机器（第二层权重固定为 $\frac {1}{K}$）学习到的感受野，分别在 $\texttt {Kur}(10)$ 和 $\texttt {Kur}(4)$ 数据集上训练得到。 模型具有 $N=40$ 个输入单元，$K=10$ 个隐藏单元，初始化方差为 $0.1$。 (\textbf {右}) 从 scikit-learn 的 FastICA 算法中学习到的 40 个分量的随机子集，其中包含 10 个分量，使用的 $\texttt {Kur}(3)$ 数据集，其长度尺度相关值为 $\xi _0 = 1$ 和 $\xi _1 = 3$。 \emph {参见 \cref {sec:extensions} 以了解详细说明。}}{figure.caption.10}{}}
\newlabel{fig:extensions@cref}{{[figure][6][]6}{[1][12][]12}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}通过位置预测验证\cref  {eq:gradient_flow_early}}{12}{subsection.4.2}\protected@file@percent }
\newlabel{sec:peak-prediction}{{4.2}{12}{通过位置预测验证\cref {eq:gradient_flow_early}}{subsection.4.2}{}}
\newlabel{sec:peak-prediction@cref}{{[subsection][2][4]4.2}{[1][12][]12}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}验证命题 \ref {thm:elliptical}：椭圆分布无法实现局部化}{12}{subsection.4.3}\protected@file@percent }
\newlabel{sec:elliptical-experiments}{{4.3}{12}{验证命题 \ref {thm:elliptical}：椭圆分布无法实现局部化}{subsection.4.3}{}}
\newlabel{sec:elliptical-experiments@cref}{{[subsection][3][4]4.3}{[1][12][]12}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}对多神经元模型和 ICA 的扩展}{12}{subsection.4.4}\protected@file@percent }
\newlabel{sec:extensions}{{4.4}{12}{对多神经元模型和 ICA 的扩展}{subsection.4.4}{}}
\newlabel{sec:extensions@cref}{{[subsection][4][4]4.4}{[1][12][]12}{}{}{}}
\abx@aux@cite{0}{hyvarinen2000independent}
\abx@aux@segm{0}{0}{hyvarinen2000independent}
\abx@aux@cite{0}{scikit-learn}
\abx@aux@segm{0}{0}{scikit-learn}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\abx@aux@cite{0}{chan2022data}
\abx@aux@segm{0}{0}{chan2022data}
\abx@aux@cite{0}{harsh2020placecell}
\abx@aux@segm{0}{0}{harsh2020placecell}
\abx@aux@cite{0}{karklin2011efficient}
\abx@aux@segm{0}{0}{karklin2011efficient}
\abx@aux@cite{0}{saxe2011unsupervised}
\abx@aux@segm{0}{0}{saxe2011unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  具有可学习的第二层权重的多神经元模型 (\labelcref  {item:many-neuron-model}) 的感受野，$N=40$，$K=10$。 (\textbf  {上图}) 来自一个使用sigmoid激活函数的模型的4个随机感受野子集， 该模型在$\texttt  {Kur(4)}$上训练（正的超额峰度为$3.28$）。 正如命题~\labelcref  {thm:localization}所预测的， 这些感受野\emph  {不是}局部化的，而表现为高频振荡。 (\textbf  {下图}) 来自一个使用ReLU激活函数的模型的4个随机感受野子集， 该模型在$\texttt  {Kur(30)}$上训练（负的超额峰度为$-1.17$）。 感受野是局部化的（\textbf  {左三}）或表现为低频振荡（\textbf  {右}）。 \emph  {参见 \cref  {sec:extensions} 以获取详细说明。} }}{13}{figure.caption.11}\protected@file@percent }
\newlabel{fig:multi-neuron}{{7}{13}{具有可学习的第二层权重的多神经元模型 (\labelcref {item:many-neuron-model}) 的感受野，$N=40$，$K=10$。 (\textbf {上图}) 来自一个使用sigmoid激活函数的模型的4个随机感受野子集， 该模型在$\texttt {Kur(4)}$上训练（正的超额峰度为$3.28$）。 正如命题~\labelcref {thm:localization}所预测的， 这些感受野\emph {不是}局部化的，而表现为高频振荡。 (\textbf {下图}) 来自一个使用ReLU激活函数的模型的4个随机感受野子集， 该模型在$\texttt {Kur(30)}$上训练（负的超额峰度为$-1.17$）。 感受野是局部化的（\textbf {左三}）或表现为低频振荡（\textbf {右}）。 \emph {参见 \cref {sec:extensions} 以获取详细说明。}}{figure.caption.11}{}}
\newlabel{fig:multi-neuron@cref}{{[figure][7][]7}{[1][12][]13}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}结论}{13}{section.5}\protected@file@percent }
\newlabel{sec:conclusions}{{5}{13}{结论}{section.5}{}}
\newlabel{sec:conclusions@cref}{{[section][5][]5}{[1][13][]13}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}定义与符号}{15}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}符号}{15}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}代数sigmoid函数}{15}{subsection.A.2}\protected@file@percent }
\newlabel{sec:algebraic-sigmoid}{{A.2}{15}{代数sigmoid函数}{subsection.A.2}{}}
\newlabel{sec:algebraic-sigmoid@cref}{{[subsection][2][1]A.2}{[1][15][]15}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}反参与比（IPR）}{15}{subsection.A.3}\protected@file@percent }
\newlabel{app:IPR}{{A.3}{15}{反参与比（IPR）}{subsection.A.3}{}}
\newlabel{app:IPR@cref}{{[subsection][3][1]A.3}{[1][15][]15}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}超出主文范围的扩展}{15}{appendix.B}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}放大器 $\varphi $ 的解析性质}{15}{subsection.B.1}\protected@file@percent }
\newlabel{sec:varphi-analysis}{{B.1}{15}{放大器 $\varphi $ 的解析性质}{subsection.B.1}{}}
\newlabel{sec:varphi-analysis@cref}{{[subsection][1][2]B.1}{[1][15][]15}{}{}{}}
\newlabel{lem:varphi}{{B.1}{15}{}{theorem.B.1}{}}
\newlabel{lem:varphi@cref}{{[theorem][1][2]B.1}{[1][15][]15}{}{}{}}
\abx@aux@cite{0}{goldt2020modelling}
\abx@aux@segm{0}{0}{goldt2020modelling}
\abx@aux@cite{0}{gerace2020generalisation}
\abx@aux@segm{0}{0}{gerace2020generalisation}
\abx@aux@cite{0}{goldt2022gaussian}
\abx@aux@segm{0}{0}{goldt2022gaussian}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}方程 \cref  {eq:gradient_flow_early} 的 PDE 极限}{16}{subsection.B.2}\protected@file@percent }
\newlabel{sec:pde-limit}{{B.2}{16}{方程 \cref {eq:gradient_flow_early} 的 PDE 极限}{subsection.B.2}{}}
\newlabel{sec:pde-limit@cref}{{[subsection][2][2]B.2}{[1][15][]16}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}假设~\labelcref  {item:mean-assumption,item:covariance-assumption} \textit  {vs.}~高斯等价性}{16}{subsection.B.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C}理论结果的证明}{16}{appendix.C}\protected@file@percent }
\newlabel{app:proofs}{{C}{16}{理论结果的证明}{appendix.C}{}}
\newlabel{app:proofs@cref}{{[section][3][]C}{[1][16][]16}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}均方误差（MSE）损失的梯度流}{16}{subsection.C.1}\protected@file@percent }
\newlabel{eq:loss_2relu_neuron}{{9}{16}{均方误差（MSE）损失的梯度流}{equation.9}{}}
\newlabel{eq:loss_2relu_neuron@cref}{{[equation][9][]9}{[1][16][]16}{}{}{}}
\abx@aux@cite{0}{elkabetz2024continuous}
\abx@aux@segm{0}{0}{elkabetz2024continuous}
\abx@aux@cite{0}{bradley2007introduction}
\abx@aux@segm{0}{0}{bradley2007introduction}
\newlabel{eq:gradient_flow_two}{{10}{17}{均方误差（MSE）损失的梯度流}{equation.10}{}}
\newlabel{eq:gradient_flow_two@cref}{{[equation][10][]10}{[1][17][]17}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}引理 \ref {lem:gradient_flow} 的证明}{17}{subsection.C.2}\protected@file@percent }
\newlabel{subsec:pf_of_gradient_flow}{{C.2}{17}{引理 \ref {lem:gradient_flow} 的证明}{subsection.C.2}{}}
\newlabel{subsec:pf_of_gradient_flow@cref}{{[subsection][2][3]C.2}{[1][17][]17}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}引理 \ref {lem:varphi} 的证明}{18}{subsection.C.3}\protected@file@percent }
\newlabel{subsec:pf_of_varphi}{{C.3}{18}{引理 \ref {lem:varphi} 的证明}{subsection.C.3}{}}
\newlabel{subsec:pf_of_varphi@cref}{{[subsection][3][3]C.3}{[1][18][]18}{}{}{}}
\abx@aux@cite{0}{frahm2004generalized}
\abx@aux@segm{0}{0}{frahm2004generalized}
\abx@aux@cite{0}{ingrosso2022data}
\abx@aux@segm{0}{0}{ingrosso2022data}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}命题~\ref {thm:elliptical}的证明}{19}{subsection.C.4}\protected@file@percent }
\newlabel{eq:elliptical_gradient_flow}{{11}{19}{命题~\ref {thm:elliptical}的证明}{equation.11}{}}
\newlabel{eq:elliptical_gradient_flow@cref}{{[equation][11][]11}{[1][19][]19}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}附加实验}{20}{appendix.D}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}可视化假设~\labelcref  {item:lindeberg-condition} 的分解}{20}{subsection.D.1}\protected@file@percent }
\newlabel{fig:0ipr_mse_zoomed_in}{{\caption@xref {fig:0ipr_mse_zoomed_in}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:0ipr_mse_zoomed_in@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:0timeshot}{{\caption@xref {fig:0timeshot}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:0timeshot@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:1ipr_mse_zoomed_in}{{\caption@xref {fig:1ipr_mse_zoomed_in}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:1ipr_mse_zoomed_in@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:1timeshot}{{\caption@xref {fig:1timeshot}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:1timeshot@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:2ipr_mse_zoomed_in}{{\caption@xref {fig:2ipr_mse_zoomed_in}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:2ipr_mse_zoomed_in@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:2timeshot}{{\caption@xref {fig:2timeshot}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:2timeshot@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:3ipr_mse_zoomed_in}{{\caption@xref {fig:3ipr_mse_zoomed_in}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:3ipr_mse_zoomed_in@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:3timeshot}{{\caption@xref {fig:3timeshot}{ on input line 14}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:3timeshot@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:gaussian_ipr_mse}{{\caption@xref {fig:gaussian_ipr_mse}{ on input line 25}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:gaussian_ipr_mse@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\newlabel{fig:gaussian_timeshot}{{\caption@xref {fig:gaussian_timeshot}{ on input line 25}}{21}{可视化假设~\labelcref {item:lindeberg-condition} 的分解}{figure.caption.13}{}}
\newlabel{fig:gaussian_timeshot@cref}{{[subsection][1][4]D.1}{[1][20][]21}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  (\textbf  {顶部}) 在 $\texttt  {NLGP}(g=100)$ 上训练的四个初始化，$\xi _0 = 0.3$ 和 $\xi _1 = 0.7$。 如预期的那样，权重始终会本地化。 在（左，第一）中，我们绘制了经验和解析感受野（RF）随时间变化的 IPR（定义为（\# 梯度步数）$\times \, \tau $，学习率）。 在（左，第二）中，我们绘制了经验和解析 RF 之间的 $\ell _2$ 距离的时间演化。 在（左，第三）中，我们放大（左，第一），将范围限制在 $[0,0.1]$ 以更清楚地观察训练初期 IPR 的发散。 在（右，第一）和（右，第二）中，我们分别在解析模型因本地化而崩溃之前和之后的时刻快照了经验和解析 RF（根据 IPR 和 $\ell _2$ 距离）。 最后，在（右，第三）中，我们快照了训练期结束时的情况。 (\textbf  {底部}) 与顶部第一行相同的初始化，但在 $\texttt  {NLGP}(g=0.01)$ 数据上训练，仍然使用 $\xi _0 = 0.3$ 和 $\xi _1 = 0.7$。 如预期的那样，权重不会本地化。 我们绘制了与上面相同的量，但在这里我们的解析模型的预测在整个训练过程中保持有效，因为本地化从未出现，因此假设（A3）未像上面那样被违反。  }}{21}{figure.caption.13}\protected@file@percent }
\newlabel{fig:time}{{8}{21}{(\textbf {顶部}) 在 $\texttt {NLGP}(g=100)$ 上训练的四个初始化，$\xi _0 = 0.3$ 和 $\xi _1 = 0.7$。 如预期的那样，权重始终会本地化。 在（左，第一）中，我们绘制了经验和解析感受野（RF）随时间变化的 IPR（定义为（\# 梯度步数）$\times \, \tau $，学习率）。 在（左，第二）中，我们绘制了经验和解析 RF 之间的 $\ell _2$ 距离的时间演化。 在（左，第三）中，我们放大（左，第一），将范围限制在 $[0,0.1]$ 以更清楚地观察训练初期 IPR 的发散。 在（右，第一）和（右，第二）中，我们分别在解析模型因本地化而崩溃之前和之后的时刻快照了经验和解析 RF（根据 IPR 和 $\ell _2$ 距离）。 最后，在（右，第三）中，我们快照了训练期结束时的情况。 (\textbf {底部}) 与顶部第一行相同的初始化，但在 $\texttt {NLGP}(g=0.01)$ 数据上训练，仍然使用 $\xi _0 = 0.3$ 和 $\xi _1 = 0.7$。 如预期的那样，权重不会本地化。 我们绘制了与上面相同的量，但在这里我们的解析模型的预测在整个训练过程中保持有效，因为本地化从未出现，因此假设（A3）未像上面那样被违反。}{figure.caption.13}{}}
\newlabel{fig:time@cref}{{[figure][8][]8}{[1][20][]21}{}{}{}}
\abx@aux@read@bbl@mdfivesum{nohash}
\abx@aux@read@bblrerun
\gdef \@abspage@last{21}
