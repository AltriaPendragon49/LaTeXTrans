






\section{实验装置}
\label{app:implementation_details}

在\Cref{tab:scaling_laws_hparams}中，我们展示了用于推导缩放定律的不同模型配置的预训练超参数。参数数量从275M到37B不等，随着模型宽度的增加而相应增加，而深度保持固定为24层。学习率随模型大小变化，在模型规模扩大时减小。基于经验实验和与\citep{mckinzie2025mm1}相似的估计，我们发现这些值在我们的设置中是有效的。训练使用完全解耦的AdamW优化器进行优化，动量值为$\beta_1=0.9$、$\beta_2=0.95$，权重衰减为$1\text{e}{-4}$。批量大小设置为2k样本，考虑到1k上下文长度，这相当于2M个词元。梯度裁剪设置为1.0，最大预热期为5k次迭代，针对较短的训练运行进行了调整：对于分别在1k–4k步和5k–15k步之间训练的模型，预热步骤分别为1k和2.5k。对于MoE，我们发现较长的预热期显著更好，因此我们在所有少于20k步的运行中采用2.5k步预热。我们使用恒定的学习率调度，在最后20\%的训练过程中逐渐冷却，按照逆平方根调度逐步减少到零。对于视觉处理，图像输入被分成$(14,14)$个补丁，增强包括随机调整大小的裁剪（将图像调整为224px，比例范围为[0.4, 1.0]）和随机水平翻转，概率为0.5。我们用混合交错的数据（图像标题和仅文本数据）\Cref{tab:pretraining_datasets}来训练我们的模型。
对于晚期融合模型，我们发现对视觉编码器使用较小的学习率显著提高了性能\Cref{tab:late_scaler_scratch}，并且当编码器和解码器都初始化时（\Cref{sec:app_init_early_late}），我们发现冻结视觉编码器的效果最好\Cref{tab:late_scaler_init}。


 

          




\begin{table}[htb]
    \begin{center}
        \centering
        \setlength{\tabcolsep}{14pt}
        \resizebox{\linewidth}{!}{
        \begin{tabular}{l c c c c c c}
            \toprule
            \textbf{Early-fusion} \\
            \midrule
            Params &  275M & 468M & 932M  & 1.63B & 2.28B & 3.35B \\
            width & 800 & 1088 & 1632 & 2208 & 2624 & 3232\\
            depth & \multicolumn{6}{c}{24} \\
            Learning rate & 1.5e-3 & 1.5e-3 & 5e-4 & 4.2e-4 & 4e-4 & 3.5e-4 \\
            \midrule
            \textbf{Late-fusion} \\
            \midrule
            Params &  289M & 494M & 1B  & 1.75B & 2.43B & 3.7B \\
            vision encoder width & 384 & 512 & 768 & 1024 & 1184 & 1536 \\
            vision encoder depth & \multicolumn{6}{c}{24} \\
            width & 768 & 1024 & 1536 & 2048 & 2464 & 3072\\
            depth & \multicolumn{6}{c}{24} \\
            Learning rate & 1.5e-3 & 1.5e-3 & 5e-4 & 4.2e-4 & 3.8e-4 & 3.3e-4 \\
            \midrule
            \textbf{Early-fusion MoEs} \\
            \midrule
            Active Params &  275M & 468M & 932M  & 1.63B & 2.28B & 3.35B \\
            width & 800 & 1088 & 1632 & 2208 & 2624 & 3232\\
            depth & \multicolumn{6}{c}{24} \\
            Learning rate & 1.5e-3 & 1.5e-3 & 5e-4 & 4.2e-4 & 4e-4 & 3.5e-4 \\
            \midrule
            Training tokens & \multicolumn{6}{c}{2.5B-600B} \\
            Optimizer & \multicolumn{6}{c}{Fully decoupled AdamW~\citep{loshchilov2017decoupled}} \\ %
            Optimizer Momentum & \multicolumn{6}{c}{$\beta_1=0.9 ,\beta_2=0.95$} \\
            Minimum Learning rate & \multicolumn{6}{c}{0} \\
            Weight decay & \multicolumn{6}{c}{1e-4} \\
            Batch size & \multicolumn{6}{c}{2k} \\
            Patch size & \multicolumn{6}{c}{(14, 14)} \\
            Gradient clipping & \multicolumn{6}{c}{1.0} \\
            MAximum Warmup iterations & \multicolumn{6}{c}{5k} \\
            Augmentations: \\
            \quad {\tt RandomResizedCrop} \\
            \qquad {\tt size} & \multicolumn{6}{c}{224px} \\
            \qquad {\tt scale} & \multicolumn{6}{c}{[0.4, 1.0]} \\
            \quad {\tt RandomHorizontalFlip} & \multicolumn{6}{c}{$p=0.5$} \\
            \bottomrule
        \end{tabular}}
    \end{center}
    \caption{\textbf{预训练超参数} 我们详细说明了用于预训练不同模型配置以推导缩放法则的超参数。}
    \label{tab:scaling_laws_hparams}
    \end{table}


\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt}
    \renewcommand{\arraystretch}{1}
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lccccc}
        Vision encoder & Interleaved & Image-Caption & Text  & AVG & AVG (SFT)  \\
        lr scaler & (CE) & (CE) & (CE) & (CE) & (Acc) \\
        \shline
        1 & 2.521 & 2.15 & 2.867 &  2.513 & 43.49 \\
        0.1 & 2.502 & 2.066 & 2.862 &  2.477 & 52.27\\
        0.01 & 2.502 & 2.066 & 2.859 &  2.476 & 53.76\\
        0.001 & 2.513 & 2.066 & 2.857 &  2.479 & -- \\
        0 (frozen) & 2.504 & 2.061 & 2.856 & 2.474 & 54.14 \\
        \bottomrule
    \end{tabular}%
    } 
    \caption{\textbf{视觉编码器缩放器。} 在用预训练模型初始化后期融合模型时，冻结视觉编码器的效果最佳。}
    \label{tab:late_scaler_init}
\end{table}


\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt}
    \renewcommand{\arraystretch}{1}
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lccccc}
        Vision encoder & Interleaved & Image-Caption & Text  & AVG & AVG (SFT)  \\
        lr scaler & (CE) & (CE) & (CE) & (CE) & (Acc) \\
        \shline
        0.1 & 2.674 & 2.219 & 3.072   & 2.655 & 34.84 \\
        0.01 & 2.672 & 2.197 & 3.071  & 2.647 & 38.77 \\
        0.001 & 2.674 & 2.218 & 3.073 & 2.655 & 38.46 \\
        \bottomrule
    \end{tabular}%
    } 
    \caption{\textbf{视觉编码器缩放器。} 从头开始训练晚期融合模型时，降低视觉编码器的学习率效果更好。}
    \label{tab:late_scaler_scratch}
\end{table}



\input{figs/late_vs_early_equal_tokens}




\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_late_datatype_sameflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
         \input{graphs/early_late/early_late_datatype_sameflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
         \input{graphs/early_late/early_vs_late_datatype_sameflops_dclm}
    \end{subfigure}
            
    \vspace{0.3cm}
    \caption{\textbf{早期融合与晚期融合：改变训练混合。} 我们改变训练混合并绘制最终的训练损失。当增加交错文档的比例时，早期融合模型表现得更好。早期融合和晚期融合分别具有1.63B和1.75B参数。}
    \label{fig:early_vs_late_datatype_sameflops}
\end{figure*}


\section{晚期 vs 早期融合}
\label{app:late_vs_early}
本节提供了早期和晚期融合模型之间的额外比较。

\subsection{浮点运算的缩放（Scaling FLOPs）} \Cref{fig:early_vs_late_scaledata_main} 在缩放浮点运算时比较了早期融合和晚期融合模型。具体来说，对于每种模型大小，我们使用不同数量的训练词元训练多个模型。两种方法之间的性能差距主要由于模型大小的增加而不是训练词元数量的增加而减小。尽管差距在缩小，但在我们训练的所有模型中，早期融合始终优于晚期融合。




\subsection{改变训练数据混合} 我们分析了训练数据混合比例的变化如何影响早期融合模型和晚期融合模型之间的性能差距。如\Cref{fig:early_vs_late_textratio}和\Cref{fig:early_vs_late_datatype_sameflops}所示，当固定模型大小时，增加文本和交错数据的比例有利于早期融合。有趣的是，对于其他数据类型，该差距基本保持不变。我们还观察到不同数据类型之间的干扰效应。具体来说，增加交错数据的量会负面影响图像标题的性能，反之亦然。此外，增加纯文本数据的比例略微提高交错数据的性能，但增加了图像标题的损失。总体而言，我们发现纯文本数据和交错数据在不同的设置中是相关的。



    









\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_textratio_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_textratio_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_textratio_dclm}
    \end{subfigure}
            
    \vspace{0.3cm}
    \caption{\textbf{早期融合与晚期融合：改变训练混合中仅文本数据的比例（isoFLOPs）。} 我们改变仅文本数据的比例并绘制最终训练损失。随着文本数据比例的增加，早期融合模型的优势更加明显。早期融合模型有1.63B个参数，而晚期融合模型有1.75B个参数。}
    \label{fig:early_vs_late_textratio}
\end{figure*}

\input{figs/early_vs_late_imageres}

\subsection{缩放图像分辨率有利于早期融合}

我们研究了两种架构在不同图像分辨率下的表现。我们将早期融合和晚期融合的模型参数数量分别固定为16.3亿和17.5亿。所有模型都训练了10万步或2000亿个词元。由于patch大小保持不变，提高分辨率会导致视觉词元的数量增加。对于所有分辨率，我们都保持相同的文本词元数量。
如\Cref{fig:early_vs_late_imageres}所示，早期融合模型在各种分辨率下始终优于晚期融合模型，特别是在多模态数据上，随着分辨率的提高，性能差距会加大。
此外，我们观察到，随着分辨率的提高，文本和交错数据上的损失也会增加。

\vspace{1cm}
\subsection{在匹配晚期融合模型的规模时，早期融合始终表现更好。}
\input{figs/early_vs_late_datatype_isoparams}


在本节中，我们比较了不同配置的早期融合模型的晚期融合模型。具体而言，我们训练了早期融合模型，使其在总参数（Params）、文本模型大小（Text）和浮点运算次数（FLOPs）方面与晚期融合模型匹配，假设采用45-45-10的训练混合比例。如表\Cref{fig:early_vs_late_datatype_isoparams}所示，当按总参数归一化时，早期融合始终优于晚期融合，接着是按浮点运算次数归一化。当匹配文本模型大小时，在交错数据比例较高时，早期融合表现更好。 







\subsection{不同的晚期融合配置} 
我们研究了这种缩放在不同晚期融合配置下的变化。不像主论文中那样等比例缩放视觉和文本模型，我们将视觉编码器的大小固定为300M，只对文本模型进行缩放。\Cref{fig:early_vs_late_scalellmdata_dclm}显示，在较小的模型尺寸下，晚期融合模型表现较差，但随着文本模型的缩放，差距显著缩小。这表明将更多参数分配给共享组件更有益处，进一步支持了早期融合模型的选择。










\begin{figure*}[htp]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scalellmdata_dclm}
    \end{subfigure}

    \makebox[0.9\linewidth]{ %
        \begin{tikzpicture}
            \begin{axis}[
                hide axis, %
                xmin=0, xmax=0.5, ymin=0, ymax=1, %
                legend columns=4, %
                legend style={
                    at={(0.5, 1)}, %
                    anchor=north, %
                    /tikz/every even column/.append style={column sep=0.2cm}, %
                    scale=0.5, %
                    cells={align=left}, font=\footnotesize,
                },
            ]
               \addlegendimage{legend late_0_2b style}
                \addlegendentry{Late-0.555B}
                \addlegendimage{legend late_0_4b style}
                \addlegendentry{Late-1.14B}
                \addlegendimage{LateGradStart!50!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-2.320B}
                \addlegendimage{LateGradStart!75!LateGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Late-3.33B}
            
            
                \addlegendimage{legend early_0_2b style}
                \addlegendentry{Early-0.464B}
                \addlegendimage{EarlyGradStart!25!EarlyGradEnd, thick, solid, mark=*, mark size=1.5pt}
                \addlegendentry{Early-0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{Early-1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{Early-3.354B}
            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4.2cm}
    \caption{\textbf{早期融合与晚期融合：在固定视觉编码器大小的情况下扩展训练 Token 数量。} 我们比较了早期和晚期融合模型，当同时扩展训练 Token 数量和模型大小时。对于晚期融合模型，我们固定视觉编码器大小（300M），并扩展文本模型的大小（250M、834M、2B、3B）。随着文本模型规模的扩展，早期和晚期之间的差距逐渐缩小。}
    \label{fig:early_vs_late_scalellmdata_dclm}
\end{figure*}















\subsection{从LLM和CLIP初始化}
\label{sec:app_init_early_late}

我们研究了在训练早期融合和晚期融合模型时都使用预训练模型的情况，特别是对于晚期融合，具体使用DCLM-1B \citep{li2024datacomp} 和 CLIP-ViT-L \citep{radford2021learning}。有趣的是，\Cref{fig:early_vs_late_init_scaledata} 表明对于文本和交错的多模态文档，当训练时间更长时，早期融合可以匹配晚期融合的性能。然而，在图像标题数据上缩小差距仍然更具挑战性。值得注意的是，考虑到包括预训练模型在内的整体训练成本，早期融合需要显著延长训练时间以弥补视觉编码器的预训练成本。

\input{figs/early_vs_late_init_scaledata}












                
                





\section{缩放律}
\label{app:scaling_laws}












\subsection{拟合 \(L = F(N, D)\) }  
following \citep{hoffmann2022training}，我们确定使所有运行下的以下目标最小化的参数 \(i\) ：  
\begin{equation}
\footnotesize
    \min_{a,b,e,\alpha,\beta} \sum_{i} \text{Huber}_\delta \left( \text{LSE} \left( a - \alpha \log N_i, b - \beta \log D_i, e \right) - \log L_i \right),
\end{equation}  
我们针对各种初始化值域进行此最优化，并选择在所有初始化中达到最低损失的参数。具体来说，我们的网格搜索在 \(\{0, 0.5, 2.5\}\)  对于 \(\alpha\)  和 \(\beta\) ，\(\{0, 5, 10, ..., 30\}\)  对于 \(a\)  和 \(b\) ，以及 \(\{-1, -0.5, 1, 0.5\}\)  对于 \(e\) 。我们使用带有 \(\delta=1e-3\) 的 L-BFGS 算法。  



\subsection{拟合 \(N \propto C^a\) 、\(D \propto C^b\) 和 \(D \propto N^d\) }  
虽然这些方程对于可以从 \Cref{eq:scaling_laws} 推导出来的早期融合模型有一个闭式解 \citep{hoffmann2022training}，但对于未指定视觉编码器或文本模型大小的晚期融合模型来说并非如此。为了确保公平比较，我们通过在对数空间中执行线性回归，为这两种模型推导这些方程。我们发现该回归与通过闭式推导 \Cref{tab:scaling_laws_closed_form} 找到的系数非常接近。例如，为了推导 \(N = K_aC^a\)，给定一个FLOP预算 \(C\) 和一组从10B到600B线性间隔的词元 \(D_i\)，我们为每个 \(D_i\) 计算早期融合的模型大小为 \(N_i = \frac{C}{6D}\)，晚期融合的模型大小为 \(N_i = \frac{C}{6D}+0.483*N_v\)（对于45 - 45 - 10混合，\(D_v=0.544D\)，因此 $C=6D(0.544N_v+N_t)$）。然后我们应用 \Cref{eq:scaling_laws} 来获得每个模型大小的损失，并选择具有最小损失的 \(N\)。我们对与我们的运行相对应的所有FLOP值重复此操作，得到一组点 \((C, N_{opt})\)，我们用它来对 \(a\) 和 \(K_a\) 进行回归。我们遵循类似的过程来找到 \(b\) 和 \(d\)。对于晚期融合模型，我们对一个线性模型进行回归，以确定给定 \(N\) 时的 \(N_v\)。值得注意的是，尽管我们为晚期融合模型保持固定的宽度比，但这种方法更准确，因为嵌入层阻止了文本和视觉模型大小之间严格固定的比例。我们在 \Cref{fig:scaling_laws_closed_form_early_late} 中展示回归结果。


\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt} %
    \renewcommand{\arraystretch}{1} %
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lcccccccc}
        Model & $a$ & $b$ & $d$ & $n$ & $dn$  \\
        \midrule
        Closed form  & 0.52649 & 0.47351 & 0.89938 &  1.11188 & -0.05298  \\
        Regression & 0.52391 & 0.47534 & 0.90052 & 1.10224 & -0.04933  \\
        \bottomrule
    \end{tabular}%
    }
    \caption{\textbf{早融合的缩放参数。} 通过回归推导缩放系数与使用闭式解得到的结果非常接近。}
    \label{tab:scaling_laws_closed_form}
\end{table}


\subsection{拟合 \(L \propto C^c\) }  
以确定最终模型的损失与计算预算\(C\)之间的关系，我们首先对对应相同模型大小的点进行插值，并计算覆盖每个FLOP所有运行达到的最小损失的凸包。这将得到从FLOPs到最低损失的连续映射。我们考虑一个范围的FLOPs，排除非常小的值($\leq 3e^{19}$)，并构建一个包含\((C, L)\)个数据点的数据集，这些数据点在计算\(C\)上是线性间隔的。使用这些数据，我们在对数空间中找到\(L\)和\(C\)之间的线性关系，并推导出指数\(c\)。我们在\Cref{fig:scaling_laws_early_late_moe}中可视化结果。









\begin{figure}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{1\linewidth}



    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/early/early_scalinglaws_params_vs_flops_avg_ap3}
    \end{subfigure}
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/late/late_scalinglaws_params_vs_flops_avg_ap3}
    \end{subfigure}
    
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/early/early_scalinglaws_tokens_vs_flops_avg_ap3}
    \end{subfigure}
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/late/late_scalinglaws_tokens_vs_flops_avg_ap3}
    \end{subfigure}
    
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/early/early_scalinglaws_tokens_to_params_vs_flops_avg_ap3}
    \end{subfigure}
    \begin{subfigure}[t]{0.47\linewidth}
        \input{graphs/late/late_scalinglaws_tokens_to_params_vs_flops_avg_ap3}
    \end{subfigure}

    


      
    \end{subfigure}
    \caption{\textbf{缩放律系数的回归结果。} 我们的缩放系数估计值接近闭式解。}
    \label{fig:scaling_laws_closed_form_early_late}
\end{figure}


\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/pred_loss_vs_loss_early}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/pred_loss_vs_loss_late}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/pred_loss_vs_loss_moe}
    \end{subfigure}
    \caption{\textbf{观测与预测损失。} 我们可视化了我们的缩放律（\Cref{eq:scaling_laws}）预测的损失以及每次运行实际达到的损失。}
    \label{fig:observed_vs_predicted_loss}
\end{figure*}



\subsection{不同类型目标数据的缩放定律}
在\Cref{fig:scaling_laws_early_late_moe_getty_obelics_dclm}中，我们推导了不同目标数据类型的缩放规律。一般来说，我们观察到模型在图像标题生成任务上比交错数据学习得更快，这由更高的缩放指数绝对值所表明（例如，0.062与0.046相比），尽管用于标题生成和交错数据的比例是相同的（各占45％）。此外，我们发现模型在仅文本数据上的学习速度更慢，可能是因为仅文本数据量较少（10％）。在不同的模型配置中，我们发现早期融合在图像标题生成任务上的缩放方式与晚期融合相似，但具有较低的乘法常数（49.99与47.97相比）。对于MoE，模型学习速度更快，但表现出更高的乘法常数。在文本和交错数据上，早期和晚期融合模型的缩放方式相似，并实现了可比的性能。然而，MoE展示了更好的整体性能，同时学习速度略慢。






\subsection{不同训练混合物的缩放定律}

我们研究了在修改训练混合物时缩放规律的变化。具体来说，我们改变图像标题、交错和纯文本数据的比例，并在\Cref{fig:app_early_scaleflops_data_mixtures}中报告结果。总体而言，我们观察到相似的缩放趋势，缩放系数只有轻微变化。经过更详细的分析，我们发现增加训练混合物中某一特定数据类型的比率会导致其相应的缩放指数增加。例如，将图像标题的比例从30\%提高到40\%，绝对值指数从0.056增加到0.061。然而，对于纯文本数据，在训练混合物中改变其比例时，我们没有观察到显著的缩放系数变化。















    
                                 
                                     
                            




                    
                        
                    
                    



\begin{wrapfigure}{r}{0.4\textwidth}
        \vspace{-4mm}
        \centering
        \captionsetup{type=figure}
        \begin{subfigure}[t]{\linewidth}
            \includegraphics[width=1.0\textwidth]{assets/moes/specialization/model1088/modality_specialization_1088_150_across_layers.pdf}
        \end{subfigure}
        
        \caption{\textbf{模态特定的特化。} 我们可视化专家在文本和图像模态上的特化。模型在Obelics上进行评估。}
        \label{fig:app_moes_specialization}
\end{wrapfigure}   



\subsection{缩放律评估和敏感性}

对于每种模型大小和训练词元数量，我们根据\Cref{eq:scaling_laws}中的估计泛函形式计算损失，并将其与我们的运行所实现的实际损失进行比较。我们在\Cref{fig:observed_vs_predicted_loss}中可视化这些点，表明我们的估计非常准确，尤其是在较低的损失值（即较大的FLOPs）时。此外，我们使用自举法进行敏感性分析。具体来说，我们用替换的方式对\( P \)个点进行采样（\( P \)等于训练的模型总数），并重新估计缩放律系数。此过程重复100次，我们报告每个系数的平均值和标准差。\Cref{tab:scaling_laws_sensitivity}显示，相比于\(\alpha\)，我们的估计在\(\beta\)更为精确，主要是因为用于推导缩放律的模型大小数量相对于不同词元计数的数量较少。  





\begin{table}[htb]
    \centering
    \setlength{\tabcolsep}{16pt} %
    \renewcommand{\arraystretch}{1} %
    \resizebox{0.9\linewidth}{!}{
    \begin{tabular}{lcccccccc}
        Model & E & $\alpha$ & $\beta$ & a & b  & d\\
        \midrule
        Avg  & 1.80922 & 0.29842 & 0.33209 & 0.54302  & 0.48301 &  0.92375 \\
        Std & 0.33811 & 0.10101 & 0.02892 & 0.08813 & 0.05787 & 0.23296 \\
        \bottomrule
    \end{tabular}%
    }
    \caption{\textbf{缩放律敏感性。} 我们报告了使用100次自举法迭代后的均值和标准差。}
    \label{tab:scaling_laws_sensitivity}
\end{table}


\subsection{\edit{稀疏神经网络模型的缩放定律}}
\label{app:scaling_laws_moes}

类似于稠密模型，我们拟合了一个参数化损失函数 (\Cref{eq:scaling_laws}) 以根据参数数量和训练词元预测稀疏NMM的损失，用激活参数的数量代替总参数计数。虽然在推导MoE的缩放定律时引入稀疏性是标准做法 (\citep{wangscalingmoe,krajewski2024scalingmoe,abnar2025parameters})，但我们专注于推导特定于我们MoE设置中稀疏水平的缩放定律。这使得系数隐式地依赖于稀疏配置。 

我们还实验了如\citep{abnar2025parameters}中提出的具有稀疏性感知的缩放定律公式，并观察到一致的趋势(\Cref{tab:moes_coeffs})。特别是，与模型大小($N$)相关的指数远大于与训练词元($\beta$)相关的指数，这进一步强调了在稀疏架构中扩展模型大小的重要性。此外，我们观察到控制活动参数缩放的项分解为两个组成部分。


\input{tables/scaling_laws_coeffs_moes}


\section{混合专家模型与模态特定的特化}
\label{app:moes}





我们研究了MoE架构中的多模态特化。我们计算一个特化得分为分配给每个专家的文字/图像词元数量与均匀分配的平均差值($1/E$)。此外，我们可视化了跨层分配给每个专家的文字和图像词元的规范化数量。\Cref{fig:app_moes_specialization}显示了明显的模态特定专家，尤其是在早期层中。此外，特化得分随着层数的增加而减少，但在最后几层又上升。这表明早期和最终层需要比中间层更多的模态特化。另外，我们观察到文字和图像模态之间存在几个共享的专家，这种现象在硬路由或预定义的模态特定专家中不存在。


        



\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_avg}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_avg}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_avg_big}
    \end{subfigure}


    \makebox[0.9\linewidth]{ %
        \begin{tikzpicture}
            \begin{axis}[
                hide axis, %
                xmin=0, xmax=0.5, ymin=0, ymax=1, %
                legend columns=6, %
                legend style={
                    at={(0.5, 1)}, %
                    anchor=north, %
                    /tikz/every even column/.append style={column sep=0.2cm}, %
                    scale=0.5, %
                    cells={align=left}, font=\footnotesize,
                },
            ]

            \addlegendimage{legend late_0_2b style}
            \addlegendentry{0.289B}
            \addlegendimage{legend late_0_4b style}
            \addlegendentry{0.494B}
            \addlegendimage{legend late_0_9b style}
            \addlegendentry{1B}
            \addlegendimage{legend late style}
            \addlegendentry{1.748B}
            \addlegendimage{legend late_2_2b style}
            \addlegendentry{2.430B}
            \addlegendimage{legend late_3_3b style}
            \addlegendentry{3.714B}

            \addlegendimage{legend early_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend early_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend early_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend early style}
            \addlegendentry{1.627B}
            \addlegendimage{legend early_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend early_3_3b style}
            \addlegendentry{3.354B}

            \addlegendimage{legend moe_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend moe_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend moe_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend moe style}
            \addlegendentry{1.627B}
            \addlegendimage{legend moe_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend moe_3_3b style}
            \addlegendentry{3.354B}

            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4cm}

    \caption{\textbf{原生多模态模型的缩放规律。} 从左到右：晚期融合（稠密）、早期融合（稠密）和早期融合 MoE。所有模型的缩放指数非常接近。然而，MoE 导致整体损失更低（乘法常数更小），并且需要更长时间达到饱和。}
    \label{fig:scaling_laws_early_late_moe}
\end{figure*}



\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/late/late_scaleflops_dclm}
    \end{subfigure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_dclm}
    \end{subfigure}


    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/moe/moe_scaleflops_dclm}
    \end{subfigure}


    \makebox[0.9\linewidth]{ %
        \begin{tikzpicture}
            \begin{axis}[
                hide axis, %
                xmin=0, xmax=0.5, ymin=0, ymax=1, %
                legend columns=6, %
                legend style={
                    at={(0.5, 1)}, %
                    anchor=north, %
                    /tikz/every even column/.append style={column sep=0.2cm}, %
                    scale=0.5, %
                    cells={align=left}, font=\footnotesize,
                },
            ]

            \addlegendimage{legend late_0_2b style}
            \addlegendentry{0.289B}
            \addlegendimage{legend late_0_4b style}
            \addlegendentry{0.494B}
            \addlegendimage{legend late_0_9b style}
            \addlegendentry{1B}
            \addlegendimage{legend late style}
            \addlegendentry{1.748B}
            \addlegendimage{legend late_2_2b style}
            \addlegendentry{2.430B}
            \addlegendimage{legend late_3_3b style}
            \addlegendentry{3.714B}

            \addlegendimage{legend early_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend early_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend early_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend early style}
            \addlegendentry{1.627B}
            \addlegendimage{legend early_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend early_3_3b style}
            \addlegendentry{3.354B}

            \addlegendimage{legend moe_0_2b style}
            \addlegendentry{0.275B}
            \addlegendimage{legend moe_0_4b style}
            \addlegendentry{0.464B}
            \addlegendimage{legend moe_0_9b style}
            \addlegendentry{0.932B}
            \addlegendimage{legend moe style}
            \addlegendentry{1.627B}
            \addlegendimage{legend moe_2_2b style}
            \addlegendentry{2.280B}
            \addlegendimage{legend moe_3_3b style}
            \addlegendentry{3.354B}

            \end{axis}
        \end{tikzpicture}
    }

    \vspace{-4cm}
    \caption{\textbf{原生多模态模型的缩放规律。} 从上到下：晚期融合（稠密）、早期融合（稠密）和早期融合MoE。从左到右：图像标题、交错和仅文本数据的验证集上的交叉熵。}
    \label{fig:scaling_laws_early_late_moe_getty_obelics_dclm}
\end{figure*}




























\begin{figure*}[h!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early/early_scaleflops_dclm}
    \end{subfigure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_getty_40_20_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_obelics_40_20_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_dclm_40_20_40}
    \end{subfigure}
    
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_getty_30_30_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_obelics_30_30_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_dclm_30_30_40}
    \end{subfigure}

    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_getty_20_40_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_obelics_20_40_40}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_data_mixtures/early_scaleflops_dclm_20_40_40}
    \end{subfigure}

    \makebox[0.9\linewidth]{ %
    \begin{tikzpicture}
        \node[anchor=north] (legend) at (0\linewidth, 0) {
            \begin{axis}[
                        hide axis, %
                        xmin=0, xmax=0.5, ymin=0, ymax=1, %
                        legend columns=6, %
                        legend style={
                            at={(-0.12, -0.025)}, %
                            anchor=north, %
                            /tikz/every even column/.append style={column sep=0.2cm}, %
                            scale=0.5,
                            cells={align=left}, font=\footnotesize,
                            anchor=center,
                        },
                    ]
                \addlegendimage{legend early_0_2b style}
                \addlegendentry{0.275B}
                \addlegendimage{legend early_0_4b style}
                \addlegendentry{0.464B}
                \addlegendimage{legend early_0_9b style}
                \addlegendentry{0.932B}
                \addlegendimage{legend early style}
                \addlegendentry{1.627B}
                \addlegendimage{legend early_2_2b style}
                \addlegendentry{2.280B}
                \addlegendimage{legend early_3_3b style}
                \addlegendentry{3.354B}
            \end{axis}
        };
    \end{tikzpicture}
    }
    \vspace{0.5cm}




      

    \caption{\textbf{早期融合原生多模态模型的缩放规律。} 我们在不同的训练混合数据（Image-caption-Interleaved-Text）和FLOPs下的实验结果。我们可视化了在3种数据类型上的最终有效验证损失：HQITP（左），Obelics（中）和DCLM（右）。}
    \label{fig:app_early_scaleflops_data_mixtures}
\end{figure*}
